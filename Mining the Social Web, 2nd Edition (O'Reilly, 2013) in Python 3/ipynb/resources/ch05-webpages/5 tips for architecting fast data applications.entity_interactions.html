<html>
    <head>
        <title>5 tips for architecting fast data applications Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body><strong>Consid<strong>era</strong>tions</strong> for setting the architectural <strong>foundations</strong> for a fast <strong>data platform.We</strong> live in the <strong>era</strong> of the connected <strong>experience</strong>, where our daily int<strong>era</strong>ctions with the <strong>world</strong> can be digitized, collected, processed, and analyzed to gen<strong>era</strong>te valuable insights. Back in the <strong>days</strong> of <strong>Web</strong> 1.0, <strong>Google</strong> <strong>founders</strong> figured out smart <strong>ways</strong> to rank <strong>websites</strong> by analyzing their <strong>connection</strong> <strong>patterns</strong> and using that <strong>information</strong> to improve the <strong>relevance</strong> of <strong>search</strong> results. <strong>Google</strong> was among the <strong>pioneers</strong> that created <strong>“</strong><strong>web</strong> scale” architectures to analyze the massive <strong>data</strong> <strong>sets</strong> that resulted from <strong>“</strong>crawling” the <strong>web</strong> that gave <strong>birth</strong> to <strong>Apache Hadoop</strong>, <strong>MapReduce</strong>, and <strong>NoSQL</strong> <strong>data</strong>bases. Those were the <strong>days</strong> when <strong>“</strong>connected<strong>”</strong> meant having some web <strong>presence</strong>, <strong>“</strong><strong>interactions</strong><strong>”</strong> were measured in <strong>number</strong> of <strong>clicks</strong>, and the <strong>analysis</strong> happened in <strong>batch overnight</strong> processes. Fast forward to the present <strong>day</strong> and we find ourselves in a <strong>world</strong> where the <strong>number</strong> of connected devices is constantly increasing. These devices not only respond to our commands, but are also able to autonomously interact with each other. Each of these interactions generates data that collectively amount to high-volume data streams. Accumulating all this <strong>data</strong> to process <strong>overnight</strong> is not an option anymore. First, we want to generate actionable <strong>insights</strong> as fast as possible, and second, one <strong>night</strong> might not be long enough to process all the <strong>data</strong> collected the previous day. At the same <strong>time</strong>, our <strong>expectations</strong> as <strong><strong>user</strong>s</strong> have also evolved to the <strong>point</strong> where we demand that <strong>applications</strong> deliver personalized <strong>user</strong> <strong>experiences</strong> in near real <strong>time</strong>. To remain competitive in a <strong>market</strong> that demands real-time <strong>responses</strong> to these digital <strong>pulses</strong>, <strong>organizations</strong> are adopting fast <strong>data applications</strong> as key <strong>assets</strong> in their technology portfolio. There are many <strong>challenges</strong> that need to be addressed to create the right <strong>architecture</strong> to support the <strong>range</strong> of fast <strong>data applications</strong> that your <strong>enterprise</strong> needs. Here are five <strong>considerations</strong> every <strong>software architect</strong> and <strong>developer</strong> <strong>needs</strong> to take into <strong>account</strong> when setting the architectural <strong>foundations</strong> for a fast data platform. 1. <strong>Determine</strong> <strong><strong>requirements</strong></strong> first
Although this seems the obvious starting <strong>point</strong> of every <strong>software architecture</strong>, there are specific <strong>considerations</strong> to observe when we define the <strong>set</strong> of <strong><strong>requirements</strong></strong> for a <strong>software platform</strong> to support fast <strong>data</strong> applications. <strong>Data</strong> in <strong>motion</strong> can be tricky to characterize, as there are usually probabilistic <strong>factors</strong> involved in the <strong>generation</strong>, <strong>transmission</strong>, <strong>collection</strong>, and <strong>processing</strong> of messages. These are some of the <strong>questions</strong> we need answered in <strong>order</strong> to help us drive the <strong>architecture</strong>:
<strong>General</strong> <strong>data</strong> <strong>shape</strong>

<strong>How</strong> large is each message? How many messages per time unit do we expect? Do we expect large <strong>changes</strong> in the <strong>frequency</strong> of message delivery? Are there peak hours? <strong>Are</strong> there “Black Friday” <strong>events</strong> in our business? <strong>Output</strong> <strong>expectations</strong>

<strong>How</strong> fast do we need a result? Do we need to process each record individually? Or can we process them in small <strong>collections</strong> (<strong>micro-batch</strong>)

<strong>Process tolerance</strong>

<strong>How “</strong>dirty” is the data? What do we do with <strong>“</strong><strong>dirty</strong><strong>”</strong> data? Drop it? Report it? Clean and reprocess it? Do I need to preserve ordering? <strong>Are</strong> there inherent <strong>time</strong> <strong>relationships</strong> in the <strong>messages</strong> that need to be preserved as they travel across the system? What message process warranty level do we require? At least once? At most once? Exactly once? The <strong>data shape</strong> will dictate <strong>capacity planning</strong>, <strong>tuning</strong> of the <strong>backbone</strong>, and <strong>scalability analysis</strong> for individual components. The <strong>output</strong> <strong>expectations</strong> will assist in the <strong>choice</strong> of <strong>processing</strong> <strong>engine</strong> while the <strong>process tolerance</strong> will add <strong>restrictions</strong> in <strong>terms</strong> of <strong>processing</strong> <strong>semantics</strong> and error handling. 2. Leverage the <strong>convergence</strong> of fast <strong><strong>data</strong></strong> and <strong>microservices</strong>
<strong>Fast</strong> <strong><strong>data</strong></strong> <strong>applications</strong> are, by <strong>nature</strong>, focused on a single task. They have a clear <strong>input</strong> and <strong>output definition</strong>, and often a schema as well. Wait. Are we describing fast data applications or microservices? There is a blurred <strong><strong>line</strong></strong> dividing the two, and <strong><strong>data</strong></strong> processing <strong><strong>libraries</strong></strong> such as <strong>Akka Streams</strong> and <strong>Kafka Streams</strong> make that <strong><strong>line</strong></strong> blur even more, as we can use these <strong><strong>libraries</strong></strong> to embed <strong><strong>data</strong></strong> processing <strong>capabilities</strong> in our microservices. We can think of <strong>combinations</strong> of data-processing <strong>applications</strong> with <strong>microservices</strong> to deliver specific <strong>features</strong> and <strong>insights</strong> from a data stream. For <strong>example</strong>, we can combine a <strong>machine</strong> learning <strong>job</strong> for anomaly <strong>detection</strong> with a <strong>dashboard</strong> that summarizes the <strong>findings</strong> to facilitate further investigation. From a <strong>project perspective</strong>, creating small, self-contained, <strong>data</strong>-driven <strong>applications</strong> that meld streaming <strong>data</strong> and <strong>microservices</strong> together is a good <strong>practice</strong> to break down large <strong>problems</strong> and <strong>projects</strong> into approachable <strong>chunks</strong>, reduce <strong>risk</strong>, and deliver value faster. 3. Get the <strong>message</strong> across
We discussed how fast <strong>data</strong> <strong>applications</strong> and <strong>microservices</strong> converge on the conceptual and executional levels. Another element they have in common is that they are both consuming and producing messages. A message-oriented <strong>implementation</strong> requires an efficient messaging <strong>backbone</strong> that facilitates the <strong>exchange</strong> of <strong>data</strong> in a reliable and secure <strong>way</strong> with the lowest latency possible. <strong>Apache Kafka</strong> is currently the leading <strong>project</strong> in this area. It delivers a publish/subscribe <strong>model</strong> backed by a distributed <strong>log implementation</strong> that provides <strong>dur<strong>ability</strong></strong>, <strong>resilience</strong>, <strong>fault tolerance</strong>, and the <strong>ability</strong> to replay <strong>messages</strong> by different consumers. The multi-subscriber <strong>approach</strong> creates the <strong>opportunity</strong> to reuse a single <strong>data stream</strong> for multiple <strong>consuming</strong> applications. 4. Leverage your <strong><strong>SQL</strong></strong> <strong>knowledge</strong>
We usually relate <strong><strong>SQL</strong></strong> to querying <strong>tables</strong> in relational databases. At first, it might seem odd to issue an <strong>SQL</strong> <strong>query</strong> on a <strong>stream</strong> of data. But what is a table? It’s a <strong>collection</strong> of <strong>records</strong> that were added, updated or deleted over time. We can see a <strong>table</strong> as an consolidated <strong>view</strong> of a <strong>stream</strong> of <strong>events</strong> over time. Likewise, we can create a <strong>stream</strong> from the observable <strong>changes</strong> applied to a <strong>table</strong>, reported as events. As <strong>Tyler Akiadu</strong>, from <strong>Google</strong>, explained in his <strong>Strata NY</strong> 2017 <strong>presentation</strong>, “<strong>Foundations</strong> of streaming <strong><strong>SQL</strong></strong><strong><strong>”</strong></strong>: “<strong>Streams</strong> are the in-motion <strong>form</strong> of <strong><strong>data</strong></strong>, both bounded and unbounded.<strong><strong>”</strong></strong> He goes further to explain how the relational <strong><strong>algebra</strong></strong> behind <strong><strong>SQL</strong></strong> can be applied to <strong>streams</strong> of <strong><strong>data</strong></strong> when we add <strong>time</strong> into the <strong><strong>algebra</strong></strong> in what he calls “<strong>time</strong>-varying relations.<strong><strong>”</strong></strong>
In 2016, <strong>Apache Spark</strong> introduced <strong>Structured Streaming</strong>, a new streaming <strong>engine</strong> based on the Spark<strong><strong>SQL</strong></strong> <strong>abstractions</strong> and run<strong>time</strong> optimizations. In the same <strong>year</strong>, <strong>Apache Flink</strong> announced streaming <strong>SQL</strong> support. More recently, <strong>Apache Kafka</strong> also introduced the <strong>KSQL</strong> <strong><strong>query</strong> engine</strong>, adding streaming <strong>query</strong> <strong>capabilities</strong> to the popular <strong>event</strong> back end. The <strong>adoption</strong> of fast <strong>data</strong> <strong>technologies</strong> is on a steep rise. The low-level <strong>streaming</strong> <strong>implementations</strong> of the mentioned <strong>engines</strong> require specialized <strong>knowledge</strong> in <strong>order</strong> to <strong>program</strong> new applications. The <strong>availability</strong> of <strong>SQL</strong> enables a <strong>wider range</strong> of <strong>professionals</strong> to participate in the <strong>development</strong> of streaming <strong><strong>data</strong> analytics pipelines</strong>, alleviating the skill <strong>shortage</strong> in the <strong>market</strong> and helping <strong>organizations</strong> to repurpose their <strong>workforces</strong> as they evolve in their <strong>fast</strong> <strong>data</strong> adoption. 5. Build on the <strong>shoulders</strong> of <strong>giants</strong>
As we mentioned at the <strong>beginning</strong>, we expect fast <strong>data</strong> <strong>applications</strong> to work reliably, continuously, and deliver <strong>results</strong> almost in near real time. These <strong>requirements</strong> impose strong <strong>scalability</strong> and <strong>resilience</strong> implications. Developing <strong>standalone</strong> <strong>applications</strong> that fulfill those <strong>requirements</strong> would be prohibitively expensive, as it would require specialized <strong>knowledge</strong> of distributed <strong><strong>systems</strong></strong>, operating <strong><strong>systems</strong></strong>, and <strong>networks</strong>, requiring large <strong>development</strong> and testing <strong>efforts</strong> to cover the <strong>complexity</strong> that distributed <strong>applications</strong> present. Instead, we build those <strong>applications</strong> on data-oriented <strong>frameworks</strong>, like <strong>Apache Spark</strong> and <strong>Apache Flink</strong>, or we resort to <strong>libraries</strong> that we can embed in our <strong>services</strong>, such as <strong>Kafka Streams</strong> and Akka Streams. These data-oriented <strong>stacks</strong> implement the low-level <strong>complexity</strong> and take <strong>care</strong> of the <strong>resilience</strong> of the application execution. In <strong>turn</strong>, they offer a high-level <strong>abstraction</strong> to enable <strong>developers</strong> to focus on delivering business value. To run our <strong>applications</strong>, we require computing <strong>system</strong> <strong>resources</strong> like <strong>CPU</strong>, <strong>memory</strong>, <strong>disk</strong>, and <strong>network bandwidth</strong> to be allocated to the critical <strong>data</strong> <strong>services</strong> that <strong>power</strong> the <strong>applications</strong>. When we work on a single <strong>machine</strong>, the <strong>operating system</strong> takes <strong>care</strong> of managing the <strong>resources</strong> allocated to applications. But when we run on a <strong>cluster</strong> of <strong>machines</strong>, how can we perform the <strong>resource management</strong> required by this new <strong>generation</strong> of distributed data-intensive applications? <strong>Cluster</strong> <strong>managers</strong>, such as <strong>Apache Mesos</strong>, are an <strong>abstraction</strong> that runs on <strong>top</strong> of any computing <strong>infrastructure</strong> (public/private <strong>cloud</strong>, <strong>VM</strong>, <strong>bare metal</strong>) to provide a single unified <strong>resource pool</strong> across multiple <strong>infrastructure</strong>s. <strong>Mesos</strong> achieves that <strong>unification</strong> by aggregating the <strong>infrastructure</strong> <strong>resources</strong>, and then offering <strong>resources</strong> slices, like <strong>x CPUs</strong>, <strong>y MB RAM</strong>, and <strong>z</strong> <strong>GB</strong> <strong>disk</strong>, to applications. <strong>Applications</strong> are then able to accept or reject those <strong>resources</strong> based on their own needs. <strong>Mesos</strong> can provide <strong>resources</strong> to execute <strong>applications</strong> and <strong>data services</strong> such as <strong>Apache Kafka</strong>, <strong>Apache Spark</strong>, and <strong>HDFS</strong>, or <strong>container</strong> <strong>schedulers</strong> such as Kubernetes. Deploying a <strong>cluster management solution</strong> like <strong><strong>Mesos</strong>phere DC/OS</strong> helps us take <strong>advantage</strong> of <strong>Mesos</strong> to deliver a complete fast-data <strong>platform</strong> by adding the <strong>deployment</strong> of standard <strong>components</strong>, providing a <strong>runtime</strong> for <strong>applications</strong> and delivering foundational <strong>services</strong> such as <strong>security</strong> and user management. It enables unbounded <strong>scalability</strong> as more <strong>commodity</strong> or specialized <strong>hardware</strong> can be seamlessly added to existing clusters. This <strong>results</strong> in increased <strong>enterprise agility</strong> as <strong>resources</strong> can be dynamically redirected to support the varying <strong>demands</strong> of different applications. Conclusion
Fast <strong>data</strong> <strong>applications</strong> are becoming a key <strong>asset</strong> for <strong>enterprises</strong> to adopt as they develop competitive <strong>advantages</strong> in a <strong>world</strong> where actionable <strong>insights</strong> need to be produced and consumed in real time. Building fast <strong>data</strong> <strong>architectures</strong> that deliver scalable and resilient <strong>real-time</strong> <strong>applications</strong> is a challenging undertaking. The five <strong>recommendations</strong> that we have collected in this <strong>post</strong> should help you in your <strong>journey</strong> from <strong>requirements</strong> <strong>capture</strong> to cluster-wide deployment. A successful <strong>implementation</strong> of the fast <strong>data architecture</strong> will give your <strong>business</strong> the <strong>ability</strong> to accelerate its data-driven <strong>innovation</strong> by creating an <strong>environment</strong> to dynamically create, <strong>deploy</strong>, and operate end-to-end data-intensive applications. In <strong>turn</strong>, you will gain increased competitive <strong>advantage</strong> and the <strong>agility</strong> to react to your specific <strong>market</strong> challenges. This <strong>post</strong> is a <strong>collaboration</strong> between <strong>O'Reilly</strong> and Mesosphere. See our statement of editorial independence. <strong>Continue</strong> reading 5 <strong>tips</strong> for architecting fast <strong>data</strong> applications.</body>
</html>