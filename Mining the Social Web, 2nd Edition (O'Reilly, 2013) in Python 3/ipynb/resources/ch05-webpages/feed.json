[
 {
  "title": "Returning to our senses",
  "content": "An introduction to how human senses can be incorporated into design principles.\nIf a Tree Falls in the Forest\u2026\nBRAZIL BEGAN USING SATELLITE imaging to monitor deforestation during the 1980s. This was the first large-scale, coordinated response to loggers and ranchers who had been illegally clearing the rainforests, and it worked, for a time. To avoid being spotted, loggers and ranchers began working more discreetly in smaller areas that were harder to detect (see Figure\u00a01-1).1 This required a new approach to monitoring the forests.\n\n\nFigure 1-1. A view powered by Google Earth Engine showing global deforestation\n\nGoogle Earth Engine and the Brazilian NGO, Imazon, worked together to create more powerful environmental monitoring capabilities. Their collaboration identified and mapped a much wider range of deforestation in much greater detail. With new analysis techniques for satellite imagery, they were able to classify forest topologies within the rainforest. This improved the accuracy of regional assessments, both for their contribution to the surrounding ecosystem and their vulnerability to human damage. They monitored the emergence of unofficial roads that marked new human activity. They modeled the environmental risks posed by agriculture, logging, and ranching to protected areas of the Amazon. They were also able to project future scenarios to help plan a more effective management strategy that balanced human land use with forest preservation.Continue reading Returning to our senses.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/YToqMoCVWTM/returning-to-our-senses"
 },
 {
  "title": "Techniques for designing to reduce risk",
  "content": "We need to plan for what we can't see and design for a wide range of user scenarios to avoid bad outcomes.Continue reading Techniques for designing to reduce risk.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Me83-jJY2r8/techniques-for-designing-to-reduce-risk"
 },
 {
  "title": "Wrapping an RxJS observable stream into an Angular service",
  "content": "How to create an injectable service that emits a stream of values, and a UI component that subscribes to this stream, displaying its values in real time.Angular\u2019s dependency injection mechanism allows us to cleanly separate business logic (services) from UI (components). What if our app generates a stream of values and we want to implement it as an injectable service? Here I\u2019ll show you how to create an injectable service that emits a stream of values, and a UI component that subscribes to this stream, displaying its values in real time.\nIn one of my RxJS blog posts, I showed how you would use the method Observable.create() providing an observer as an argument. Let\u2019s create a service with a method that will take an observer as an argument and emit the current time every second.\n\nimport {Observable} from 'rxjs/Observable';\n \nexport class ObservableService{\n \n  createObservableService(): Observable<Date>{  // 1\n \n      return new Observable(  // 2\n          observer => {   // 3\n              setInterval(() =>\n                  observer.next(new Date())  // 4\n              , 1000);\n          }\n      );\n  }\n}\n\n1. Return an observable stream of dates\n2. Create an observable\n3. Provide an observer\n4. Emit the new date every second\nIn this service, an instance of the RxJS Observable object is created, assuming that the subscriber will provide an Observer that knows what to do with the emitted data. Whenever the observable invokes the method next(new Date()) on the observer, the subscriber will receive the current date and time. The data stream never throws an error and never completes.\nIf you inject the ObservableService into the AppComponent, it invokes the method createObservableService() and subscribes to its stream of values, creating an observer that knows what to do with the data. The observer just assigns the received time to the variable currentTime which renders the time on UI.\n\nimport 'rxjs/add/operator/map';\nimport {Component} from \"@angular/core\";\nimport {ObservableService} from \"./observable.service\";\n \n@Component({\n  selector: 'app-root',\n  providers: [ ObservableService ],\n  template: `<h1>Custom observable service</h1>\n       Current time: mediumTime  // 1\n  `})\nexport class AppComponent {\n \n  currentTime: Date;\n \n  constructor(private observableService: ObservableService) { // 2\n \n    this.observableService.createObservableService()  // 3\n      .subscribe( data => this.currentTime = data );  // 4\n  }\n}\n\n1. Display the time using the date pipe\n2. Inject the service that wraps the observable\n3. Create the observable and start emitting dates\n4. Subscribe to the stream of dates\nThis app doesn\u2019t use any servers, and you can see it in action in the great Stackblitz online IDE.\nIn the browser\u2019s window, the current time will be updated every second. You use DatePipe here with the format 'mediumTime', which displays only hours, minutes, and seconds (all date formats are described in the DatePipe documentation).\nThis simple example demonstrates a basic technique for wrapping any application logic in an observable stream and subscribing to it. In this case, we use setInterval(), but you could replace it with any application-specific code that generates one or more values and sends them as a stream.\nDon\u2019t forget about error handling and completing the stream if need be. The following code snippet shows a sample observable that sends one element to the observer, may throw an error, and tells the observer that the streaming is complete:\n\nreturn new Observable(\n    observer => {\n      try {\n        observer.next('Hello from observable');\n \n        //throw (\"Got an error\");\n \n      } catch(err) {\n         observer.error(err);\n      } finally{\n         observer.complete();\n      }\n    }\n);\n\nIf you uncomment the line with a throw, observer.error() is invoked, which results in the invocation of the error handler on the subscriber if there is one.\nThe data producer for the observable stream was generating date/time, but it could be any app code that generates some useful values\u2014e.g., a WebSocket server generating stock quotes, auction bids, actions of online game players, etc. During workshops, I show a sample online auction app that has a Node server emulating users\u2019 bids on products. That server uses a WebSocket connection to push new bids for products to all users that are interested in receiving them.\nContinue reading Wrapping an RxJS observable stream into an Angular service.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/HXbFtolEng4/wrapping-an-rxjs-observable-stream-into-an-angular-service"
 },
 {
  "title": "Four short links: 27 April 2018",
  "content": "Automating Commerce, Faster Training, MacOS Monitoring, and Formal Methods\n\nDeath of A Supply-Driven World -- The company employs under a dozen engineers that built a technology stack that integrates the brand\u2019s planning, design, marketing and commerce systems into an all-knowing brain. If a shopper adds a product to the cart and then removes it, the brand knows and feeds this info back into its demand planning system. If a shopper returns one size and keeps another, this informs how the brand will reorder that product, if it does at all. All of this happens automatically, and while there are still humans making some decisions, the brand has no merchandising team. Most of its buying and planning is entirely automated.\n\n\nAccelerated Neuro-Evolution -- open source code that maximizes the use of CPUs and GPUs in parallel. It runs deep neural networks on the GPU, the domains (e.g. video games or physics simulators) on the CPU, and executes multiple evaluations in parallel in a batch, allowing all available hardware to be utilized efficiently. [...] [I]t also contains custom TensorFlow operations, which significantly improve training speed.\n\n\nMacOS Monitoring the Open Source Way -- interesting read about how Dropbox security team monitor the employee laptops to catch malware, using osquery for snapshots, Santa for real-time process events, and OpenBSM/Audit for real-time syscall monitoring.\n\nThe Great Theorem-Prover Showdown -- he chose three imperative programs with variable assignment, and challenged theorem prover Twitter to formally prove the code's correctness, with interesting results. My favourite sentence in the write-up is If the only result of this challenge is that Leftpad becomes the theorem prover\u2019s \u201chello world\u201d, I\u2019ll be pretty happy.\n\n\nNote: The email edition of Four Short Links will be discontinued on Monday, April 30. New editions of Four Short Links will still be published every weekday at oreilly.com/4sl and through the Four Short Links feed. Please send questions about this change to onlinecap@oreilly.com.\n\nContinue reading Four short links: 27 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/frUwN7wejng/four-short-links-27-april-2018"
 },
 {
  "title": "How to customize an Istio service mesh",
  "content": "Choose an Istio sidecar for reliability, observability, and security.Even though service meshes provide value outside of the use of microservices and containers, it's in these environments that many teams first consider using a service mesh. The sheer volume of services that must be managed on an individual, distributed basis with microservices (versus centrally for a monolith) creates challenges for ensuring reliability, observability, and security of these services.\nAdoption of a container orchestrator addresses a layer of infrastructure needs, but leaves some application or service-level needs unmet. Rather than attempting to overcome distributed systems concerns by writing infrastructure logic into application code, some teams choose to manage these challenges with a service mesh. A service mesh can help by ensuring the responsibility of service management is centralized, avoiding redundant instrumentation, and making observability ubiquitous and uniform across services.\nChoosing a service mesh\nFactors such as your teams\u2019 operational and technology expertise, existing observability, and access control tooling will influence the service mesh components, adapters, and deployment model you choose. Among others, Istio is a popularly adopted, open source service mesh. Some choose Istio (or any service mesh) for the automatic and immediate visibility it provides into top-line service metrics. In fact, many become hooked on service meshes for the observability they provide alone.\nAs a microservices platform, Istio is extensible through the way in which it offers choice of adapters and sidecars. Istio envelops and integrates with other open source projects to deliver a full-service mesh, which both bolsters its set of capabilities and offers a choice of which specific projects are included and deployed. Whether through Mixer adapters for observability or through swapping sidecars, Istio allows you to choose which components to include in your deployment.\nCustomizing an Istio service mesh\nThere are multiple deployment models you can use to lay down a service mesh. One of the most popular options is to deploy your service proxies as sidecars. Sidecarring your service proxy offers benefits like fine-grained policy enforcement and intra-cluster service-to-service encryption. This deployment model is the model of choice for Istio. Other Istio deployment choices include:\n\n\nMixer adapters: typically used for integrating with access control, telemetry, quota enforcement, and billing systems.\n\nService proxies: abstract the network, translating requests between a client and service.\n\nThough Envoy is the default service proxy sidecar, you may choose another service proxy for your sidecar. While there are multiple service proxies in the ecosystem, outside of Envoy, only two have currently demonstrated integration with Istio: Linkerd and NGINX. The arrival of choice in service proxies for Istio has generated a lot of excitement. Linkerd\u2019s integration was created early in Istio\u2019s 0.1.6 release. Similarly, the nginMesh project has drawn much interest in the use of NGINX as Istio\u2019s service proxy, as many organizations have broad and deep operational expertise built around this battle-tested proxy.\n\nLearn more about how to deploy your sidecar (Istio proxy) of choice in the free webcast \"Istio\u2014The extensible service mesh.\"\n\nThis post is a collaboration between O'Reilly and NGINX. See our statement of editorial independence.\nContinue reading How to customize an Istio service mesh.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/BZ75FEreSAU/how-to-customize-an-istio-service-mesh"
 },
 {
  "title": "Teaching and implementing data science and AI in the enterprise",
  "content": "The O\u2019Reilly Data Show Podcast: Jerry Overton on organizing data teams, agile experimentation, and the importance of ethics in data science.In this episode of the Data Show, I spoke with Jerry Overton, senior principal and distinguished technologist at DXC Technology. I wanted the perspective of someone who works across industries and with a variety of companies. I specifically wanted to explore the current state of data science and AI within companies and public sector agencies. As much as we talk about use cases, technologies, and algorithms, there are also important issues that practitioners like Overton need to address, including privacy, security, and ethics. Overton has long been involved in teaching and mentoring new data scientists, so we also discussed some tips and best practices he shares with new members of his team.Continue reading Teaching and implementing data science and AI in the enterprise.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/n8cBdBRINVA/teaching-and-implementing-data-science-and-ai-in-the-enterprise"
 },
 {
  "title": "Building tools for the AI applications of tomorrow",
  "content": "We\u2019re currently laying the foundation for future generations of AI applications, but we aren\u2019t there yet.For the last few years, AI has been almost synonymous with deep learning (DL). We\u2019ve seen AlphaGo touted as an example of deep learning. We\u2019ve seen deep learning used for naming paint colors (not very successfully), imitating Rembrandt and other great painters, and many other applications. Deep learning has been successful in part because, as Fran\u00e7ois Chollet tweeted, \u201cyou can achieve a surprising amount using only a small set of very basic techniques.\u201d In other words, you can accomplish things with deep learning that don\u2019t require you to become an AI expert. Deep learning\u2019s apparent simplicity--the small number of basic techniques you need to know--makes it much easier to \u201cdemocratize\u201d AI, to build a core of AI developers that don\u2019t have Ph.D.s in applied math or computer science.\nBut having said that, there\u2019s a deep problem with deep learning. As Ali Rahimi has argued, we can often get deep learning to work, but we aren\u2019t close to understanding how, when, or why it works: \u201cwe\u2019re equipping [new AI developers] with little more than folklore and pre-trained deep nets, then asking them to innovate. We can barely agree on the phenomena that we should be explaining away.\u201d Deep learning\u2019s successes are suggestive, but if we can\u2019t figure out why it works, its value as a tool is limited. We can build an army of deep learning developers, but that won\u2019t help much if all we can tell them is, \u201cHere are some tools. Try random stuff. Good luck.\u201d\nHowever, nothing is as simple as it seems. The best applications we\u2019ve seen to date have been hybrid systems. AlphaGo wasn\u2019t a pure deep learning engine; it incorporated Monte Carlo Tree Search, and at least two deep neural networks. At O\u2019Reilly\u2019s New York AI Conference in 2017, Josh Tenenbaum and David Ferrucci sketched out systems they are working on, systems that combine deep learning with other ideas and methods. Tenenbaum is working with one-shot learning, imitating the human ability to learn based on a single experience, and Ferrucci is working on building cognitive models that enable machines to understand human language in a meaningful way, not just pattern matching. DeepStack\u2019s poker playing system combines neural networks with counterfactual regret minimization and heuristic search.\nAdding structure to improve models\nThe fundamental idea behind deep learning is very simple: deep learning systems are neural networks with several hidden layers. Each neuron is very simple: it takes a number of inputs from previous layers, combines them according to a set of weights, and produces an output that\u2019s passed to the next layer. The network doesn\u2019t really care whether it\u2019s processing images, text, or telemetry. That simplicity, though, is a hint that we\u2019re missing out on a lot of structure that\u2019s inherent in data. Images and texts aren\u2019t the same; they\u2019re structured differently. Languages have a lot of internal structure. As the computational linguist Chris Manning says:\nI think the current era where everyone touts this mantra of fast GPUs, massive data, and these great deep learning algorithms has ... sent computational linguistics off-track. Because it is the case that if you have huge computation and massive amounts of data, you can do a lot ... with a simple learning device. But those learners are extremely bad learners. Human beings are extremely good learners. What we want to do is build AI devices that are also extremely good learners. ... The way to achieve those learners is to put much more innate structures.\nIf we\u2019re going to make AI applications that understand language as well as humans do, we will have to take advantage of the structures that are in language. From that standpoint, deep learning has been a fruitful dead end: it\u2019s a shortcut that has prevented us from asking the really important questions about how knowledge is structured. Gary Marcus makes an argument that\u2019s even more radical:\nThere is a whole world of possible innate mechanisms that AI researchers might profitably consider; simply presuming by default it is desirable to include little or no innate machinery seems, at best, close-minded. And, at worst, an unthinking commitment to relearning everything from scratch may be downright foolish, effectively putting each individual AI system in the position of having to recapitulate a large portion of a billion years of evolution.\nDeep learning began with a model that was, at least in principle, based on the human brain: the interconnection of neurons, and the ancient notion that human brains start out as a blank slate. Marcus is arguing that humans are born with innate abilities which are still very poorly understood--for example, the ability to learn language, or the ability to form abstractions. For AI to progress beyond deep learning, he suggests that researchers must learn how to model these innate abilities.\nThere are other paths forward. Ben Recht has written a series of posts sketching out how one might approach problems that fall under reinforcement learning. He is also concerned with the possibility that deep learning, as practiced today, promises more than it can deliver:\nIf you read Hacker News, you\u2019d think that deep reinforcement learning can be used to solve any problem. ... I personally get suspicious when audacious claims like this are thrown about in press releases, and I get even more suspicious when other researchers call into question their reproducibility.\nRecht argues for taking a comprehensive view, and reviews the possibility for augmenting reinforcement learning with techniques from optimal control and dynamical systems. This allows RL models to benefit from research results and techniques used in many real-world applications. He notes:\nBy throwing away models and knowledge, it is never clear if we can learn enough from a few instances and random seeds to generalize.\nAI is more than machine learning\nAs Michael Jordan pointed out in a recent post, what is called AI is often machine learning (ML). As someone who organizes AI conferences, I can attest to this: many of the proposals we receive are for standard machine learning applications. The confusion was inevitable: when calling a research project \u201cartificial intelligence\u201d was hardly respectable, we used the term \u201cmachine learning.\u201d ML became a shorthand for \u201cthe parts of AI that work.\u201d These parts, up to and including deep learning, were basically large-scale data analysis. Now that the tides of buzz have shifted, and everyone wants AI, machine learning applications are AI again.\nBut a full-fledged AI application, such as an autonomous vehicle, requires much more than data analysis. It will require progress in many areas that go well beyond pattern recognition. To build an autonomous vehicle and other true AI applications, we will need significant advances in sensors and other hardware; we will need to learn how to build software for \u201cedge devices,\u201d which includes understanding how to partition problems between the edge devices and some kind of \u201ccloud\u201d; we will need to develop infrastructure for simulation and distributed computation; and we will need to understand how to craft the user experience for truly intelligent devices.\nJordan highlights the need for further research in two important areas:\nIntelligence augmentation (IA): Tools that are designed to augment human intelligence and capabilities. These include search engines (which remember things we can\u2019t), automated translation, and even aids for artists and musicians. These tools might involve high-level reasoning and thought, though current implementations don\u2019t.\nIntelligent infrastructure (II): Jordan defines II as \u201ca web of computation, data, and physical entities exist that make human environments more supportive, interesting and safe.\u201d This would include networks to share medical data safely, systems to make transportation safer (including smart cars and smart roads), and many other applications. Intelligent infrastructure is about managing flows of data in ways that support human life.\nWhat\u2019s most important about Jordan\u2019s argument, though, is that we won\u2019t get either IA or II if we focus solely on deep learning. They are inherently multidisciplinary. Deep learning will inevitably be part of the solution, but just as inevitably, it won\u2019t be the whole solution. It may even be a very small part.\nClosing thoughts\nResearchers from many institutions are building tools for creating the AI applications of the future. While there is still a lot of work to be done on deep learning, researchers are looking well beyond DL to build the next generation of AI systems. UC Berkeley's RISE Lab has sketched out a research agenda that involves systems, architectures, and security.\nAmeet Talwalkar\u2019s recent post lists a number of research directions that should benefit industrial machine learning platforms. Industrial machine learning will have to meet system requirements, such as memory limitations, power budgets, and hard real time; they must be easy to deploy and to update, particularly since data models tend to grow stale over time; and they must be safe. Humans must understand how applications make decisions, along with the likely consequences of those decisions. These applications must take ethics into account.\nThese are all requirements for Jordan\u2019s intelligent infrastructure. Over the past few years, we\u2019ve seen many examples of machine learning put to questionable purposes, ranging from setting bail and determining prison sentences to targeted advertising, emotional manipulation, and the spreading of misinformation, that point us to a different set of needs. The research agenda for AI needs to take into account fairness and bias, transparency, privacy and user control over data, and the models built from that data. These issues encompass everything from ethics to design: getting informed consent, and explaining what that consent means, is not a trivial design problem. We\u2019re only starting to understand how these disciplines connect to research in artificial intelligence. Fortunately, we\u2019re seeing increasing interest within the data community in connecting ethics to practice. Events like the Data For Good Exchange (D4GX), the Conference on Fairness, Accountability, and Transparency (FAT*), and others are devoted to data ethics.\nTalwalkar notes that air travel didn\u2019t become commonplace until nearly 50 years after the Wright Brothers. While they were the first to achieve flight, many more developments were needed to make flying safe, inexpensive, and convenient. We\u2019re at a similar stage in the history of AI. We\u2019ve made progress in a few basic areas, and what we ultimately build will no doubt be amazing. We\u2019re currently laying the foundation for future generations of AI applications, but we aren\u2019t there yet.\nRelated content:\n\n\u201cToward the Jet Age of machine learning\u201d\n\u201cOpen-endedness: The last grand challenge you\u2019ve never heard of\u201d\n\n\"Language understanding remains one of AI\u2019s grand challenges\": David Ferrucci on the evolution of AI systems for language understanding\n\u201cThe machine learning paradox\u201d\n\u201cWe need to build machine learning tools to augment machine learning engineers\u201d\n\n\"Building and deploying large-scale machine learning pipelines\": Ben Recht on why we need primitives, pipeline synthesis tools, and most importantly, error analysis and verification.\n\n\"How to train and deploy deep learning at scale\": Ameet Talwalkar on large-scale machine learning\n\nContinue reading Building tools for the AI applications of tomorrow.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/e3rGotvDf9A/building-tools-for-the-ai-applications-of-tomorrow"
 },
 {
  "title": "Four short links: 26 April 2018",
  "content": "DNA for Data, Project Names, VGA SDR, and Image Magic\n\nExabytes in a Test Tube: The Case for DNA Data Storage -- still in its infancy, but researchers are drawn by high storage density (up to 1E12 GB/gram), unpowered, and durable in \"ideal\" conditions. There are even people working on random-access tech.\n\nWaggle Dance -- Hive federation service. Enables disparate tables to be concurrently accessed across multiple Hive deployments. (Hive is an Apache data warehouse project.) This easily wins today's award for Best Project Name. (Circus Train is a good name, but not as {fingerkiss} as Waggle Dance.\n\nVGA as SDR -- this is wild. osmo-fl2k allows you to use USB 3.0 to VGA adapters based on the Fresco Logic FL2000 chip, which are available for around $5, as general purpose DACs and SDR transmitter generating a continuous stream of samples by avoiding the HSYNC and VSYNC blanking intervals. Can transmit low-power FM, DAB, DVB-T, GSM, UMTS, and GPS signals.\n\n\nImage Inpainting for Irregular Holes Using Partial Convolutions -- the video is solid gold wow. (via NVIDIA developer news)\n\nNote: The email edition of Four Short Links will be discontinued on Monday, April 30. New editions of Four Short Links will still be published every weekday at oreilly.com/4sl and through the Four Short Links feed. Please send questions about this change to\u00a0onlinecap@oreilly.com.\n\nContinue reading Four short links: 26 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/TwyE7jrx8V8/four-short-links-26-april-2018"
 },
 {
  "title": "Four short links: 25 April 2018",
  "content": "Music Biz, Amazon DNS Hijack, Embedded Platform, and Tech Change\n\nMusic Industry's \"Fantastic 2017\" -- That $1.4 billion of growth puts the global total just below 2008 levels ($17.7 billion), meaning that the decline wrought through much of the last 10 years has been expunged. The recorded music business is locked firmly in growth mode, following nearly $1 billion growth in 2016. Cory Doctorow makes the point that while the \"music industry\" is booming, artist incomes aren't growing at the same rate. Or, indeed, at all.\n\nAmazon's DNS Hijacked For Two Hours -- in service of raiding a cryptocurrency website.\n\nNerves -- Pack your whole application into as little as 12MB and have it start in seconds by booting a lean cross-compiled Linux directly to the battle-hardened Erlang VM. Let Nerves take care of the network, discovery, I/O, firmware updates, and more. Focus on what matters, and have fun writing robust and maintainable software. Nifty approach to a very real problem.\n\nFive Things We Need to Know About Technological Change (Neil Postman) -- this is incredibly prescient and good. Technological change is not additive; it is ecological.[...] A new medium does not add something; it changes everything. In the year 1500, after the printing press was invented, you did not have old Europe plus the printing press. You had a different Europe. After television, America was not America plus television. Television gave a new coloration to every political campaign, to every home, to every school, to every church, to every industry, and so on. That is why we must be cautious about technological innovation. The consequences of technological change are always vast, often unpredictable, and largely irreversible. See also a related talk by Postman. (via Daniel G. Siegel)\n\nNote: The email edition of Four Short Links will be discontinued on Monday, April 30. New editions of Four Short Links will still be published every weekday at oreilly.com/4sl and through the Four Short Links feed. Please send questions about this change to onlinecap@oreilly.com.\n\nContinue reading Four short links: 25 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/gsxJX98XdjA/four-short-links-25-april-2018"
 },
 {
  "title": "Toward the Jet Age of machine learning",
  "content": "Solving the challenges of efficiency, automation, and safety will require cooperation between researchers and engineers spanning both academia and industry.Machine learning today resembles the dawn of aviation. In 1903, dramatic flights by the Wright brothers ushered in the Pioneer Age of aviation, and within a decade, there was widespread belief that powered flight would revolutionize transportation and society more generally. Machine learning (ML) today is also rapidly advancing. We have recently witnessed remarkable breakthroughs on important problems including image recognition, speech translation, and natural language processing, and major technology companies are investing billions of dollars to transform themselves into ML-centric organizations. There is a growing conviction that ML holds the key to some of society\u2019s most pressing problems.\nFigure 1. The Wright brothers\u2019 first powered airplane traveled 120 feet during its initial 12 second flight on December 17, 1903, at Kitty Hawk. Credit Stacy Pancake.\nHowever, this excitement should also be met with caution. For all the enthusiasm that the Wright brothers generated, nearly half a century would pass before widespread commercial aviation finally became a reality. During the Pioneer Age, aviation was largely restricted to private, sport, and military use. Getting to the Jet Age required a series of fundamental innovations in aeronautical engineering\u2014monoplane wings, aluminum designs, turbine engines, stress testing, jumbo jets, etc.\nFigure 2. Decades of advances in aeronautical engineering led to the Jet Age in the 1950s, which fundamentally changed societal behavior and enabled us to tackle new challenges\u2014e.g., space exploration. Credit: Stacy Pancake.\nSimply put, we needed to invent aeronautical engineering before we could transform the aviation industry. Similarly, we need to invent a new kind of engineering to build ML applications. Data-driven software development is radically different from conventional software development, as it targets complex applications domains (e.g., vision, speech, language) and focuses on learned behaviors instead of rule-based operations (e.g., training deep neural networks on massive data sets versus hand-coded if-then-else statements). Currently, very few organizations have the expertise to do this kind of engineering, and we are just scratching the surface of the potential for ML-powered technology. We describe three key challenges of this new development paradigm below.\nFigure 3. The turbine engine, developed over several decades, resulted in planes that were dramatically faster and more efficient, enabling travel around the world in less than a day. Credit: Stacy Pancake.\nChallenge 1: Efficiency\nModern ML applications typically involve complex models and massive data sets, requiring significant computational and storage resources. For instance, engineers at Google Brain needed more than 250,000 GPU hours to train a neural translation model for a single pair of languages (English and German), which costs about $200,000 on Google Compute Engine.[1] In response, a wide range of specialized hardware solutions are being developed (e.g., GPUs, TPUs, massively parallel CPUs, FPGAs) to improve the speed, energy efficiency, and cost of ML-powered applications.\nHowever, effectively leveraging heterogenous hardware will require us to fundamentally redesign ML software itself. In particular, systems-aware algorithms and software are needed (i) to efficiently train models on massively parallel and heterogeneous hardware, and (ii) to satisfy service level agreements (SLAs) related to latency, power consumption, and memory footprint constraints for production deployments. Advances in hardware must be closely coupled with algorithmic and software innovation in order to develop and deploy ML-based applications in a timely and economical fashion.\nFigure 4. Automation is widespread in modern commercial aviation, including plane manufacturing / testing, air traffic control, and even operating planes. Credit: Stacy Pancake.\nChallenge 2: Automation\nIn addition to being computationally intensive, ML-powered applications are incredibly labor-intensive for ML engineers to train, debug, and deploy. First, even selecting the appropriate computational platform is challenging, given the rapidly changing hardware landscape and diverse set of available cloud-based offerings. Second, the quality of an ML model is highly sensitive to hyperparameters; tuning these hyperparameters is crucial for accuracy but is often labor-intensive and expensive in computational cost. Third, utilizing parallel hardware at training time is highly non-trivial. Naively boosting computational power often does not result in meaningful speedups, and fair and effective sharing of cluster resources among users can be challenging.\nTo make things worse, developing ML applications is not a one-shot process: data changes over time, and therefore models and systems must adapt. Diagnosing and updating stale models is challenging, and exacerbated by the surprising difficulty (and sometimes impossibility[2]) of reproducing the behavior of ML applications. These issues are due to many factors, including (i) the statistical or \"fuzzy\" nature of these applications; (ii) the complexity of ML applications (e.g., pipeline jungles[3]); and (iii) ad-hoc development processes in which both code and data evolve over time with inadequate (and sometimes non-existent) controls. Given the shortage and cost of ML talent and the increased demands for ML technology, there is a pressing need to automate and simplify these development and deployment processes.\nFigure 5. The widespread adoption of commercial aviation hinged on dramatic advances in aviation safety, including advances in plane design and testing, as well as the creation of international and domestic regulatory bodies\u2014e.g., the ICAO and FAA. Credit: Stacy Pancake.\nChallenge 3: Safety\nAs ML applications become more ubiquitous and increasingly influence societal interactions (e.g., curating news, determining credit worthiness, influencing criminal sentencing, navigating vehicles autonomously), the safety risks associated with the misuse or misunderstanding of this technology are magnified. It is, thus, critical to understand and audit the behavior of ML applications: do we understand how models are making their decisions? What is the confidence / uncertainty associated with individual decisions? Do these predictions pose immediate threats to an individual or to society? What are the broader ethical ramifications of a given ML application? What information is being used to make decisions? Is individual privacy adequately being preserved?\nUnfortunately, ML applications do not provide us with straightforward answers to these questions. They are inherently data-driven and not based on simple rules, and we have a fundamental lack of understanding as to why leading ML approaches (e.g., deep learning models) even work in the first place. In addition to advancing our basic scientific understanding, it is paramount that we develop robust ML-centric engineering processes to mitigate potential safety risks. These new processes must address the complexity and uncertainty inherent to ML applications.\nThe interdisciplinary path forward\nThese challenges\u2014efficiency, automation, and safety\u2014won\u2019t be solved overnight. It is clear that they touch a broad set of disciplines, and consequently devising effective solutions will require cooperation between researchers and engineers spanning both academia and industry.\nFrom an academic perspective, we are already witnessing encouraging signs of interdisciplinary progress, as these core challenges have spurred the development of new research communities. Two notable examples are: (i) the SysML[4] research community that works at the intersection of systems and ML to design system-aware algorithms and identify best practices for learning systems; and (ii) the FatML[5] research community that brings together a diverse set of social and quantitative researchers and practitioners concerned with fairness, accountability, and transparency in ML.\nHowever, we ultimately want to move beyond academic research, and leverage cutting-edge theoretical advances in order to design and build increasingly robust and sophisticated engineering systems. To do so will require coordination between researchers working on more abstract and theoretical problems and engineers who understand industrial processes and real-world deployment requirements. While we have a long way to go before we arrive at the Jet Age of ML, continued collaborative efforts will truly enable ML to take flight.\n\n\n[1] Britz et al. Massive Exploration of Neural Machine Translation Architectures, Conference on Empirical Methods in Natural Language Processing, 2017. (Return)\n\n\n[2] For instance, various TensorFlow operations on GPUs or multi-threaded CPUs are known to be non-deterministic; see https://github.com/tensorflow/tensorflow/issues/3103 for more details. (Return)\n\n\n[3] Sculley et al. Hidden Technical Debt in Machine Learning Systems, Neural Information Processing Systems, 2015. (Return)\n\n\n[4] http://www.sysml.cc (Return)\n\n\n[5] https://fatconference.org (Return)\n\n\nRelated content:\n\n\n\"How to train and deploy deep learning at scale\": Ameet Talwalkar on large-scale machine learning.\n\nContinue reading Toward the Jet Age of machine learning.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/9CQRHiYLMr8/toward-the-jet-age-of-machine-learning"
 },
 {
  "title": "Four short links: 24 April 2018",
  "content": "IoT, Migrations, Prisoner's Dilemma, and Security\n\nIoT Inspector -- The Princeton University research team is digging into the traffic that IoT devices do, to identify malicious or otherwise dodgy behaviour. They want to know what IoT devices you have so they can test them. They'll release their packet capture and analysis tool as open source. (via BoingBoing)\n\nMigrations (Will Larson) -- very good explanation of how to manage migrations which are usually the only available avenue to make meaningful progress on technical debt. (via Simon Willison)\n\nBeating the Prisoner's Dilemma -- In 2013 as the semester ended in December, students in Fr\u00f6hlich\u2019s \"Intermediate Programming,\" \"Computer System Fundamentals,\" and \"Introduction to Programming for Scientists and Engineers\" classes decided to test the limits of the policy, and collectively planned to boycott the final. Because they all did, a zero was the highest score in each of the three classes, which, by the rules of Fr\u00f6hlich\u2019s curve, meant every student received an A. How did they manage to avoid defection? (If just one student sat the test, that person would get an A and everyone else fail) The students waited outside the rooms to make sure that others honored the boycott, and were poised to go in if someone [broke the pact]. No one did, though. Prisoner's Dilemma only works if the prisoners can't communicate. (via Freakonomics and Ian Miers)\n\nComputer Security: The Achilles' Heel of the Air Force? -- incredibly prescient 1979 article on the important problems of security. The stories of repeatedly improving early systems like GCOS and MULTICS are super-interesting and rich with parallels for today. A contract cannot provide security. Basically, the same GCOS system was selected for a major command and control system. Advocates assured the users that it would be made multilevel secure because security was required by the contract. An extensive tiger team evaluation found there were many deep and complex security flaws that defied practical repair\u2014the computer was finally deemed not only insecure but insecurable.\n\n\nNote: The email edition of Four Short Links will be discontinued on Monday, April 30. New editions of Four Short Links will still be published every weekday at oreilly.com/4sl and through the Four Short Links feed. Please send questions about this change to onlinecap@oreilly.com.\n\nContinue reading Four short links: 24 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/lSu48BGq_L4/four-short-links-24-april-2018"
 },
 {
  "title": "The Intertwingularity is near: When humans transcend print media",
  "content": "Both reproducible science and open source are necessary for collaboration at scale\u2014the nexus for that intermingling is Jupyter.(Apologies to Ray Kurzweil for the title puns)\nRecent one-day events showcased the Jupyter community in Boston and Atlanta, with another Jupyter Pop-up event coming on May 15 in Washington, D.C. At the same time, Project Jupyter has been in the news. We\u2019re finding overlap between the themes explored at these community events and recent articles written about Jupyter. That overlap, in turn, illustrates the kinds of dialog that we\u2019re looking forward to at JupyterCon this August.\nIn the news, notably there was the James Somers article, \u201cThe Scientific Paper Is Obsolete\u201d, in The Atlantic, and a subsequent piece, \u201cJupyter, Mathematica, and the Future of the Research Paper\u201d, by Paul Romer, former chief economist at the World Bank. Both articles compare and contrast between Wolfram Research\u2019s Mathematica and Project Jupyter. On the surface these two approaches both implement notebooks, with excellent examples coming from both communities. However, Paul Romer nailed the contrast between them with a one-liner: \u201cThe tie-breaker is social, not technical. The more I learn about the open source community, the more I trust its members.\u201d\nUnder the surface, the parallels end. Mathematica, which came first, is a popular commercial software product. Jupyter is an open standard for a suite of network protocols that support remote execution environments\u2014plus a spectrum of open source software projects that build extensible environments atop, such as JupyterLab, JupyterHub, Binder, etc. Organizations leverage Jupyter as a foundation for shared data infrastructure at scale. Organizational challenges emerge along with those implementations at scale: collaboration, discovery, security, compliance, privacy, ethics, provenance, etc. Through this open, community-centered approach, we get open standards, open source implementations, and open discussions about best practices for shared concerns.\nFor common threads between the two, James Somers\u2019 distillation is subtle: \u201cSoftware is a dynamic medium; paper isn\u2019t.\u201d It\u2019s been 27 years since the public debut of the World Wide Web, though we\u2019re still barely scratching the surface of what that invention made possible. Frankly, an overwhelming amount of \u201cdigital paper\u201d persists on the web. While the promise of WWW implies dynamic, interactive media shared across global infrastructure, questions linger about how best to make it happen. Some of those questions have also been in the news recently.\nRolling the clock back a few decades further, one gem on my bookshelf is Computer Lib/Dream Machines, by Ted Nelson, first published in 1974. Nelson explored hypertext, which he\u2019d been working to implement since 1963\u2014though, arguably, that notion traces back to Vannevar Bush and Jorge Luis Borges in the 1940s. To capture the essence of hypertext, Computer Lib also introduced the concept of \"intertwingularity\": complex interrelations within human knowledge. Nelson\u2019s vision had documents representing the world\u2019s knowledge, documents which could interact and intermingle. Borges prefigured a poetic glimpse of this in his 1941 short story, El jard\u00edn de senderos que se bifurcan: the legend of Ts\u2019ui P\u00ean constructing an infinite labyrinth, in which all would lose their way, along with a WWII espionage drama unfolding around that legend.\nOut of the many neologisms and one-liners that have attempted to describe Jupyter, intertwingularity nails it. One may \u201cperform science\u201d by authoring a research paper in a journal. That\u2019s science with a lowercase \u201cs,\u201d on paper or something approximating it\u2014merey navigating a single corner of Ts\u2019ui P\u00ean\u2019s labyrinth. Ted Nelson\u2019s vision, however, had documents interacting, intermingling. The practice of reproducible science, which is rapidly unfolding around Jupyter, also relies on documents interacting and intermingling. That opens the door to software as a dynamic medium, \"Science\" with an uppercase \u201cS.\u201d Not merely a library of \u201cdigital paper,\u201d but an entirely new way of collaborating, extending our understanding. Potentially as a map through the entire labyrinth.\nReproducible science via Jupyter finds immediate applications in many places. Certainly there are the \u201chard sciences\u201d: at JupyterCon, we\u2019ll have session talks ranging across astrophysics, quantum chemistry, genomics, geospatial analysis, climatology, and scientific computing in general. During the Jupyter Day Atlanta event, one excellent example was \u201cClassification and Characterization of Metal Powder in Additive Manufacturing using Convolutional Neural Networks,\u201d by Anna Smith from CMU.\nBeyond research, reproducible science is vital for any organization that depends on analysis\u2014and that forms Jupyter\u2019s direct link to data science. During the Jupyter Pop-up Boston event, Dave Stuart presented \u201cCitizen Data Science campaign,\u201d about an open source project called nbgallery, which thousands of DoD analysts use to discover and share Jupyter notebooks. While some teams have computational needs in common, they may not be allowed to share data. Similar data privacy concerns are encountered in finance, health care, social media, etc. The DoD project provides a fascinating approach to discovery (search, recommendations) for interactive content in highly regulated enterprise environments.\nIn Atlanta, two industry use cases addressed similar needs: Peter Parente from Valassis Digital with \u201cGive a Little Bit of Your Notebooks to Me\u201d\u2014also about sharing and discovering notebook content across an enterprise organization\u2014and John Patanian from General Electric with \u201cAchieving Reproducible and Deployable Data Science Workflows,\u201d about using templates for reproducible workflows.\n\nDave Stuart and Peter Parente will both be presenting at the Jupyter Pop-up D.C. event.\n\nSimilar efforts are changing the classroom. In Boston, we had Allen Downey, Taylor Martin, and Doug Blank join the \u201cJupyter in Education\u201d panel. In particular, reproducible science via Jupyter notebooks helps instructors manage the scaffolding needed to make course materials more engaging, more immediately hands-on, to give learners confidence and direct experience. Ryan Cooper from UConn presented \u201cFlipping the classroom with Jupyter and GitHub\u201d as a case study for this. In Atlanta, Carol Willing guided us through several excellent examples in \u201cSTEAM Workshops with Binder and JupyterHub.\u201d\n\nAt the D.C. event, we\u2019ll have Lorena Barba from GWU presenting \u201cFlipped Learning with Jupyter,\u201d and Laura Nor\u00e9n from NYU Center for Data Science presenting \u201cData Science in U.S. and Canadian Higher Education.\u201d\n\nAt a higher level of abstraction, reproducible science has an impact on computer science. In Boston, David Koop and Colin Brown from UMassD presented \u201cSupporting Reproducibility in Jupyter through Dataflows.\u201d Also, see a related project called Nodebook at Stitch Fix by Kevin Zielnicki. By default, cells in a Jupyter Notebook run from top to bottom\u2014although, a person needs to \u201cRun All\u201d to be sure that results are correct. The Dataflows and Nodebook projects track inputs and outputs for each cell so that notebooks can be guaranteed to \u201crerun\u201d successfully. The UMassD project also allows for rearranging cell order: for example, while you may need a long list of Python imports to initialize a notebook, why not move that cell to the end, so that the initial part of a notebook can jump directly into core code? On the one hand, that supports better scaffolding. On the other hand, these projects represent Jupyter Notebooks as dependency graphs, with pre- and post-conditions for each cell. That\u2019s only a few steps away from Petri nets and other automata used for formal analysis of computer programs, concurrency, business process, reliability engineering, security audits, etc. An imaginable next step could be to leverage machine learning to start generating unit tests\u2014and for code gen in general.\nHere\u2019s an intertwingled idea that weaves together most of the above. Generations of modern science have brought us to a point where reproducible science becomes a priority. Collaboration at a global scale can\u2019t proceed further without it. Meanwhile, open source software, since roughly 1998, has similarly evolved to support collaboration at a global scale, leading to standard practices such as versioning (e.g., git), testing, documentation, pull requests, etc. Most of those practices support reusability. Adding some DevOps, continuous integration/continuous deployment is the software analogy for reproducible science.\nWe\u2019re at a point where those two cultures, science and open source, have much to learn from each other. Science must learn to reuse and improve common software tools, while software must embrace reproducible science. Both are necessary for collaboration at scale. The nexus for that intermingling is Jupyter, where (and when) humans move beyond using digital mimics of print media to take better advantage of what software and collaboration promise in the long term.\n\nAt the D.C. event, Tony Fast will present \u201cA Notebook is a Hypothesis: Blending the paradigms of modern science and open source software.\u201d\n\nJoin us at Jupyter Pop-up D.C. on Tuesday, May 15, 2018, at the GWU Marvin Center, from 9:00 a.m. to 5:00 p.m. We\u2019ll have a mix of talks from government, industry, and education about Jupyter, along with a lot of opportunities for networking. It\u2019s a great preview for what\u2019s to come at JupyterCon, August 21-24, 2018, in New York City.\nContinue reading The Intertwingularity is near: When humans transcend print media.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/aVwQuI6UP9M/the-intertwingularity-is-near-when-humans-transcend-print-media"
 },
 {
  "title": "Four short links: 23 April 2018",
  "content": "Metrics and Incentives, Facebook as Fire Starter, Meeting Mastery, and Weird Chart Types\n\nHeart Surgeons Avoid Difficult Operations to Avoid Poor Performance Rankings -- Just under one-third of the 115 specialists who responded said they had recommended a different treatment path to avoid adding another death to their score. And 84% said they were aware of other surgeons doing the same.  Reminds me of MySociety's hard-learned lessons with their MP scorecard, whereby MPs would ask pointless questions in Parliament just to get their numbers up.\n\nWhen Countries are Tinderboxes, and Facebook is a Match (NYT) -- where institutions are weak or undeveloped, Facebook\u2019s newsfeed can inadvertently amplify dangerous tendencies. Designed to maximize user time on site, it promotes whatever wins the most attention. Posts that tap into negative, primal emotions like anger or fear, studies have found, produce the highest engagement, and so proliferate. Plenty of horrifying examples of lynchings and riots triggered by Facebook posts.\n\nReflections (Matt Webb) -- Much of any founder's time will be spent meeting advisors and investors. There's a knack to running the room and getting what you want out of it, while maintaining a feeling of collaboration and conversation. Meetings aren't just time you spend in a room together. Meetings are an atomic unit of work. They should have purpose and outcomes, although these don't necessarily need to be stated. There are a lot of small ways to make sure attendees don't drift or feel lost. Really fascinating notes about how he coaches his founders through the incubator program.\n\nXeno.graphics -- weird but (sometimes) useful charts.\n\n\nCheck out the \"Strata Business Summit\" sessions at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 23 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/M5YUFmfQwEM/four-short-links-23-april-2018"
 },
 {
  "title": "Traits you\u2019ll find in good managers",
  "content": "Work with your manager to get what you need, when you need it.Continue reading Traits you\u2019ll find in good managers.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/zAeTD0PQ-TQ/traits-youll-find-in-good-managers"
 },
 {
  "title": "Four short links: 20 April 2018",
  "content": "Functional Programming, High-Dimensional Data, Games and Datavis, and Container Management\n\nInterview with Simon Peyton-Jones -- I had always assumed that the more bleeding-edge changes to the type system, things like type-level functions, generalized algebraic data types (GADTs), higher rank polymorphism, and existential data types, would be picked up and used enthusiastically by Ph.D. students in search of a topic, but not really used much in industry. But in fact, it turns out that people in companies are using some of these still-not-terribly-stable extensions. I think it's because people in companies are writing software that they want to still be able to maintain and modify in five years time. SPJ is the creator of Haskell, and one of the leading thinkers in functional programming.\n\nHyperTools -- A Python toolbox for visualizing and manipulating high-dimensional data. Open source. High-dimensional = \"a lot of columns in each row\".\n\nWhat Videogames Have to Teach Us About Data Visualization -- super-interesting exploration of space, storytelling, structure, and annotations.\n\nTitus -- Netflix open-sourced their container management platform. There aren't many companies with the scale problems of Amazon, Netflix, Google, etc., so it's always interesting to see what comes out of them.\n\n\nCheck out the Evolutionary Architecture sessions at OSCON, July 16-19, 2018, in Portland. Hurry\u2014best price ends April 20.\n\nContinue reading Four short links: 20 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3CzPcc_aOe4/four-short-links-20-april-2018"
 },
 {
  "title": "Thinking beyond bots: How AI can drive social impact",
  "content": "A few ways to think differently and integrate innovation and AI into your company's altruistic pursuits.What do artificial intelligence (AI), invention, and social good have in common? While on the surface they serve very different purposes, at their core, they all require you to do one thing in order to be successful at them: think differently.\nTake the act of inventing\u2014in order to develop a great patent, trade secret, or other intellectual property, you need to think outside of the box. Similarly, at the heart of AI is the act of unlocking new capabilities, whether that\u2019s making virtual personal assistants like Alexa more useful, or creating a chatbot that provides a personalized experience to customers. And because of the constantly changing economic and social landscapes, coming up with impactful social good initiatives requires you to constantly approach things through a new lens.\nIndividually, these fields have seen notable advancements over the past year, including new technologies that are bringing improvements to AI and large companies that are prioritizing giving back. But even more exciting is that we\u2019re seeing more and more business leaders and nonprofits combining AI, innovation, and social good to reach communities in innovative ways, at a scale we\u2019ve never before seen.\nThere\u2019s no better time than now to explore how your organization approaches your social good efforts. Here are a few ways you can think differently and integrate innovation and AI into your company\u2019s altruistic pursuits.\nApproach social good through the mind of an inventor\nAs a master inventor at IBM, I\u2019m part of the team responsible for helping the company become the leading recipient of U.S. patents for the last quarter century. While developing patents and intellectual properties might not be what you\u2019re setting out to do as part of your humanitarian efforts, the way we approach our jobs as inventors is something that can be applied across all aspects of giving back. Consider the United Nations\u2019 17 Sustainable Development Goals, which aim to eradicate things like poverty, hunger, disease, and more. These are game-changing initiatives that definitely require new ideas. What\u2019s more, the United Nations estimates that we\u2019re $5 trillion short on resources needed to accomplish these goals. How do we bridge this gap? Well, we need to start thinking differently.\nFoundationally, coming up with a great invention is identifying a problem that needs to be solved and coming up with an out-of-the-box idea that\u2019s smart, has the biggest impact, and the lowest risk. To do this, we look around us to see which relevant technologies we can use that are already at our disposal so we don\u2019t have to completely reinvent the wheel if we don\u2019t have to. We also identify which parts of the solution need a completely new idea to be created from scratch. Additionally, we look at the issue we\u2019re trying to solve and the current landscape as a whole so we can predict any issues or future problems that may arise, and we try to address them ahead of time in our invention.\nThe same approach should be applied to social good\u2014identify the problem you want to solve, the tools that already exist that can help you solve this dilemma, and the resources that need to be created or brought in from outside properties in order to execute your plan. At the heart of social good, similar to most inventions, are the people you\u2019re trying to help. You need to make sure you\u2019re maximizing the reach of your project while also minimizing any risks that may unintentionally create additional problems for the people you\u2019re trying to help. To do this, you need to be creative in your approach.\nAs an example, this is exactly the approach InvestEd is taking (full disclosure: I am an advisor for InvestEd). They started off by realizing they could commercialize and create social good at the same time by enabling financial education and facilitating microloans for small businesses in emerging markets. Helping these small businesses grow added more value to the small, local communities. And to make their product even better, InvestEd is adding AI capabilities to widen their offerings and provide a more innovative user experience.\nAI: Unlocking new capabilities\nTo grab the value and create disruptive AI technology for social good ideas, we have to think beyond the typical automation activities of a machine. Take Guiding Eyes, for example, which is using AI to discover the secrets behind successful guide dogs. By taking advantage of natural language processing (NLP) on structured and unstructured data, the system they\u2019re using is trained to find correlations to successful dogs among genetic, health, temperament, and environmental factors\u2014and the technology continues to learn and get better. By using AI, Guiding Eyes has seen a 10% increase in guide dog graduation rates, helping the organization meet the growing demand for guide dogs.\nThere are many other examples of AI being used for the betterment of society. For example, PAWS is an organization that uses machine learning to predict where poachers may strike, or Dr. Eric Elster, who worked with the Walter Reed National Military Medical Center to apply machine learning techniques to improve the treatment of U.S. service members injured in combat.\nBest practices for getting started\nThese are a just a few ideas for how AI can be used for social good\u2014 there are still plenty of opportunities out there. The challenge is how to get started, so here are three best practices I\u2019d like to share to help people who want to embark on this journey.\n\nFirst, build your understanding of what AI is and is not through great online learning, such as Intro to Artificial Intelligence, led by Peter Norvig and Sebastian Thrun, on Udacity.\nSecond, think differently. AI is a different computing model. Instead of thinking about use cases and scenarios, really focus on the problem you want to solve. Think more \u201cideal scenario\u201d on how to best develop a solution, and then see if a machine can be trained to do this work. Let\u2019s consider personalized education, particularly reading comprehension (which has shown to have a tremendous impact on a child\u2019s long-term educational performance across all subjects). With a traditional use case approach, we would probably try to develop a general framework that would help in a handful of scenarios. Now, Learning Ovations has thought about the more ideal scenario. They have realized there are too many possible scenarios to program or for a general framework to even cover. Instead, they\u2019re training AI to assess each child\u2019s performance (across traditional metrics and some new ones) as a tool for educators and parents. In addition, they\u2019re creating an AI-powered recommendation engine based on each individual school\u2019s curriculum to provide another tool for educators to create a customized reading program for each student. Thus, Learning Ovations thought differently on how to personalized education.\nThird, set aside preconceived notions. There are things that people are better than machines at doing, but there are things machines are better than people at doing\u2014some of which may be surprising. For example, people seem to be more honest in sharing health or financial information with a machine than a person because they don\u2019t worry about being judged. This typically means the machine gets more accurate data to provide recommendations. Thus, recognizing that a machine might be as capable in some areas could unlock whole new capabilities.\n\nWhen it comes to AI, invention, and social good, the possibilities are endless. Technology will only continue to become more advanced, creating new opportunities to fix societal problems related to health, sustainability, conservation, accessibility, and much more. If you\u2019re thinking of jumping into AI for good, just remember the most important rule: think differently.\nContinue reading Thinking beyond bots: How AI can drive social impact.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/BXie2iEFXRE/thinking-beyond-bots-how-ai-can-drive-social-impact"
 },
 {
  "title": "5 best practices for delivering design critiques",
  "content": "Real critique helps teams strengthen their designs, products, and services.Continue reading 5 best practices for delivering design critiques.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/jbPvrGd1a_M/5-best-practices-for-delivering-design-critiques"
 },
 {
  "title": "How to run a custom version of Spark on hosted Kubernetes",
  "content": "Learn how Spark 2.3.0+ integrates with K8s clusters on Google Cloud and Azure.Do you want to try out a new version of Apache Spark without waiting around for the entire release process? Does running alpha-quality software sound like fun? Does setting up a test cluster sound like work? This is the blog post for you, my friend! We will help you deploy code that hasn't even been reviewed yet (if that is the adventure you seek). If you\u2019re a little cautious, reading this might sound like a bad idea, and often it is, but it can be a great way to ensure that a PR really fixes your bug, or the new proposed Spark release doesn\u2019t break anything you depend on (and if it does, you can raise the alarm). This post will help you try out new (2.3.0+) and custom versions of Spark on Google/Azure with Kubernetes. Just don't run this in production without a backup and a very fancy support contract for when things go sideways.\nNote: This is a cross-vendor post (Azure's Spark on AKS and Google Cloud's Custom Spark on GKE), each of which have their own vendor-specific posts if that\u2019s more your thing.\nWarning: it\u2019s important to make sure your tests don\u2019t destroy your real data, so consider using a sub-account with lesser permissions.\nSetting up your version of Spark to run\nIf there is an off-the-shelf version of Spark you want to run, you can go ahead and download it. If you want to try out a specific patch, you can checkout the pull request to your local machine with git fetch origin pull/ID/head:BRANCHNAME, where ID is the PR number, and then follow the directions to build Spark (remember to include the -P components you want/need, including your cluster manager of choice).\nNow that we\u2019ve got Spark built, we will build a container image and upload it to the registry of your choice, like shipping a PXE boot image in the early 90s (bear with me, I miss the 90s).\nDepending on which registry you want to use, you\u2019ll need to point both the build tool and spark-submit in the correct location. We can do this with an environment variable\u2014for Docker Hub, this is the name of the registry; for Azure Container Registry (ACR), this value is the ACR login server name; and for Google Container Registry, this is gcr.io/$PROJECTNAME.\nexport REGISTRY=value\nFor Google cloud users who want to use the Google-provided Docker registry, you will need to set up Docker to run through gcloud. In the bash shell, you can do this with an alias:\nshopt -s expand_aliases && alias docker=\"gcloud docker --\"\nFor Azure users who want to use Azure Container Registry (ACR), you will need to grant Azure Container Service (AKS) cluster read access to the ACR resource.\nFor non-Google users, you don\u2019t need to wrap the Docker command, and just skip that step and keep going:\n\r\nexport DOCKER_REPO=$REGISTRY/spark\r\nexport SPARK_VERSION=`git rev-parse HEAD`\r\n./bin/docker-image-tool.sh -r $DOCKER_REPO -t $SPARK_VERSION build\r\n./bin/docker-image-tool.sh -r $DOCKER_REPO -t $SPARK_VERSION push\r\n\nBuilding your Spark project for deployment (or, optionally, starting a new one)\nSpark on K8s does not automatically handle pushing JARs to a distributed file system, so we will need to upload whatever JARs our project requires to work. One of the easiest ways to do this is to turn our Spark project into an assembly JAR.\nIf you\u2019re starting a new project and you have sbt installed, you can use the Spark template project:\nsbt new holdenk/sparkProjectTemplate.g8\nIf you have an existing SBT-based project, you can add the sbt-assembly plugin:\n\r\ntouch project/assembly.sbt\r\necho 'addSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"0.14.6\")' >> project/assembly.sbt\r\n\nWith SBT, once you have the SBT assembly plugin (either through creating a project with it included in the template or adding it to an existing one), you can produce an assembly JAR by running:\nsbt assembly\nThe resulting JAR not only will have your source code, but all of the requirements as well. Note that this JAR may have multiple entry points, so later on, we\u2019re going to need to tell Spark submit about the entry point we want it to use. For the world standard wordcount example, we might use:\nexport CLASS_NAME=org.apache.spark.examples.JavaWordCount\nIf you have a maven or other project, there are a few different options for building assembly JARs. Sometimes, these may be referred to as \u201cfat jars\u201d in the documentation.\nIf starting a new project sounds like too much work and you really just want to double check that your Spark on K8s deployment works, you can use the example JAR that Spark ships with (e.g., examples/target/spark-examples).\nUploading your JARs\nOne of the differences between Spark on K8s and Spark in the other cluster managers is that there is no automatic tool to distribute our JARs (or other job dependencies). To make sure your containers have access to your JAR, the fastest option is normally to upload it.\nRegardless of platform, we need to specify which JAR, container / bucket, and the target:\n\r\nexport FOLDER_NAME=mybucket\r\nexport SRCJAR=target/scala-2.11/...\r\nexport MYJAR=myjar\r\n\nWith Azure:\n\r\nRESOURCE_GROUP=sparkdemo\r\nSTORAGE_ACCT=sparkdemo$RANDOM\r\naz group create --name $RESOURCE_GROUP --location eastus\r\naz storage account create --resource-group $RESOURCE_GROUP --name $STORAGE_ACCT --sku Standard_LRS\r\nexport AZURE_STORAGE_CONNECTION_STRING=`az storage account show-connection-string --resource-group $RESOURCE_GROUP --name $STORAGE_ACCT -o tsv`\r\naz storage container create --name $FOLDER_NAME\r\naz storage container set-permission --name $FOLDER_NAME --public-access blob\r\naz storage blob upload --container-name $FOLDER_NAME --file $SRCJAR --name $MYJAR\r\n\nWith Google Cloud:\ngsutil cp $SRCJAR gs://$JARBUCKETNAME/$MYJAR\nFor now though, we don\u2019t have the JARs installed to access the GCS or Azure blob storage, and Spark on K8s doesn\u2019t currently support spark-packages, which we could use to access those, so we need to make our JAR accessible over http.\nWith Azure:\nJAR_URL=$(az storage blob url --container-name $FOLDER_NAME --name $MYJAR | tr -d '\"')\nWith Google Cloud:\nexport PROJECTNAME=boos-demo-projects-are-rad\r\ngcloud iam service-accounts create signer --display-name \"signer\"\r\ngcloud projects add-iam-policy-binding $PROJECTNAME --member serviceAccount:signer@$PROJECTNAME.iam.gserviceaccount.com --role roles/storage.objectViewer\r\ngcloud iam service-accounts keys create     ~/key.json     --iam-account signer@$PROJECTNAME.iam.gserviceaccount.com\r\nexport JAR_URL=`gsutil signurl -m GET ~/key.json gs://$JARBUCKETNAME/$MYJAR | cut  -f 4 | tail -n 1`\r\n\nStarting your cluster\nNow you are ready to kick off your super-fancy K8s Spark cluster.\nFor Azure:\n\r\naz group create --name mySparkCluster --location eastus\r\naz aks create --resource-group mySparkCluster --name mySparkCluster --node-vm-size Standard_D3_v2\r\naz aks get-credentials --resource-group mySparkCluster --name mySparkCluster\r\nkubectl proxy &\r\n\nFor Google cloud:\n\r\ngcloud container clusters create  mySparkCluster --zone us-east1-b --project $PROJECTNAME\r\ngcloud container clusters get-credentials mySparkCluster --zone us-east1-b --project $PROJECTNAME\r\nkubectl proxy &\r\n\nOn Google Cloud, before we kick off our Spark job, we need to make a service account for Spark that will have permission to edit the cluster:\n\r\nkubectl create serviceaccount spark\r\nkubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default\r\n\nRunning your Spark job\nAnd now we can finally run our Spark job:\n\r\n./bin/spark-submit --master k8s://http://127.0.0.1:8001  \\\r\n  --deploy-mode cluster --conf \\\r\n spark.kubernetes.container.image=$DOCKER_REPO/spark:$SPARK_VERSION \\\r\n--conf spark.executor.instances=1 \\\r\n--class $CLASS_NAME \\\r\n--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\\r\n--name wordcount \\\r\n$JAR_URL \\\r\ninputpath\r\n\nAnd we can verify the output with:\nkubectl logs [podname-from-spark-submit]\nHandling dependencies in Spark K8s (and accessing your data/code without making it public):\nWhat if we want to directly read our JARs from the storage engine without using https? Or if we have dependencies that we don\u2019t want to package in our assembly JARs? In that case, can the necessary dependencies to our docker file as follows:\n\r\nmkdir /tmp/build && echo \u201cFROM $DOCKER_REPO/spark:$SPARK_VERSION\r\n\r\n# Manually update Guava deleting the old JAR to ensure we don\u2019t have class path conflicts\r\nRUN rm \\$SPARK_HOME/jars/guava-14.0.1.jar\r\nADD http://central.maven.org/maven2/com/google/guava/guava/23.0/guava-23.0.jar \\$SPARK_HOME/jars\r\n# Add the GCS connectors\r\nADD https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar \\$SPARK_HOME/jars\r\n# Add the Azure Hadoop/Storage JARs\r\nADD http://central.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.0/hadoop-azure-2.7.0.jar\r\nADD http://central.maven.org/maven2/com/microsoft/azure/azure-storage/7.0.0/azure-storage-7.0.0.jar\r\n\r\nENTRYPOINT [ '/opt/entrypoint.sh' ]\u201d > /tmp/build/dockerfile\r\ndocker build -t $DOCKER_REPO/spark:$SPARK_VERSION-with-deps -f /tmp/build/dockerfile /tmp/build\r\n\r\nPush to our registry:\r\n\r\ndocker push $DOCKER_REPO/spark:$SPARK_VERSION-with-deps\r\n\nFor Azure folks wanting to launch using Azure Storage rather than https:\n\r\nexport JAR_URL=wasbs://$FOLDER_NAME@$STORAGE_ACCT.blob.core.windows.net/$MYJAR\r\n\nFor Google folks wanting to launch using GCS rather than https:\nexport JAR_URL=gs://$JARBUCKETNAME/$MYJAR\nAnd then run the same spark-submit as shown previously.\nWrapping up\nNotably, each vendor has a more detailed guide to running Spark jobs on hosted K8s focused on their own platforms (e.g., Azure\u2019s guide, Google\u2019s guide, etc.), but hopefully this cross-vendor version shows you the relative portability between the different hosted K8s engines and our respective APIs with Spark. If you\u2019re interested in helping join in Spark code reviews, you can see the contributing guide and also watch Karau\u2019s past streamed code reviews on YouTube (and subscribe to her YouTube or Twitch channels for new livestreams). You can also follow the authors on their respective Twitter accounts: Alena Hall and Holden Karau.\nContinue reading How to run a custom version of Spark on hosted Kubernetes.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/86Q45ikq5BE/how-to-run-a-custom-version-of-spark-on-hosted-kubernetes"
 },
 {
  "title": "Four short links: 19 April 2018",
  "content": "Free Multics, Community Relevance, Speech Synthesis, and Dandelion Data\n\nBAN.AI Multics -- free multiuser Multics (predecessor to Unix) emulation. This Multics guide will be useful.\n\nThe Art of Relevance -- explores how mission-driven organizations can matter more to more people. The book is packed with inspiring examples, rags-to-relevance case studies, research-based frameworks, and practical advice on how your work can be more vital to your community. Should be read by startups (relevant to your customers?) and anyone who is trying to build a community around their software. Text available for free online, print versions still available for purchase.\n\nVoiceLoop: Voice Fitting and Synthesis via a Phonological Loop -- We present a new neural text to speech (TTS) method that is able to transform text to speech in voices that are sampled in the wild. Unlike other systems, our solution is able to deal with unconstrained voice samples and without requiring aligned phonemes or linguistic features. The Presidential voices are impressive. Code and paper available.\n\nNo Boundaries for Facebook Data -- Today we report yet another type of surreptitious data collection by third-party scripts that we discovered: the exfiltration of personal identifiers from websites through \u201clogin with Facebook\u201d and other such social login APIs. Specifically, we found two types of vulnerabilities: seven third parties abuse websites\u2019 access to Facebook user data; one third party uses its own Facebook \u201capplication\u201d to track users around the web.\n\n\n\nCheck out the \"Emerging technologies and case studies\" sessions at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 19 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ye_WK_vX2oY/four-short-links-19-april-2018"
 },
 {
  "title": "Four short links: 18 April 2018",
  "content": "Open Source Slack-alike, Open Source MailChimp-alike, DeepFake PSA, and Secure Devices\n\nZulip -- FOSS Slack-type chat.\n\nMailtrain -- self-hosted GPLv3 MailChimp-style newsletter service that you can hook up to your favorite mail service (e.g., Mailgun).\n\nFake News PSA -- DeepFake video of Barack Obama saying things that Obama never said (made for Buzzfeed).\n\nSeven Properties of Highly Secure Devices (Microsoft) -- Hardware-based root of trust; small trusted computing base; defense in depth; compartmentalization; certificate-based authentication; renewable security; failure reporting.\n\n\n\nCheck out the \"Impact of AI on Business and Society\" sessions at the AI Conference in New York, April 29-May 2, 2018.\n\nContinue reading Four short links: 18 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/6Zwqwy8dli4/four-short-links-18-april-2018"
 },
 {
  "title": "From USENET to Facebook: The second time as farce",
  "content": "Demanding and building a social network that serves us and enables free speech, rather than serving a business metric that amplifies noise, is the way to end the farce.Re-interpreting Hegel, Marx said that everything in history happens twice, the first time as tragedy, the second as farce. That\u2019s a fitting summary of Facebook\u2019s Very Bad Month. There\u2019s nothing here we haven\u2019t seen before, nothing about abuse, trolling, racism, spam, porn, and even bots that hasn\u2019t already happened. This time as farce? Certainly Zuckerberg\u2019s 14-year Apology Tour, as Zeynep Tufecki calls it, has the look and feel of a farce. He just can\u2019t stop apologizing for Facebook\u2019s messes.\nExcept that the farce isn\u2019t over yet. We\u2019re in the middle of it. As Tufekci points out, 2018 isn\u2019t the first time Zuckerberg has said \u201cwe blew it, we\u2019ll do better.\u201d Apology has been a roughly biennial occurrence since Facebook\u2019s earliest days. So, the question we face is simple: how do we bring this sad history to an endpoint that isn\u2019t farce? The third time around, should there be one, it isn\u2019t even farce; it\u2019s just stupidity. We don\u2019t have to accept future apologies, whether they come from Zuck or some other network magnate, as inevitable.\nI want to think about what we can learn from the forerunners of modern social networks\u2014specifically about USENET, the proto-internet of the 1980s and 90s. (The same observations probably apply to BBSs, though I\u2019m less familiar with them.) USENET was a decentralized and unmanaged system that allowed Unix users to exchange \u201cposts\u201d by sending them to hundreds of newsgroups. It started in the early 80s, peaked sometime around 1995, and arguably ended as tragedy (though it went out with a whimper, not a bang).\nAs a no-holds-barred Wild West sort of social network, USENET was filled with everything we rightly complain about today. It was easy to troll and be abusive; all too many participants did it for fun. Most groups were eventually flooded by spam, long before spam became a problem for email. Much of that spam distributed pornography or pirated software (\u201cwarez\u201d). You could certainly find newsgroups in which to express your inner neo-Nazi or white supremacist self. Fake news? We had that; we had malicious answers to technical questions that would get new users to trash their systems. And yes, there were bots; that technology isn\u2019t as new as we\u2019d like to think.\nBut there was a big divide on USENET between moderated and unmoderated newsgroups. Posts to moderated newsgroups had to be approved by a human moderator before they were pushed to the rest of the network. Moderated groups were much less prone to abuse. They weren\u2019t immune, certainly, but moderated groups remained virtual places where discussion was mostly civilized, and where you could get questions answered. Unmoderated newsgroups were always spam-filled and frequently abusive, and the alt.* newsgroups, which could be created by anyone, for any reason, matched anything we have now for bad behavior.\nSo, the first thing we should learn from USENET is the importance of moderation. Fully human moderation at Facebook scale is impossible. With seven billion pieces of content shared per day, even a million moderators would have to scan seven thousand posts each: roughly 4 seconds per post. But we don\u2019t need to rely on human moderation. After USENET\u2019s decline, research showed that it was possible to classify users as newbies, helpers, leaders, trolls, or flamers, purely by their communications patterns\u2014with only minimal help from the content. This could be the basis for automated moderation assistants that kick suspicious posts over to human moderators, who would then have the final word. Whether automated or human, moderators prevent many of the bad posts from being made in the first place. It\u2019s no fun being a troll if you can\u2019t get through to your victims.\nAutomated moderation can also do fact checking. The technology that won Jeopardy a decade ago is more than capable of checking basic facts. It might not be capable of checking complex logic, but most \u201cfake news\u201d centers around facts that can easily be evaluated. And automated systems are very capable of detecting bots: Google\u2019s Gmail has successfully throttled spam.\nWhat else can we learn from USENET? Trolls were everywhere, but the really obnoxious stuff stayed where it was supposed to be. I\u2019m not naive enough to think that neo-Nazis and white supremacists will dry up and go away, on Facebook or elsewhere. And I\u2019m even content to allow them to have their own Facebook pages: Facebook can let these people talk to each other all they want, because they\u2019re going to do that anyway, whatever tools you put in place. The problem we have now is that Facebook\u2019s engagement metric paves the road to their door. Once you give someone a hit of something titillating, they\u2019ll come back for more. And the next hit has to be stronger. That\u2019s how you keep people engaged, and that\u2019s (as Tufekci has argued about YouTube) how you radicalize them.\nUSENET had no engagement metrics, no means of linking users to stronger content. Islands of hatred certainly existed. But in a network that didn\u2019t optimize for engagement, hate groups didn\u2019t spread. Neo-Nazis and their like were certainly there, but you had to search them out, you weren\u2019t pushed to them. The platform didn\u2019t lead you there, trying to maximize your \u201cengagement.\u201d I can\u2019t claim that was some sort of brilliant design on USENET\u2019s part; it just wasn\u2019t something anyone thought about at the time. And as a free service, there was a need to maximize profit. Facebook\u2019s obsession with engagement is ultimately more dangerous than their sloppy handling of personal data. \u201cEngagement\u201d allows\u2014indeed, encourages\u2014hate groups to metastasize.\nEngagement metrics harm free speech, another ideal carried to the modern internet from the USENET world. But in an \u201cattention economy,\u201d where the limiting factor is attention, not speech, we have to rethink what those values mean. I\u2019ve said that USENET ended in a \u201cwhimper\u201d\u2014but what drained the energy away? The participants who contributed real value just got tired of wading through the spam and fighting off the trolls. They went elsewhere. USENET\u2019s history gives us a warning: good speech was crowded off the stage by bad speech.\nSpeech that exists to crowd out other speech isn\u2019t the unfettered interchange of ideas. Free speech doesn\u2019t mean the right to a platform. Indeed, the U.S. Constitution already makes that distinction: \u201cfreedom of the press\u201d is about platforms, and you don\u2019t get freedom of the press unless you have a press. Again, Zeynep Tufekci has it: in \u201cIt\u2019s the (Democracy-Poisoning) Golden Age of Free Speech,\u201d she writes \u201cThe most effective forms of censorship today involve meddling with trust and attention, not muzzling speech itself.\u201d Censorship isn\u2019t about arresting dissidents; it\u2019s about generating so much noise that voices you don\u2019t like can\u2019t be heard.\nIf we\u2019re to put an end to the farce, we need to understand what it means to enable speech, rather than to drown it out. Abandoning \u201cengagement\u201d is part of the solution. We will be better served by a network that, like USENET, doesn\u2019t care how people engage, and that allows them to make their own connections. Automated moderation can be a tool that makes room for speech, particularly if we can take advantage of communication patterns to moderate those whose primary goal is to be the loudest voice.\nMarx certainly would have laid blame at the feet of Zuckerberg, for naively and profitably commoditizing the social identities of his users. But blame is not a solution. As convenient a punching bag as Zuckerberg is, we have to recognize that Facebook\u2019s problems extend to the entire social world. That includes Twitter and YouTube, many other social networks past and present, and many networks that are neither online nor social. Expecting Zuck to \u201cfix Facebook\u201d may be the best way to guarantee that the farce plays on.\nHistory is only deterministic in hindsight, and it doesn\u2019t have to end in farce (or worse). We all build our social networks, and Mark Zuckerberg isn\u2019t the only player on history\u2019s stage. We need to revisit, reassess, and learn from all of our past social networks. Demanding and building a social network that serves us and enables free speech, rather than serving a business metric that amplifies noise, is the way to end the farce.\nIs that a revolution? We have nothing to lose but our chains.\nContinue reading From USENET to Facebook: The second time as farce.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/AwGHYMGH7dg/from-usenet-to-facebook-the-second-time-as-farce"
 },
 {
  "title": "Four short links: 17 April 2018",
  "content": "Dubsteganography, Parsing History, Hackin' the Jack In, and Model Bias\n\nHide Data in Dubstep Drops -- the blog post shows how to use it. Skrillex meets steganography!\n\nParsing Timeline -- wonderfully detailed, yet it reads almost chatty. Interesting and informative.\n\nSecuring Wireless Neurostimulators -- a hack and discussion of the risk of insecure implantable medical devices that interface with the brain. (via Paper a Day)\n\nText Embedding Models Contain Bias (Google) -- great to see this making its way to research outputs, instead of being the province of damage control and bad PR. The Developers section of the Semantic Experiences microsite talks about \"unwanted associations\": In Semantris, the list of words we're showing are hand curated and reviewed. To the extent possible, we've excluded topics and entities that we think particularly invite unwanted associations, or can easily complement them as inputs. In Talk to Books, while we can't manually vet each sentence of 100,000 volumes, we use a popularity measure which increases the proportion of volumes that are published by professional publishing houses. There are additional measures that could be taken. For example, a toxicity classifier or sensitive topics classifier could determine when the input or the output is something that may be objectionable or party to an unwanted association. We recommend taking bias-impact mitigation steps when crafting end-user applications built with these models.\n\n\n\nCheck out the \"Law, ethics, and governance\" sessions at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 17 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/o0BAi-S-2pw/four-short-links-17-april-2018"
 },
 {
  "title": "Relato: Turking the business graph",
  "content": "A failed analytics startup post-mortem.In order to conquer a market, you must first understand it. We often speak of markets in the abstract, as addressable segments of the economy, defining them by examples of companies and by comparisons to others engaged in similar activities. Sales and marketing leaders have richer internal models of markets they use to guide their organizations as they fight for their share of the markets they contest. In January 2015, I set out to build an external representation of a market every bit as rich as those in the minds of leading executives driving successful companies; I founded an analytics startup called Relato\u2014a startup that, unfortunately, did not succeed. In this post, I\u2019ll present the story of the company and the work I did there, the entrepreneurship and network science involved in my work, and some insight into how not to run a young analytics startup, and a little about how to do so as well.\nMy mission with Relato was to build a deeper understanding of the modern networked economy, a vast network in which companies are best defined according to their business relationships with other companies. When it comes to understanding companies, it\u2019s \u201cwho you know.\u201d These relationships translate to connections in the business graph, made up of connections between customer, partner, competitor, and investor.\nMission: Mapping markets\nI started Relato with an experiment to see how much market intelligence I could gather from the business web. Having worked at LinkedIn, I missed their social graph. I wondered, \u201cCould a copy of the business graph be collected from the open web?\u201d The answer to that research question is what led me to found Relato.\nI started by surveying the state of the market for data on companies. I discovered that while basic firmographic data was available\u2014things like address, industry code, website technologies\u2014there was nothing that captured the actual business activity of companies. By contrast, when I surveyed the websites of businesses, I found a treasure trove of information about their business relationships with other companies. Starting with a market I knew\u2014big data\u2014I manually transcribed the partnership pages of the major players: Hortonworks, Cloudera, MapR, and Pivotal. The combined list came to hundreds of companies\u2014not a bad survey of the big data market.\nFigure 1. Where it all started: Hortonworks\u2019 partnership page. Screenshot by Russell Jurney.\nI saw opportunity! I could transcribe the companies listed on partnership pages to learn how companies actually did business. Then I could use graph analytics on this data to extract next-generation profiles on companies. This data could be used in lead scoring and lead generation systems to provide a breakthrough in their level of performance. In short, I could provide leads for enterprise customers that would convert to sales at a rate never before seen! I got excited. What if sales calls only came to people who wanted your product, because Relato told you so? I could optimize the economy and change the world! I was inspired.\nI figured out roughly how I could collect this data using natural language processing, an area that I know a little bit about but is not one of my core skills. Building this model and making it good enough to be saleable would take at least a year. I did not have a year of cash to burn in the bank. Fortunately, there was a faster alternative.\nThere was a shift in \u201cbig data\u201d to hybrid human/machine processing, where humans located in places where wages are low would perform many instances of simple tasks to cheaply create data sets for machine learning systems. Using this method, there would ultimately be a higher cost per record collected because I would be paying real humans wages, but the up-front cost in development time was much lower. This way, I could get started much faster, shipping a beta product to customers using money from angel investors instead of venture capitalists.\nFigure 2. A slide from our first deck on human/machine hybrid data processing. Image by Russell Jurney.\nMost data scientists use application programing interfaces (APIs) like Amazon\u2019s Mechanical Turk to automate delegating data processing tasks to humans. Rather than using an API, I built a data collection web application that was used by people I actually got to know: \u201cmechanical Turks\u201d I hired on a website called UpWork. They would transcribe partnership pages and enter them into a database using an application that did things like autocomplete company names to ensure the data was clean and consistent. If the page had thousands of partnerships, I automated the collection process using utilities I developed to extract the names and domains of companies.\nThe system worked beautifully, and the workers became good at their jobs. I would spot check their work, offering corrections. Instead, they often corrected me! There is truly a wealth of talent available from underemployed individuals in areas of the world with less opportunity than we enjoy in the Bay Area. They are talented and hardworking, and you can get great work humanely\u2014if you treat them with the respect they deserve\u2014rather than as human computers at the other end of an API.\nFigure 3. The Relato data collection system. Image by Russell Jurney.\nData in hand, I developed algorithms using a graph database to calculate metrics describing the way companies worked together. I started by basing Relato\u2019s lead scoring system on data from several commercial APIs to ensure my model had everything my competitors used. Then I added to the model the features I derived from the partnership graph. It worked! The accuracy of the model increased dramatically. I knew I was on to something when the model indicated that the partnership centrality, a graph metric, was by far the most important feature determining lead scoring accuracy. It was even more important than the 650-area code (Silicon Valley) for a company selling to technology startups! Relato was off to a good start, algorithmically at least. This became a slide in our pitch deck (see Figure 4).\nFigure 4. A slide from Relato\u2019s deck on the efficacy of partnership data in lead scoring. Image by Russell Jurney.\nLead generation: Minting hot leads\nRelato built two things: a lead generation system for B2B sales, and MarketMaps, a business graph visualization tool. A lead scoring system is just a predictive model for inbound business contacts, scoring them by how likely they are to become customers. A lead generation system adds a database already populated with a \u201cuniverse\u201d full of contacts, plus a lot of plumbing to shuffle the data through the system, through the algorithms and back out to the customer. In goes a current customer list, out go recommended leads.\nThe idea of algorithmic lead generation is to take a database of business contacts representing the entire world of business and select those few \u201chot leads\u201d for a specific company that will convert into real customers. In the process, this generates a ton of value. If you can pull this off, it\u2019s a good business model\u2014see Figure 5, which describes the price amplification as contacts travel through the marketing funnel on their way to becoming sales. Contacts sell for a fraction of a dollar. Good leads sell for $50 to as much as $500. That makes a lot of room for profit!\nFigure 5. Minting leads and dollars using graph analytics. Image by Russell Jurney.\nFigure 6 shows the marketing funnel itself for a business-to-business (B2B) company with a $4 million marketing budget. At the top of the funnel, contacts for a person sell for a fraction of a dollar. The sale of lead lists is still a thriving market, although the accuracy of the contact information varies greatly.\nIt takes many leads in the top of the funnel to result in one sale at the bottom. In this case, we\u2019ll need 80,000 responses from contacts to meet our revenue goal. A response would be opening or clicking on a link in an email or coming to the website from a web search.\nFigure 6. A B2B sales and marketing funnel for a B2B company with a sales goal of $10 million, a marketing budget of $4 million and a sale price of $100K. Image by Russell Jurney.\nThe next step in the funnel is a marketing qualified lead (MQL). A lead becomes an MQL when an analysis of the lead\u2019s behavior determines the lead is likely enough to buy that they merit attention from a real person. MQLs for enterprise companies go for about $50 a piece. Marketo and other marketing automation systems calculate a lead score based on a lead\u2019s behavior, such as when they interact with your website (10 points!) or download a white paper (50 points!). When the score becomes high enough, contact is made by a lead qualifier. A lead qualifier is a junior salesperson who makes initial sales contacts by phone and email. The problem with marketing automation systems is that the scoring algorithm is usually arbitrary. As a result, there is widespread dissatisfaction in the results generated by the large investments enterprises have made in marketing automation over the last decade. This is what drives the lead scoring market.\nPredictive lead scoring systems substitute machine learning for manual behavioral analysis to optimize the lead scoring algorithm. They replace arbitrary lead scores with artificial intelligence. Lead scoring systems then become a black box within the marketing funnel that uses past results (sales) to score future leads. Firmographic data or data characterizing a business is limited, so behavior is the primary training data for these systems, which work better than marketing automation alone. These systems have return on investment (ROI), but so far, this has turned out to be an iterative improvement that has not revolutionized sales and marketing.\nThe next step in the marketing funnel is a sales qualified lead (SQL). A lead becomes an SQL when a live, in-person salesperson has spoken to the person behind the potential lead, and through conversation has determined they are a good fit for the company\u2019s product. Top salespeople are fed SQLs from junior salespeople and they use their extensive skills to build relationships and close deals. The lead funnel has side branches: a good senior salesperson will also do his or her own lead generation, often bringing a rolodex from job to job, selling different products to the same contacts over and over.\nFor B2B sales, it is necessary to pour a lot of contacts (200 in our slide in Figure 6) into the sales and marketing funnel to generate a single sale. Most leads fail to mature to the next level at each level of the funnel. Relato\u2019s mission was ambitious: to skip levels in the sales and marketing funnel, in order to mint contacts directly into leads every bit as good as sales qualified leads. Many other lead generation companies have attempted this task, but none that I could find used anything like Relato\u2019s business graph to do so.\nIn the next post, we\u2019ll talk more about the products I built at Relato, and where I went wrong in steering the business.\nContinue reading Relato: Turking the business graph.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/QkT3gevXwkg/relato-turking-the-business-graph"
 },
 {
  "title": "The eight rules of good documentation",
  "content": "Like good code, good documentation is difficult and time consuming to write.Imagine for a moment two common scenarios in the life of a web developer.\nIn the first scenario, meet Harlow. Today is Harlow's first day on a new project. The team has a well-established codebase, a great working environment, and a robust test suite. As Harlow sits down at her desk, she's excited to get up to speed with the team. After the morning stand-up meeting she's pointed to the project's documentation for installation with a slight grimace from her colleague Riley. He mentions that the docs \"might be a little out of date, but should hopefully be enough to get you going.\" Harlow then spends the rest of the day following the documentation until she gets stuck, at which point she is forced to dig through code or ask colleagues for guidance. What might have taken a few minutes becomes a day-long exercise in frustration, tampering Harlow's initial excitement.\nIn the second scenario, meet Harrison. He's working on a web app and finds a library that, at first glance, seems incredibly useful for his project. As he attempts to integrate it with his codebase he discovers that parts of the API seem to be glossed over in the documentation or even undocumented. In the end, he walks away from the project in favor of another solution.\nThough these scenarios may be slightly exaggerated, I'm reasonably certain that many of us can relate. These problems were not primarily caused by low-quality code, but rather by poor documentation.\nIf useful documentation is so important to the success of projects and developer well-being, why don't all projects have it? The answer, I believe, is that like good code, good documentation is difficult and time consuming to write.\nIn my eyes, there are eight rules that we can follow to produce good documentation:\n\nWrite documentation that is inviting and clear\nWrite documentation that is comprehensive, detailing all aspects of the project\nWrite documentation that is skimmable\nWrite documentation that offers examples of how to use the software\nWrite documentation that has repetition, when useful\nWrite documentation that is up-to-date\nWrite documentation that is easy to contribute to\nWrite documentation that is easy to find\n\nThe most important rule of good documentation is for it to be as inviting as possible. This means that we should aim to write it in the clearest terms possible without skipping over any steps. We should avoid making assumptions about what our users may know. Sometimes this can seem to be overkill, and we may be tempted to say something like \"every X developer knows about Y,\" but we each bring our own background and set of experiences to a project. Though this may result in more verbose documentation, it is ultimately simpler, as there is less guesswork involved for developers with all levels of experience.\nDocumentation should aim to be comprehensive. This means that all aspects of the project are documented. Undocumented features or exceptions can lead to frustration and become a time suck as users and other developers are forced to read through code to find the answers they need. Fully documenting all features takes away this kind of ambiguity.\nWhen we write documentation that is skimmable, we help users find the content they need quickly. Making documentation skimmable can be accomplished by using clear headings, bulleted lists, and links. For large project documentation, a table of contents or clear navigation will help users to skip straight to what they need, rather than scrolling through a single long document.\nDocumentation that features examples allows users to see how they might use the code themselves. Aim to provide examples of the most common use cases for the project, while letting the comprehensive documentation detail every possibility.\nIt is perfectly acceptable to include some repetition in  documentation, which the Write the Docs project terms \"ARID\" (accepts (some) repetition in documentation). Doing so acknowledges that users may not read the full docs or that some information is relevant in multiple places in the documentation. While good code may be DRY, good writing aims to be clear, and sometimes this means repeating ourselves. The Write the Docs project calls out the difference between writing that is ARID, DRY, and WET in this way:\nThe pursuit of minimizing repetition remains valiant! ARID does not mean WET, hence the word choice. It means: try to keep things as DRY as possible, but also recognize that you\u2019ll inevitably need some amount of \u201cmoisture\u201d to produce documentation.\nEffective documentation is kept up-to-date. This is surprisingly challenging. We may begin our project with the best of intentions and great documentation, but as our software evolves and we are quickly iterating, it can be easy to fall out of step. If you are working as part of an agile development team, I recommend adding documentation to your team's \"definition of done.\" For independent projects, try to treat documentation as an important final step.\nDocumentation that is easy to contribute to is also easy to keep up-to-date. The simplest way to make documentation easy to contribute to is to treat it as code, storing it as text in source control. The site and book Docs Like Code advocates for treating our docs like our code by using source control, automating builds, and applying software development tools and techniques to our documentation practices.\nDocumentation is only as helpful as it is easy to find. Keeping an updated README file and linking to more extensive documentation at the top of the README when necessary helps to keep discoverability simple.\nI hope these guidelines are useful as you draft your project's documentation. Sometimes it is helpful to remember that documentation isn't just for other developers, but often for our future selves as well. When we return to a project after a number of months, we will appreciate the work we put into clear and up-to-date documentation.\nContinue reading The eight rules of good documentation.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/eX305rPUBmg/the-eight-rules-of-good-documentation"
 },
 {
  "title": "Stephen Gates on the growing risks posed by malicious bots",
  "content": "The O\u2019Reilly Podcast: Protecting your organization against current and future threats.In this episode of the O\u2019Reilly podcast, I spoke with Stephen Gates of Oracle Dyn. Gates joined the Oracle Dyn Global Business Unit from Zenedge, the web application security company recently acquired by Oracle. Gates and I discussed how growing malicious bot activity impacts organizations.\n\nHere are some highlights:\nThe rise of malicious bots\n\nOne of the factors driving the current proliferation of malicious bots is the Mirai malware. It works by using a list of default usernames and passwords (from previous data breaches) to take control of IoT devices. One key differentiator with Mirai is that it\u2019s self-propagating\u2014each infected device has the ability to scan the internet to find similar devices and subsequently infect them. This has also spurred other self-propagating, copycat malware.\nAnother key factor driving malicious bot growth is the increase in malware that focuses on exploiting vulnerabilities (versus relying on usernames and passwords). The malware automates the process of scanning and infecting IoT devices for known vulnerabilities. Then, they're exploiting those known software vulnerabilities, which are quite common in IoT devices. The volume of attack traffic these devices can generate is a huge differentiator because many of these devices have access to pretty sizeable CPUs, and they've got access to a lot of bandwidth. As a result, we're seeing DDoS attacks being launched by these botnets in excess of 1.5 terabits per second. That's enough traffic to take a small country offline.\n\nMitigating malicious bot threats\n\nTo manage the risks malicious bots pose, organizations need to be aware that, realistically, bots represent a significant portion of site and application traffic. They must understand the threats against their specific business models and recognize the need to build systems that can differentiate between good bot traffic, bad bot traffic, and human activity. Sites and applications must allow good bots to continue performing critical activities (scrape data for Google search queries, for example), but also mitigate malicious bot activity. Done poorly, you could reduce the effectiveness of your SEO, or worse yet, block paying customers from your sites or applications.\nAn effective DDoS incident response plan includes detection and mitigation of these bot-driven attacks. Defenses should be layered, including cloud-based defenses for volumetric attacks, and most likely web application firewalls for the more measured attacks. Without having a DDoS response plan in place, you\u2019re a sitting duck and effectively just waiting for one of these attacks to take your organization offline.\n\nPreparing for the malicious bot attacks of the future\nThe malicious bot threat landscape will continue to evolve rapidly. To prepare, organizations must embrace advanced data capabilities, such as AI and supervised machine learning, to detect and defeat sophisticated malicious bot attacks. Additionally, businesses need to focus on hiring security intelligence analysts. Embracing AI and machine learning is only helpful if we have the capabilities to analyze the output. Accordingly, security analyst skills will be in very high demand.\nThis post is a collaboration between O'Reilly and Oracle Dyn. See our statement of editorial independence.\nContinue reading Stephen Gates on the growing risks posed by malicious bots.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Tz2Uj3LxvxM/stephen-gates-on-the-growing-risks-posed-by-malicious-bots"
 },
 {
  "title": "Simon Moss on using artificial intelligence to fight financial crimes",
  "content": "Innovations that increase detection of, and response to, criminal attacks of financial systems.In this episode of the O\u2019Reilly Podcast, I talk with Simon Moss, vice president of industry consulting and solutions, Americas, at Teradata. We discuss how machine learning and deep learning techniques are being used to fight financial crimes, such as credit card fraud, identity theft, health care fraud, and money laundering.\n\nDiscussion points:\n\nMoss says AI techniques are \u201ca new set of weapons\u201d against perpetrators of financial crime. \u201cIf we use them right, we can finally at least slow down the constant tide of financial crime.\u201d\nAI can be more effective than traditional methods of combatting identity fraud, health care fraud, and money laundering, because for those issues, he explains, \u201cyou\u2019re not looking for a needle in a haystack. You\u2019re looking for a needle in a stack of needles. You are trying to find individuals whose nefarious activity is disguised and hidden in pure normality, by completely innocuous activity.\u201d\nMoss compares the use of machine learning techniques to a rules engine: \u201ca rules engine looks for behaviors that have already happened, whereas machine learning is trying to connect different bread crumbs. It\u2019s running multiple scenarios at the same time to try to look at the problem from multiple different angles.\u201d\nMachine learning can add efficiency to the detection process: \u201cIt can take multiple data sources, map the data to a case, analyze it, and then in seconds, make a decision on whether it\u2019s a false positive, whether it\u2019s normal business activity, whether it\u2019s something that needs further investigation, or whether it is outright criminality,\u201d Moss says.\n\nOther links:\n\n\nThink Big Analytics, the consulting division of Teradata\n\nMoss\u2019 recent LinkedIn article on the fight against money laundering\n\nThis post is a collaboration between Teradata and O\u2019Reilly. See our statement of editorial independence.\nContinue reading Simon Moss on using artificial intelligence to fight financial crimes.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Z9wOokDjPqw/simon-moss-on-using-artificial-intelligence-to-fight-financial-crimes"
 },
 {
  "title": "Four short links: 16 April 2018",
  "content": "Light-Powered Camera, Government Blogging, TensorFlow.js, and Metanotation\n\nLight-Powered Camera -- prototype gets 15 frames/second, no external power. The light is used for both image sensing and solar power.\n\nGovernment Blogs and Government Bloggers (Public Strategist) -- the blogging spectrum 2x2 is solid and explains why government blogs are often about prototypes, not operations.\n\nIntroducing TensorFlow.js -- an open source library you can use to define, train, and run machine learning models entirely in the browser, using Javascript and a high-level layers API.\n\n\nIt's Time for a New Old Programming Language (YouTube) -- Guy L. Steele Jr.'s talk about the Computer Science Metanotation that CS papers use to indicate programs without having to use a specific programming language. This is one for your inner CS meta-nerd.\n\n\nCheck out the \"Data Science & Machine Learning\" sessions\u00a0at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 16 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/gGC3adn_Fzw/four-short-links-16-april-2018"
 },
 {
  "title": "Four short links: 13 April 2018",
  "content": "Compositing, Exfiltrating, Listening, and Munging\n\nDeep Painterly Harmonisation -- composite and preserve the style of the destination image. The examples are impressive.\n\nPowerHammer: Exfiltrate Data Over Power Lines -- In this case, a malicious code running on a compromised computer can control the power consumption of the system by intentionally regulating the CPU utilization. Data is modulated, encoded, and transmitted on top of the current flow fluctuations, and then it is conducted and propagated through the power lines.\n\n\nLearn To Listen At The Cocktail Party -- We present a joint audio-visual model for isolating a single speech signal from a mixture of sounds such as other speakers and background noise. Solving this task using only audio as input is extremely challenging and does not provide an association of the separated speech signals with speakers in the video. In this paper, we present a deep network-based model that incorporates both visual and auditory signals to solve this task. The visual features are used to \"focus\" the audio on desired speakers in a scene and to improve the speech separation quality.\n\n\nprototool -- a Swiss Army Knife for protocol buffers.\n\n\nCheck out the \"Data Science & Machine Learning\" sessions\u00a0at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 13 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/SmyvsxSzbVg/four-short-links-13-april-2018"
 },
 {
  "title": "Jupyter is where humans and data science intersect",
  "content": "Discover how data-driven organizations are using Jupyter to analyze data, share insights, and foster practices for dynamic, reproducible data science.I'm grateful to join Fernando P\u00e9rez and Brian Granger as a program co-chair for JupyterCon 2018. Project Jupyter, NumFOCUS, and O'Reilly Media will present the second annual JupyterCon in New York City August 21\u201325, 2018.\nTiming for this event couldn't be better. The human side of data science, machine learning/AI, and scientific computing is more important than ever. This is seen in the broad adoption of data-driven decision-making in human organizations of all kinds, the increasing importance of human centered design in tools for working with data, the urgency for better data insights in the face of complex socioeconomic conditions worldwide, as well as dialogue about the social issues these technologies bring to the fore: collaboration, security, ethics, data privacy, transparency, propaganda, etc.\nTo paraphrase our co-chairs, Brian Granger:\nJupyter is where humans and data science intersect.\nAnd Fernando Perez:\nThe better the technology, the more important that human judgement becomes.\nConsequently, we'll explore three main themes at JupyterCon 2018:\n\n\nInteractive computing with data at scale: the technical best practices and organizational challenges of supporting interactive computing in companies, universities, research collaborations, etc., (JupyterHub)\n\nExtensible user interfaces for data science, machine learning/AI, and scientific computing (JupyterLab)\n\nComputational communication: taking the artifacts of interactive computing and communicating them to different audiences\n\nA meta-theme that ties these together is extensible software architecture for interactive computing with data. Jupyter is built on a set of flexible, extensible, and re-usable building blocks that can be combined and assembled to address a wide range of usage cases. These building blocks are expressed through the various open protocols, APIs, and standards of Jupyter.\nThe Jupyter community has much to discuss and share this year. For example, success stories such as the data science program at UC Berkeley illustrate the power of JupyterHub deployments at scale in education, research, and industry. As universities and enterprise firms learn to handle the technical challenges of rolling out hands-on, interactive computing at scale, a cohort of organizational challenges come to the fore: practices regarding collaboration, security, compliance, data privacy, ethics, etc. These points are especially poignant in verticals such as health care, finance, and education, where the handling of sensitive data is rightly constrained by ethical and legal requirements (HIPAA, FERPA, etc.). Overall, this dialogue is extremely relevant\u2014it is happening at the intersection of contemporary political and social issues, industry concerns, new laws (GDPR), the evolution of computation, plus good storytelling and communication in general\u2014as we'll explore with practitioners throughout the conference.\nThe recent beta release of JupyterLab embodies the meta-theme of extensible software architecture for interactive computing with data. While many people think of Jupyter as a \"notebook,\" that's merely one building block needed for interactive computing with data. Other building blocks include terminals, file browsers, LaTeX, markdown, rich outputs, text editors, and renderers/viewers for different data formats. JupyterLab is the next-generation user interface for Project Jupyter, and provides these different building blocks in a flexible, configurable, customizable environment. This opens the door for Jupyter users to build custom workflows, and also for organizations to extend JupyterLab with their own custom functionality.\nThousands of organizations require data infrastructure for reporting, sharing data insights, reproducing results of analytics, etc. Recent business studiesestimate that more than half of all companies globally are precluded from adopting AI technologies due to a lack of digital infrastructure\u2014 often because their efforts toward data and reporting infrastructure are buried in technical debt. So much of that infrastructure was built from scratch, even when organizations needed essentially the same building blocks. JupyterLab's primary goal is to make it routine to build highly customized, interactive computing platforms, while supporting more than 90 different popular programming environments.\nFigure 1. Screenshot from the JupyterLab beta release. Image used with permission from Project Jupyter contributors.\nA third major theme builds on top of the other two: computational communication. For data and code to be useful for humans, who need to make decisions, it has to be embedded into a narrative\u2014a story\u2014 that that can be communicated to others. Examples of this pattern include: data journalism, reproducible research and open science, computational narratives, open data in society and government, citizen science, and really any area of scientific research (physics, zoology, chemistry, astronomy, etc.), plus the range of economics, finance, and econometric forecasting.\nAnother growing segment of use cases involves Jupyter as a \"last-mile\" layer for leveraging AI resources in the cloud. This becomes especially important in light of new hardware emerging for AI needs, vying with competing demand from online gaming, virtual reality, cryptocurrency mining, etc.\nPlease take the following as personal opinion, observations, perspectives: we've reached a point where hardware appears to be evolving more rapidly than software, while software appears to be evolving more rapidly than effective process. At O'Reilly Media, we work to map the emerging themes in industry, in a process nicknamed \"radar.\" This perspective about hardware is a theme I've been mapping, and meanwhile comparing notes with industry experts. A few data points to consider: Jeff Dean's talk at NIPS 2017, \"Machine Learning for Systems and Systems for Machine Learning\" about comparisons of CPUs/GPUs/TPUs, and how AI is transforming the design of computer hardware; The Case for Learned Index Structures, also from Google, about the impact of \"branch vs. multiple\" costs on decades of database theory; this podcast interview \"Scaling machine learning\" with Reza Zadeh about the critical importance of hardware/software interfaces in AI apps; the video interview that Wes McKinney and I recorded at JupyterCon 2017 about how Apache Arrow presents a much different take on how to leverage hardware and distributed resources.\nThe notion that \"hardware > software > process\" contradicts the past 15\u201320 years of software engineering practice. It's an inversion of the general assumptions we make. In response, industry will need to rework approaches for building software within the context of AI\u2014 which was articulated succinctly by Lenny Pruss from Amplify Partners in \"Infrastructure 3.0: Building blocks for the AI revolution.\" In this light, Jupyter provides an abstraction layer\u2014 a kind of buffer to help \"future proof\"\u2014 for complex use cases in NLP, machine learning, and related work. We're seeing this from most of the public cloud vendors, who are also leaders in AI, Google, Amazon, Microsoft, IBM, etc., and who will be represented at the conference in August.\nOur program at JupyterCon will feature expert speakers across all of these themes. However, to me, that's merely the tip of the iceberg. So much of the real value that I get from conferences happens in the proverbial \"Hallway Track,\" where you run into people who are riffing off news they've just learned in a session\u2014 perhaps in line with your thinking, perhaps in a completely different direction. Those conversations have space to flourish when people get immersed in the community, the issues, the possibilities.\nIt'll be a busy week. We'll have two days of training courses: intensive, hands-on coding, a lot of interaction with expert instructors. Training will overlap with one day of tutorials: led by experts, generally larger than training courses (though more detailed than session talks), featuring a lot of Q&A.\nThen we'll have two days of keynotes and session talks, expo hall, lunches and sponsored breaks, plus Project Jupyter sponsored events. Events include Jupyter User Testing, author signings, \"Meet the Experts\" office hours, demos in the vendor expo hall\u2014 plus related meetups in the evenings. Last year, the Poster Session was one of the biggest surprises to me: it was such a hit that it was difficult to move through the room; walkways were packed with people asking presenters questions about their projects.\nThis year, we'll introduce a Business Summit, similar to the popular summits at the Strata Data Conferences and The AI Conference. This will include high-level presentations on the most promising and important developments in Jupyter for executives and decision-makers. Brian Granger and I will be hosting the Business Summit, along with Joel Horwitz of IBM. One interesting data point: among the regional events, we've seen much more engagement this year from enterprise and government than we'd expected, more emphasis on business use cases and new product launches. The ecosystem is growing, and will be represented well at JupyterCon!\nWe will also feature an Education Track in the main conference, expanding on the well-attended Education Birds-of-a-Feather and related talks during JupyterCon 2017. Use of Jupyter in education has grown rapidly across many contexts: middle/high-school, universities, corporate training, and online courses. Lorena Barba and Robert Talbert will be organizing this track.\nFollowing our schedule of conference talks, the week wraps up with a community sprint day on Saturday. You can work side-by-side with leaders and contributors in the Jupyter ecosystem to implement that feature you've always wanted, fix bugs, work on design, write documentation, test software, or dive deep into the internals of something in the Jupyter ecosystem. Be sure to bring your laptop.\nNote that we believe true innovation depends on hearing from, and listening to, people with a variety of perspectives. Please read our Diversity Statement for more details. Also, we're committed to creating a safe and productive environment for everyone at all of our events. Please read our Code of Conduct. Last year, we were able to work with the community plus matching donations to provide several \"Diversity & Inclusion\" scholarships, as well as more than dozen student scholarships. We're looking forward to building on that this year!\nThat's a sample of what's coming up for JupyterCon in NYC this August. In preparation for the event, we'll also help present and sponsor a regional community event\u2014check out Jupyter Pop-up DC, May 15, 2018. We look forward to many opportunities to showcase new work and ideas, to meet each other, to learn about the architecture of the project itself, and to contribute to the future of Jupyter.\nContinue reading Jupyter is where humans and data science intersect.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/L2RhtI1GEno/jupyter-is-where-humans-and-data-science-intersect"
 },
 {
  "title": "The importance of transparency and user control in machine learning",
  "content": "The O\u2019Reilly Data Show Podcast: Guillaume Chaslot on bias and extremism in content recommendations.In this episode of the Data Show, I spoke with Guillaume Chaslot, an ex-YouTube engineer and founder of AlgoTransparency, an organization dedicated to helping the public understand the profound impact algorithms have on our lives. We live in an age when many of our interactions with companies and services are governed by algorithms. At a time when their impact continues to grow, there are many settings where these algorithms are far from transparent. There is growing awareness about the vast amounts of data companies are collecting on their users and customers, and people are starting to demand control over their data. A similar conversation is starting to happen about algorithms\u2014users are wanting more control over what these models optimize for and an understanding of how they work.\nI first came across Chaslot through a series of articles about the power and impact of YouTube on politics and society. Many of the articles I read relied on data and analysis supplied by Chaslot. We talked about his work trying to decipher how YouTube\u2019s recommendation system works, filter bubbles, transparency in machine learning, and data privacy.Continue reading The importance of transparency and user control in machine learning.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/JN_Jmuznbzo/the-importance-of-transparency-and-user-control-in-machine-learning"
 },
 {
  "title": "Four short links: 12 April 2018",
  "content": "Probabilistic Programming, Bad Copyright, Technical Debt, and Video Data Set\n\nTensorFlow Probability -- a probabilistic programming toolbox for machine learning.\n\n\nEuropean Copyright Law Isn't Great. It Could Soon Get a Lot Worse. (EFF) -- The practical effect of this could be to make it impossible for a news publisher to publish their stories for free use, for example by using a Creative Commons license. (via BoingBoing)\n\nA Taxonomy of Technical Debt -- you can argue about whether his categories are your categories, but it's useful to have words for the nuance.\n\nMoments in Time Data Set -- A large-scale data set for recognizing and understanding action in videos. (via MIT News)\n\n\nCheck out the \"Data Science & Machine Learning\" sessions\u00a0at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 12 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/UEgbKhQNWYc/four-short-links-12-april-2018"
 },
 {
  "title": "Using qualitative and quantitative data to design better user experiences",
  "content": "It's important to know the \"why\" in addition to the \"what\" in UX design.Continue reading Using qualitative and quantitative data to design better user experiences.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/-gA93-tgDlQ/using-qualitative-and-quantitative-data-to-design-better-user-experiences"
 },
 {
  "title": "Probing the pill box: Repurposing drugs for new treatments",
  "content": "As the cost of developing new drugs rises, researchers are investigating new ways to use existing medicines\nWith the development of new medicines often exceeding 10 years and topping $1 billion, faster and cheaper methods of drug development are sorely needed. Drug repurposing, whereby drugs approved for one condition are used to treat a completely different disease, is a fast-emerging strategy aimed at circumventing this daunting pipeline.  Several biotechnology companies now specialize in identifying new drug-disease pairs by interrogating massive biomedical datasets with ever-evolving artificial intelligence algorithms. This systematic approach to repurposing, augmenting the chance application of drugs to new diseases, represents a powerful tool for producing new medicines. Indeed, major drug companies such as GlaxoSmithKline have committed to probing \u201cdark data,\u201d or failed trial data, to achieve this goal.\nThe Promise of Drug Repositioning\nThe time and money required to bring a new drug to market severely limits the number of new treatments, in part explaining the steady decline in the number of approved drugs entering use each year. The drug development process, overseen in the United States by the Food and Drug Administration (FDA), has three main stages. Candidate compounds, which are being generated in abundance by discovery science and have established mechanisms of action, safe dosages, and a pharmacokinetic profile, begin in Phase I trials. In this trial stage, the safety profile of the compound is established, usually in healthy volunteers. Promising candidates are selected for Phase II trials, which determine the effectiveness of the compound at treating a particular disease or indication in a small sample group. Positive candidates are admitted to a Phase III trial, which takes place in a larger patient population, where the efficacy of the drug and its side-effects are fully assessed.Continue reading Probing the pill box: Repurposing drugs for new treatments.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/OqElFEaWaaw/probing-the-pill-box-repurposing-drugs-for-new-treatments"
 },
 {
  "title": "Data engineers vs. data scientists",
  "content": "The two positions are not interchangeable\u2014and misperceptions of their roles can hurt teams and compromise productivity.It\u2019s important to understand the differences between a data engineer and a data scientist. Misunderstanding or not knowing these differences are making teams fail or underperform with big data.\nA key misunderstanding is the strengths and weaknesses of each position. I think some of these misconceptions come from the diagrams that are used to describe data scientists and data engineers.\nFigure 1. Overly simplistic venn diagram with data scientists and data engineers. Illustration by Jesse Anderson.\nVenn diagrams like Figure 1 oversimplify the complex positions and how they\u2019re different. It makes the two positions seem interchangeable. Yes, both positions work on big data. However, what each position does to create value or data pipelines with big data is very different. This difference comes from the base skills of each position.\n\nWhat are data scientists and data engineers?\nWhen I work with organizations on their team structures, I don\u2019t use a Venn diagram to illustrate the relationship between a data engineer and a data scientist. I draw the diagram as shown in Figure 2.\nFigure 2. Diagram showing the core competencies of data scientists and data engineers and their overlapping skills. Illustration by Jesse Anderson and the Big Data Institute.\n\nData scientists\u2019 skills\nAt their core, data scientists have a math and statistics background (sometimes physics). Out of this math background, they\u2019re creating advanced analytics. On the extreme end of this applied math, they\u2019re creating machine learning models and artificial intelligence.\nJust like their software engineering counterparts, data scientists will have to interact with the business side. This includes understanding the domain enough to make insights. Data scientists are often tasked with analyzing data to help the business, and this requires a level of business acumen. Finally, their results need to be given to the business in an understandable fashion. This requires the ability verbally and visually communicate complex results and observations in a way that the business can understand and act on them.\nMy one sentence definition of a data scientist is: a data scientist is someone who has augmented their math and statistics background with programming to analyze data and create applied mathematical models.\nA common data scientist trait is that they\u2019ve picked up programming out of necessity to accomplish what they couldn\u2019t do otherwise. When I talk to data scientists, this is a common thing they tell me. In order to accomplish a more complicated analysis or because of an otherwise insurmountable problem, they learned how to program. Their programming and system creation skills aren\u2019t the levels that you\u2019d see from a programmer or data engineer\u2014nor should they be.\n\nData engineers\u2019 skills\nAt their core, data engineers have a programming background. This background is generally in Java, Scala, or Python. They have an emphasis or specialization in distributed systems and big data. A data engineer has advanced programming and system creation skills.\nMy one sentence definition of a data engineer is: a data engineer is someone who has specialized their skills in creating software\nsolutions around big data.\nUsing these engineering skills, they create data pipelines. Creating a data pipeline may sound easy or trivial, but at big data scale, this means bringing together 10-30 different big data technologies. More importantly, a data engineer is the one who understands and chooses the right tools for the job. A data engineer is the one who understands the various technologies and frameworks in-depth, and how to combine them to create solutions to enable a company\u2019s business processes with data pipelines.\nIn my experience, a data engineer is only tangentially involved in the operations of the cluster (in contrast to what\u2019s said about data engineers here). Though some data science technologies really require a DevOps or DataOps set up, the majority of technologies don't. Just like with most programers, I wouldn't allow them direct access to the production system. That's primarily the job for system administrators or DevOps.\n\n\nOverlapping skills\nThere is an overlap between a data scientist and a data engineer. However, the overlap happens at the ragged edges of each one\u2019s abilities.\nFor example, they overlap on analysis. However, a data scientist\u2019s analytics skills will be far more advanced than a data engineer\u2019s analytics skills. A data engineer can do some basic to intermediate level analytics, but will be hard pressed to do the advanced analytics that a data scientist does.\nBoth a data scientist and a data engineer overlap on programming. However, a data engineer\u2019s programming skills are well beyond a data scientist\u2019s programming skills. Having a data scientist create a data pipeline is at the far edge of their skills, but is the bread and butter of a data engineer. In this way, the two roles are complementary, with data engineers supporting the work of data scientists.\nYou\u2019ll notice that there is another overlap between a data scientist and a data engineer\u2014that of big data. Understanding each positions\u2019 skills better, you can now understand the overlap. Data engineers use their programming and systems creation skills to create big data pipelines. Data scientists use their more limited programming skills and apply their advanced math skills to create advanced data products using those existing data pipelines. This difference between creating and using lies at the core of a team's failure or underperforming with big data. A team that expects their data scientists to create the data pipelines will be woefully disappointed.\n\n\n\nWhen organizations get it wrong\nIt\u2019s unfortunately common for organizations to misunderstand the core skills and roles of each position. Some organizations believe that a data scientist can create data pipelines. A data scientist can create a data pipeline after a fashion. The issues with a data scientist creating a data pipeline are several fold. Remember that a data scientist has only learned programming and big data out of necessity. They\u2019re smart people and can figure things out\u2014eventually. Creating a data pipeline isn\u2019t remotely their core competency.\nFrom the managerial point of view, the data science team will appear stuck. You\u2019ll look around or hear about other teams and compare their progress to your team\u2019s progress. It will appear as if the data science team isn\u2019t performing or greatly under performing. This is an unfair evaluation based on misunderstanding the core competency of a data scientist.\n\nData scientists doing data engineering\nI\u2019ve seen companies task their data scientists with things you\u2019d have a data engineer do. The data scientists were running at 20-30% efficiency. The data scientist doesn\u2019t know things that a data engineer knows off the top of their head. Creating a data pipeline isn\u2019t an easy task\u2014it takes advanced programming skills, big data framework understanding, and systems creation. These aren\u2019t skills that an average data scientist has. A data scientist can acquire these skills; however, the return on investment (ROI) on this time spent will rarely pay off. Don\u2019t misunderstand me: a data scientist does need programming and big data skills, just not at the levels that a data engineer needs them.\nThere is also the issue of data scientists being relative amateurs in this data pipeline creation. A data scientist will make mistakes and wrong choices that a data engineer would (should) not. A data scientist often doesn\u2019t know or understand the right tool for a job. Everything will get collapsed to using a single tool (usually the wrong one) for every task. The reality is that many different tools are needed for different jobs. A qualified data engineer will know these, and data scientists will often not know them.\nA recent example of this was a data scientist using Apache Spark to process a data set in the 10s of GB. Yes, Spark can process that amount of data. However, a small data program would have been much, much faster and better. Their Spark job was taking 10-15 minutes to execute, but the small data RDBMS took 0.01 seconds to accomplish the same thing. In this case, the data scientist solved the problem after a fashion, but didn\u2019t understand what the right tool for the job was. Times that 15 minutes spent running that job by 16 times in a day (that\u2019s on the low end for analysis), and your data scientist is spending four hours a day waiting because they\u2019re using the wrong tool for the job.\nAt another organization, their data scientists didn\u2019t have any data engineering resources. The data scientists would work on the problems until they got stuck on a data engineering problem they couldn\u2019t solve. They\u2019d report back to the business that they couldn\u2019t finish things and there it sat, half-finished. This led to the data scientists wasting their time up to that point, and left, by their estimate, millions of dollars on the table because things couldn\u2019t be finished.\nA more worrisome manifestation of having a data scientist do a data engineer\u2019s work is that the data scientist will get frustrated and quit. I\u2019ve talked to many data scientists at various organizations who were doing data engineer work. The conversation is always the same\u2014the data scientist complains that they came to the company to data science work, not data engineering work. They\u2019ll do data engineering work in a pinch to get something done, but having a data scientist do data engineer work will drive them crazy. They will quit and you will have 3-6 months to get your data engineering act together. I talk more about these issues in another post.\n\n\nRatios of data engineers to data scientists\nA common issue is to figure out the ratio of data engineers to data scientists. The general things to consider when choosing a ratio is how complex the data pipeline is, how mature the data pipeline is, and the level of experience on the data engineering team.\nHaving more data scientists than data engineers is generally an issue. It typically means that an organization is having their data scientists do data engineering. As I\u2019ve shown, this leads to all sorts of problems.\nA common starting point is 2-3 data engineers for every data scientist. For some organizations with more complex data engineering requirements, this can be 4-5 data engineers per data scientist. This includes organizations where data engineering and data science are in different reporting structures. You need more data engineers because more time and effort is needed to create data pipelines than to create the ML/AI portion.\nI talk more about how data engineering and data science teams should interact with each other in my book Data Engineering Teams.\n\n\nData Engineers doing data science\nA far less common case is when a data engineer starts doing data science. There is an upward push as data engineers start to improve their math and statistics skills. This upward push is becoming more common as data science becomes more standardized. It\u2019s leading to a brand new type of engineer.\n\n\n\nThe need for machine learning engineers\nLet\u2019s face it\u2014data scientists come from academic backgrounds. They usually have a Ph.D. or master's degree. The issue is that they\u2019d rather write a paper on a problem than get something into production. Other times, their programming abilities only extend to creating something in R. Putting something written in R into production is an issue unto itself. They don\u2019t think in terms of creating systems, like an engineer.\nThe general issue with data scientists is that they\u2019re not engineers who put things into production, create data pipelines, and expose those AI/ML results.\nTo deal with the disparity between an academic mindset and the need to put something in production, we\u2019re seeing a new type of engineer. Right now, this engineer is mostly seen in the U.S. Their title is machine learning engineer.\nFigure 3. Diagram showing where a machine learning engineer fits with a data scientist and data engineer. Illustration by Jesse Anderson and the Big Data Institute.\nMachine learning engineers primarily come from data engineering backgrounds. They\u2019re cross-trained enough to become proficient at both data engineering and data science. A less common route is for a data scientist to cross-train on the data engineering side.\nMy one sentence definition of a machine learning engineer is: a machine learning engineer is someone who sits at the crossroads of data science and data engineering, and has proficiency in both data engineering and data science.\nAs you looked at Figure 2, you probably wondered what happens to the gap between data science and data engineering. This exactly where the machine learning engineer fits in, as shown in Figure 3. They\u2019re the conduit between the data pipeline a data engineer creates and what the data scientist creates. A machine learning engineer is responsible for taking what a data scientist finds or creates and making it production worthy (it\u2019s worth noting that most of what a data scientist creates isn\u2019t production worthy and is mostly hacked together enough to work).\nThe machine learning engineer\u2019s job primarily is to create the last mile of the data science pipeline. This might entail several parts. It might be rewriting a data scientist\u2019s code from R/Python to Java/Scala. It might be optimizing the ML/AI code from a software engineering point of view that the data scientist wrote so it runs well (or runs at all). The machine learning engineer has the engineering background to enforce the necessary engineering discipline on a field (data science) that isn\u2019t known for its adherence to good engineering principles.\nA model running in production requires care and feeding that software doesn\u2019t. A machine learning model can go stale and start giving out incorrect or distorted results. This could be from the nature of the data changing, new data, or a malicious attack. Either way, the machine learning engineer is on the lookout for changes in their model that would require retraining or tweaking.\n\nMachine learning engineers and data engineers\nThe transition of data engineer to machine learning engineer is a slow-moving process. To be honest, we\u2019re going to see similar revisions to what a machine learning engineer is to what we\u2019ve seen with the definition of data scientists.\nTo explain what I mean by slow moving, I will share the experience of those who I\u2019ve seen make the transition from data engineer to machine learning engineer. They\u2019ve spent years doing development work as a software engineer and then data engineer. They\u2019ve always had an interest in statistics or math. Other times, they just got bored with the constraints of being a data engineer. Either way, this transition took years. I\u2019m not seeing people become machine learning engineers after taking a beginning stats class or after taking a beginning machine learning course.\nAs I much as I razz the data scientists for being academics, data engineers aren\u2019t the right people, either. An engineer loves trues and falses, the black and white, and the ones and zeros of the the world. They don\u2019t like uncertainty. With machine learning, there is a level of uncertainty of the model\u2019s guess (engineers don\u2019t like guessing, either). Unlike most engineers, a machine learning engineer can straddle the certainty of data engineering and the uncertainty of data science.\n\n\nThe increasing value of machine learning engineers\nThe bar for doing data science is gradually decreasing. The best practices are gradually being fleshed out. The most common algorithms are known. Even better, someone has already coded and optimized these algorithms.\nThis increasing maturity is making it easier for both data scientists and machine learning engineers to put things in production without having to code them. We\u2019re also seeing data science become a more automatic and automated process. Google\u2019s AutoML is one such trend where it will find the best algorithm for you automatically and give results without requiring the work of a full-fledged data scientist. DataRobot is another technology that is automating the process of finding the right data science algorithm for the data. It will also aid the machine learning engineers in putting that algorithm into production.\nThese tools aren\u2019t going to replace hardcore data science, but it will allow data scientists to focus on the more difficult parts of data science. It will allow machine learning engineers to become more and more productive. We\u2019ll see a gradually increasing amount of offloading to machine learning engineers and automation of algorithms.\nI\u2019m torn on what level of productivity we should expect from machine learning engineers in the future. To grossly oversimplify things, will machine learning engineers be the Wordpress configurators to their web developer counterparts? In this scenario, a machine learning engineer can be productive with very known and standard use cases, and only a data scientist can handle the really custom work. Or will machine learning engineers be the database administrator reborn? Given an in-depth knowledge of the model, they can use a known, cookie-cutter approach to configure a model, get correct results 50-80% of the time, and that\u2019s good enough for what was needed. To get truly accurate results, you would need a data scientist.\nThe key to the productivity of machine learning engineers and data scientists will be their tools. There\u2019s a lack of maturity now, and that\u2019s why I\u2019m wondering how productive they\u2019ll be in the future.\nI expect the bar for doing data science to continue to lower. This will make a machine learning engineer able to accomplish more data science without a massive increase in knowledge. I expect the role of machine learning engineer to become increasingly common in the U.S. and around the world.\n\n\n\nWhat to do?\nNow that you\u2019ve seen the differences between data scientists and data engineers, you need to go back through your organization and see where you need to make changes. This is a change I\u2019ve helped other organizations accomplish, and they\u2019ve seen tremendous results. In cases where the data science group seemed stuck and unable to perform, we created data engineering teams, showed the data science and data engineering teams how to work together, and put the right processes in place. \nThese changes took the data science team from 20-30% productivity to 90%. The teams were able to do more with the same number of people. The data scientists were happier because they weren\u2019t doing data engineering. Management could start delivering value against the promises of big data.\nYou also met a new position, machine learning engineer. As your data science and data engineering teams mature, you\u2019ll want to check the gaps between the teams. You may need to promote a data engineer on their way to becoming a machine learning engineer or hire a machine learning engineer.\nFinally, most problems with big data are people and team issues. They are not technical issues (at least not initially). Technology usually gets blamed because it\u2019s far easier to blame technology than to look inward at the team itself. Until you solve your personnel issues, you won\u2019t hit the really tough technical issues or create the value with big data you set out to create. Take an honest look at your team and your organization to see where you need to change.\nA big thanks to Russell Jurney, Paco Nathan, and Ben Lorica for their feedback.\n\n\nContinue reading Data engineers vs. data scientists.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/h07p-vrbmtI/data-engineers-vs-data-scientists"
 },
 {
  "title": "Four short links: 11 April 2018",
  "content": "Assignment, Warranties, Data, and Public Goods\n\nWhy Does \"=\" Mean Assignment -- marvellous history lesson.\n\nWarranty Void if Removed Stickers Are Bull -- Federal law says you can repair your own things, and manufacturers cannot force you to use their own repair services. (via BoingBoing)\n\nTXR -- a pattern language and a Lisp variant for data problems.\n\nRoman Roads and Persistence Development -- In some ways, the emergence of the Roman road network is almost a natural experiment\u2014in light of the military purpose of the roads, the preferred straightness of their construction, and their construction in newly conquered and often undeveloped regions. This type of public good seems to have had a persistent influence on subsequent public good allocations and comparative development. At the same time, the abandonment of the wheel shock in MENA appears to have been powerful enough to cause that degree of persistence to break down. Overall, our analysis suggests that a public good provision is a powerful channel through which persistence in comparative development comes about. I wonder whether this kind of analysis is even conceivable with internet public policy like broadband, coding classes, and laws. (via BoingBoing)\n\n\nCheck out the \"Law, ethics, and governance\" sessions at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 11 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/vAe26u3PZmA/four-short-links-11-april-2018"
 },
 {
  "title": "4 things business leaders should know as they explore AI and deep learning",
  "content": "Our survey reveals how organizations are using tools, techniques, and training to apply AI through deep learning. We\u2019re at an exciting point with artificial intelligence (AI). Years of research are yielding tangible results, specifically in the area of deep learning. New projects and related technologies are blossoming. Enthusiasm is high.\nYet the path toward real and practical application of AI and deep learning remains unclear for many organizations. Business and technology leaders are searching for clarity. Where do I start? How can I train my teams to perform this work? How do I avoid the pitfalls?\nWe conducted a survey[1] to help leaders better understand how organizations are applying AI through deep learning and where they\u2019re encountering the biggest obstacles. We identified four notable survey findings that apply to organizations.\n1. There\u2019s an AI skills gap\nOf particular note is an AI skills gap revealed in the survey. 28% of respondents are using deep learning now and 54% say it will play a key role in their future projects. Who will do this work? AI talent is scarce, and the increase in AI projects means the talent pool will likely get smaller in the near future.\n2. Companies are addressing the AI skills gap through training\nDeep learning remains a relatively new technique, one that hasn\u2019t been part of the typical suite of algorithms employed by industrial data scientists. So, it\u2019s no surprise that the main factor holding companies back from trying deep learning is the skills gap. To overcome this gap, a majority (75%) of respondents said their company is using some form of in-house or external training program. Almost half (49%) of respondents said their company offered \u201cin-house on-the-job training.\u201d 35% indicated their company used either formal training from a third party or from individual training consultants or contractors.\n3. Initial deep learning projects often focus on safe upgrades\nThe rise of deep learning can be traced to its success in computer vision, speech technologies, and game playing, but our survey shows developers and data scientists are more likely to use it to work with structured or semistructured data. Why? There are good reasons. Upgrading familiar applications with deep learning is a safer investment than starting something new, businesses have a lot of structured and semistructured data already, and the number of businesses that can currently make use of computer vision (to say nothing of gaming) is limited. That said, our respondents see value in vision technology, and new deep learning applications for vision will grow in tandem with text and semistructured data.\n4. TensorFlow is the most popular deep learning tool\nMost respondents (73%) said they\u2019ve begun playing with deep learning software. TensorFlow is by far the most popular tool among our respondents, with Keras in second place, and PyTorch in third. Other frameworks like MXNet, CNTK, and BigDL have growing audiences as well. We expect all of these frameworks\u2014including those that are less popular now\u2014to continue to add users and use cases.\nLooking for more insight? Download our free report, \"How companies are putting AI to work through deep learning,\" for full findings from our AI and deep learning survey.\nWe'll also explore these and related AI topics at Artificial Intelligence Conference in New York, April 29-May 2, 2018.\n\n\n\n[1] In early 2018 we conducted a survey of subscribers to our AI, data, and programming newsletters and received more than 3,300 responses. We focused on deep learning and assessed the adoption of tools and techniques needed to build AI applications.\n\n\nContinue reading 4 things business leaders should know as they explore AI and deep learning.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/KKdWWqe41AU/4-things-business-leaders-should-know-as-they-explore-ai-and-deep-learning"
 },
 {
  "title": "Strong feedback loops make strong software teams",
  "content": "Enhance overall code quality through a blend of interpersonal communication and tool-based analysis.Software quality takes time. And good quality products come from properly working feedback loops. Timely feedback can mean clarity over confusion; a validation of assumptions can mean shorter development cycles.\nFor example, let\u2019s say you have a project that needs to be delivered next month, but you and your development team know it will take at least two more months to complete. How do you communicate this to key stakeholders?\nFirst off, you need to establish a shared understanding of goals and quality amongst all involved participants. As a developer, you tend to base your behavior and build products and architectures around values and assumptions. If these values and assumptions are not aligned and validated, you will never end up with what you intended\u2014let alone on time and within budget. Assuming your assumptions are accurate, you get carried away and spend way too much time on something before gathering feedback. But honestly, when would you rather hear all of your effort was a waste: after you spent a day working on it, or after working on it for a week?\nA feedback loop is straightforward: it uses its input as one of its inputs. In its simplest form, a developer changes a code base and then gets feedback from the system by unit testing. This feedback will now be input for the developer\u2019s next steps to improve the code. However, reality is not that simple. Plus, humans have an irrepressible tendency to include as many people as possible in one loop.\nIf you follow such a course, you\u2019ll end up with feedback chaos: massive \u201cloops\u201d including every potential player make it impossible to control, validate assumptions, and create a shared sense of reality. Quite simply, there\u2019s too much going on. But there\u2019s a solution: reflection. Reflection helps you identify existing feedback loops and determine who needs to be included. The shorter the feedback loop, the better.\nThere are two forms of feedback: personal and tool based. Personal feedback is given on an interpersonal level\u2014people discussing code, products, or processes and identifying where things can be improved. Tool-based feedback, such as static analysis, provides you with code-level feedback and tells you where to improve your code (or specific parts of your code) to increase quality. Personal feedback is often specific for projects, more sensitive to context, and offers concrete suggestions to implement. Tool-based feedback enables faster feedback loops, allows for scalability by iteration, and is more objective. But which form of feedback is better?\nThere is a false dichotomy between full automation and human intervention. Successful quality control combines tool-based measurement with manual review and discussion. At the end of the day, the most effective feedback loops are a mixture of daily best practices, automation, tools, and human intervention.\nIn an upcoming follow-up post, I\u2019ll discuss specific practices that integrate personal and tool-based feedback. These practices will help you bolster your code and architectural quality.\nThis post is a collaboration between O'Reilly and SIG. See our statement of editorial independence.\nContinue reading Strong feedback loops make strong software teams.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/-us1qlRyN5w/strong-feedback-loops-make-strong-software-teams"
 },
 {
  "title": "Four short links: 10 April 2018",
  "content": "Deep Learning Learnings, Reverse Engineering WhatsApp, Database Client, and Social Science\n\nLessons Learned Reproducing a Deep Reinforcement Learning Paper -- REALLY good retrospective on eight months reproducing a paper, with lots of lessons learned, like starting a reinforcement learning project, you should expect to get stuck like you get stuck on a math problem. It\u2019s not like my experience of programming in general so far where you get stuck but there\u2019s usually a clear trail to follow and you can get unstuck within a couple of days at most. It\u2019s more like when you\u2019re trying to solve a puzzle, there are no clear inroads into the problem, and the only way to proceed is to try things until you find the key piece of evidence or get the key spark that lets you figure it out.\n\n\nReverse Engineering WhatsApp -- This project intends to provide a complete description and re-implementation of the WhatsApp Web API, which will eventually lead to a custom client. WhatsApp Web internally works using WebSockets; this project does as well.\n\n\nDatabaseFlow -- an open source self-hosted SQL client, GraphQL server, and charting application that works with your database. Visualize schemas, query plans, charts, and results. You can run Database Flow locally for your own use, or install to a shared server for the whole team.\n\n\nCode and Data for the Social Sciences -- This handbook is about translating insights from experts in code and data into practical terms for empirical social scientists.\n\n\n\nCheck out the \"Data Science & Machine Learning\" sessions at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 10 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/GDZWkeB2yIE/four-short-links-10-april-2018"
 },
 {
  "title": "Four short links: 9 April 2018",
  "content": "Monads, GDPR, Blockchain, and Search\n\nWhat We Talk About When We Talk About Monads -- This paper is not a monad tutorial. It will not tell you what a monad is. Instead, it helps you understand how computer scientists and programmers talk about monads and why they do so.\n\n\nPublishers and GDPR -- a nice explanation of what GDPR is bringing to companies like Facebook and Google, how it's changing ad-serving, and what it means for content publishers.\n\nBlockchain is Not Only Crappy Technology But a Bad Vision for the Future -- There is no single person in existence who had a problem they wanted to solve, discovered that an available blockchain solution was the best way to solve it, and therefore became a blockchain enthusiast.\n\n\nTypesense -- open source typo tolerant search engine that delivers fast and relevant results out of the box.\n\n\n\nCheck out the \"Law, ethics, and governance\" sessions at the Strata Data Conference in London, May 21-24, 2018.\n\nContinue reading Four short links: 9 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/XPqSjjkHGQE/four-short-links-9-april-2018"
 },
 {
  "title": "Four short links: 6 April 2018",
  "content": "Library Management, Flame Graphs, Silent Speech Interface, and Cloud Backup\n\nThou Shalt Not Depend on Me (ACM) -- with 37% of websites using at least one known vulnerable library, and libraries often being included in quite unexpected ways, there clearly is room for improvement in library handling on the web.\n\n\nFlameScope -- Netflix's open source visualization tool for exploring different time ranges as Flame Graphs. (via Netflix Tech Blog)\n\nAlterEgo: A Personalized Wearable Silent Speech Interface -- The results from our preliminary experiments show that the accuracy of our silent speech system is at par with the reported word accuracies of state-of-the-art speech recognition systems, in terms of being robust enough to be deployed as voice interfaces, albeit on smaller vocabulary sets. (via MIT News)\n\nDuplicity -- Encrypted bandwidth-efficient backup using the rsync algorithm. Common use case is backing up server to S3, but there's an impressive number of connective services, including Google Drive, Azure, Mega.co, and Dropbox.\n\nContinue reading Four short links: 6 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/mWtbID3c7lM/four-short-links-6-april-2018"
 },
 {
  "title": "It's time to usher in a new era of UX curation",
  "content": "Empowering groups to understand design for themselves will lead to new user experiences for users and designers alike.Continue reading It's time to usher in a new era of UX curation.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/xdlpSXINxnI/its-time-to-usher-in-a-new-era-of-ux-curation"
 },
 {
  "title": "Kyle Simpson and Tammy Everts on the challenges of the modern web",
  "content": "The O\u2019Reilly Programming Podcast: Rising barriers to entry, the complexity of the modern web, and a preview of upcoming Fluent sessions.In this episode of the O\u2019Reilly Programming Podcast, I talk with two of the program chairs for the upcoming O\u2019Reilly Fluent Conference (July 11-14 in San Jose), Kyle Simpson and Tammy Everts. Simpson is co-author of the HTML 5 Cookbook, and the author of the You Don\u2019t Know JS series of books. Everts is the chief experience officer at SpeedCurve and the author of Time is Money: The Business Value of Web Performance.Continue reading Kyle Simpson and Tammy Everts on the challenges of the modern web.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/vk3mrYECK3E/kyle-simpson-and-tammy-everts-on-the-challenges-of-the-modern-web"
 },
 {
  "title": "Four short links: 5 April 2018",
  "content": "Interactive Notebooks, Molecule-making AI, Interpersonal Dynamics, and Javascript Motion Library\n\nMyBinder -- Turn a GitHub repo into a collection of interactive notebooks. (via Julia Evans)\n\nMolecule-Making AI (Nature) -- The new AI tool, developed by Marwin Segler, an organic chemist and artificial intelligence researcher at the University of M\u00fcnster in Germany, and his colleagues, uses deep learning neural networks to imbibe essentially all known single-step organic-chemistry reactions\u2014about 12.4 million of them. This enables it to predict the chemical reactions that can be used in any single step. The tool repeatedly applies these neural networks in planning a multi-step synthesis, deconstructing the desired molecule until it ends up with the available starting reagents. (via Slashdot)\n\nInterpersonal Dynamics -- The list of common corrosive dynamics rang true: bone-deep competition; fear of being found out; my reality is not the reality; it's no fun being the squeaky wheel; feedback stays at the surface; denial that work is personal.\n\nPopmotion -- A functional, flexible JavaScript motion library.\n\n\nContinue reading Four short links: 5 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/0VI5ueh83o4/four-short-links-5-april-2018"
 },
 {
  "title": "5 tips for architecting fast data applications",
  "content": "Considerations for setting the architectural foundations for a fast data platform.We live in the era of the connected experience, where our daily interactions with the world can be digitized, collected, processed, and analyzed to generate valuable insights.\nBack in the days of Web 1.0, Google founders figured out smart ways to rank websites by analyzing their connection patterns and using that information to improve the relevance of search results. Google was among the pioneers that created \u201cweb scale\u201d architectures to analyze the massive data sets that resulted from \u201ccrawling\u201d the web that gave birth to Apache Hadoop, MapReduce, and NoSQL databases. Those were the days when \u201cconnected\u201d meant having some web presence, \u201cinteractions\u201d were measured in number of clicks, and the analysis happened in batch overnight processes.\nFast forward to the present day and we find ourselves in a world where the number of connected devices is constantly increasing. These devices not only respond to our commands, but are also able to autonomously interact with each other. Each of these interactions generates data that collectively amount to high-volume data streams. Accumulating all this data to process overnight is not an option anymore. First, we want to generate actionable insights as fast as possible, and second, one night might not be long enough to process all the data collected the previous day. At the same time, our expectations as users have also evolved to the point where we demand that applications deliver personalized user experiences in near real time.\nTo remain competitive in a market that demands real-time responses to these digital pulses, organizations are adopting fast data applications as key assets in their technology portfolio. There are many challenges that need to be addressed to create the right architecture to support the range of fast data applications that your enterprise needs.\nHere are five considerations every software architect and developer needs to take into account when setting the architectural foundations for a fast data platform.\n1. Determine requirements first\nAlthough this seems the obvious starting point of every software architecture, there are specific considerations to observe when we define the set of requirements for a software platform to support fast data applications.\nData in motion can be tricky to characterize, as there are usually probabilistic factors involved in the generation, transmission, collection, and processing of messages.\nThese are some of the questions we need answered in order to help us drive the architecture:\nGeneral data shape\n\nHow large is each message?\nHow many messages per time unit do we expect?\nDo we expect large changes in the frequency of message delivery? Are there peak hours? Are there \u201cBlack Friday\u201d events in our business?\n\nOutput expectations\n\nHow fast do we need a result?\nDo we need to process each record individually? Or can we process them in small collections (micro-batch)\n\nProcess tolerance\n\nHow \u201cdirty\u201d is the data? What do we do with \u201cdirty\u201d data? Drop it? Report it? Clean and reprocess it?\nDo I need to preserve ordering? Are there inherent time relationships in the messages that need to be preserved as they travel across the system?\nWhat message process warranty level do we require? At least once? At most once? Exactly once?\n\nThe data shape will dictate capacity planning, tuning of the backbone, and scalability analysis for individual components.\nThe output expectations will assist in the choice of processing engine while the process tolerance will add restrictions in terms of processing semantics and error handling.\n2. Leverage the convergence of fast data and microservices\nFast data applications are, by nature, focused on a single task. They have a clear input and output definition, and often a schema as well. Wait. Are we describing fast data applications or microservices? There is a blurred line dividing the two, and data processing libraries such as Akka Streams and Kafka Streams make that line blur even more, as we can use these libraries to embed data processing capabilities in our microservices.\nWe can think of combinations of data-processing applications with microservices to deliver specific features and insights from a data stream. For example, we can combine a machine learning job for anomaly detection with a dashboard that summarizes the findings to facilitate further investigation.\nFrom a project perspective, creating small, self-contained, data-driven applications that meld streaming data and microservices together is a good practice to break down large problems and projects into approachable chunks, reduce risk, and deliver value faster.\n3. Get the message across\nWe discussed how fast data applications and microservices converge on the conceptual and executional levels. Another element they have in common is that they are both consuming and producing messages. A message-oriented implementation requires an efficient messaging backbone that facilitates the exchange of data in a reliable and secure way with the lowest latency possible.\nApache Kafka is currently the leading project in this area. It delivers a publish/subscribe model backed by a distributed log implementation that provides durability, resilience, fault tolerance, and the ability to replay messages by different consumers. The multi-subscriber approach creates the opportunity to reuse a single data stream for multiple consuming applications.\n4. Leverage your SQL knowledge\nWe usually relate SQL to querying tables in relational databases. At first, it might seem odd to issue an SQL query on a stream of data. But what is a table? It\u2019s a collection of records that were added, updated or deleted over time. We can see a table as an consolidated view of a stream of events over time. Likewise, we can create a stream from the observable changes applied to a table, reported as events. As Tyler Akiadu, from Google, explained in his Strata NY 2017 presentation, \u201cFoundations of streaming SQL\u201d: \u201cStreams are the in-motion form of data, both bounded and unbounded.\u201d He goes further to explain how the relational algebra behind SQL can be applied to streams of data when we add time into the algebra in what he calls \u201ctime-varying relations.\u201d\nIn 2016, Apache Spark introduced Structured Streaming, a new streaming engine based on the SparkSQL abstractions and runtime optimizations. In the same year, Apache Flink announced streaming SQL support. More recently, Apache Kafka also introduced the KSQL query engine, adding streaming query capabilities to the popular event back end.\nThe adoption of fast data technologies is on a steep rise. The low-level streaming implementations of the mentioned engines require specialized knowledge in order to program new applications.\nThe availability of SQL enables a wider range of professionals to participate in the development of streaming data analytics pipelines, alleviating the skill shortage in the market and helping organizations to repurpose their workforces as they evolve in their fast data adoption.\n5. Build on the shoulders of giants\nAs we mentioned at the beginning, we expect fast data applications to work reliably, continuously, and deliver results almost in near real time. These requirements impose strong scalability and resilience implications.\nDeveloping standalone applications that fulfill those requirements would be prohibitively expensive, as it would require specialized knowledge of distributed systems, operating systems, and networks, requiring large development and testing efforts to cover the complexity that distributed applications present. Instead, we build those applications on data-oriented frameworks, like Apache Spark and Apache Flink, or we resort to libraries that we can embed in our services, such as Kafka Streams and Akka Streams. These data-oriented stacks implement the low-level complexity and take care of the resilience of the application execution. In turn, they offer a high-level abstraction to enable developers to focus on delivering business value.\nTo run our applications, we require computing system resources like CPU, memory, disk, and network bandwidth to be allocated to the critical data services that power the applications. When we work on a single machine, the operating system takes care of managing the resources allocated to applications. But when we run on a cluster of machines, how can we perform the resource management required by this new generation of distributed data-intensive applications?\nCluster managers, such as Apache Mesos, are an abstraction that runs on top of any computing infrastructure (public/private cloud, VM, bare metal) to provide a single unified resource pool across multiple infrastructures. Mesos achieves that unification by aggregating the infrastructure resources, and then offering resources slices, like x CPUs, y MB RAM, and z GB disk, to applications. Applications are then able to accept or reject those resources based on their own needs. Mesos can provide resources to execute applications and data services such as Apache Kafka, Apache Spark, and HDFS, or container schedulers such as Kubernetes.\nDeploying a cluster management solution like Mesosphere DC/OS helps us take advantage of Mesos to deliver a complete fast-data platform by adding the deployment of standard components, providing a runtime for applications and delivering foundational services such as security and user management. It enables unbounded scalability as more commodity or specialized hardware can be seamlessly added to existing clusters.\nThis results in increased enterprise agility as resources can be dynamically redirected to support the varying demands of different applications.\nConclusion\nFast data applications are becoming a key asset for enterprises to adopt as they develop competitive advantages in a world where actionable insights need to be produced and consumed in real time.\nBuilding fast data architectures that deliver scalable and resilient real-time applications is a challenging undertaking. The five recommendations that we have collected in this post should help you in your journey from requirements capture to cluster-wide deployment.\nA successful implementation of the fast data architecture will give your business the ability to accelerate its data-driven innovation by creating an environment to dynamically create, deploy, and operate end-to-end data-intensive applications. In turn, you will gain increased competitive advantage and the agility to react to your specific market challenges.\nThis post is a collaboration between O'Reilly and Mesosphere. See our statement of editorial independence.\nContinue reading 5 tips for architecting fast data applications.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/FAy1Wwr46Sw/5-tips-for-architecting-fast-data-applications"
 },
 {
  "title": "What becomes of the broken hearted? Blueprint of a donor-free world using custom heart technologies",
  "content": "Advances in 3D-printing technology have the potential to lower the cost and increase the availability of organ transplants.\nImagine feeling like you ran a marathon when you\u2019re actually just getting off the couch.  Imagine the extreme anxiety you might experience from living with bouts of dizziness, chest pain, and accelerated heartbeat until a doctor explains to you that these symptoms are not \u201cnothing\u201d, and that in fact, you have cardiomyopathy. This condition could lead to heart failure and eventually a heart transplant, but this desperately needed organ may not be available in time.\nOrgan transplants are in high demand in the United States. The heart is the third most requested organ, with 4,000 candidates on the waitlist and over 2,000 heart transplant surgeries performed in 2017.Continue reading What becomes of the broken hearted? Blueprint of a donor-free world using custom heart technologies.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/jO-w4_kQSdc/what-becomes-of-the-broken-hearted-blueprint-of-a-donor-free-world-using-custom-heart-technologies"
 },
 {
  "title": "Four short links: 4 April 2018",
  "content": "Forum Software, Data Analytics, Datalog Query, and Online != High-Tech\n\nSpectrum -- open source forum software. (via announcement)\n\nMacroBase -- a data analytics tool that prioritizes attention in large data sets using machine learning [...] specialized for one task: finding and explaining unusual or interesting trends in data.\n\n\ndatahike -- a durable database with an efficient datalog query engine.\n\n\nWhy So Many Online Mattress Brands -- trigger for a rant: software is eating everything, but that doesn't make everything an innovative company. If you're applying the online sales playbook to product X (kombucha, mattresses, yoga mats) it doesn't make you a Level 9 game-changing disruptive TechCo, it makes you a retail business keeping up with the times. I'm curious where the next interesting bits of tech are\u2014@gnat me with your ideas.\n\nContinue reading Four short links: 4 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Yjt_S8HBnTg/four-short-links-4-april-2018"
 },
 {
  "title": "100+ new live online trainings just launched on O'Reilly's learning platform",
  "content": "Get hands-on training in AWS, Python, Java, blockchain, management, and many other topics.Develop and refine your skills with 100+ new live online trainings we opened up for April and May on our learning platform.\nSpace is limited and these trainings often fill up.\nCreating Serverless APIs with AWS Lambda and API Gateway, April 6\nGetting Started with Amazon Web Services (AWS), April 19-20\nPython Data Handling: A Deeper Dive, April 20\nHow Product Management Leads Change in the Enterprise, April 23\nBeyond Python Scripts: Logging, Modules, and Dependency Management, April 23\nBeyond Python Scripts: Exceptions, Error Handling, and Command-Line Interfaces, April 24\nGetting Started with Go, April 24-25\nEnd-to-End Data Science Workflows in Jupyter Notebooks, April 27\nGetting Started with Vue.js, April 30\nJava Full Throttle with Paul Deitel: A One-Day, Code-Intensive Java Standard Edition Presentation, April 30\nBuilding a Cloud Roadmap, May 1\nGit Fundamentals, May 1-2\nAWS Certified SysOps Administrator (Associate) Crash Course , May 1-2\nOCA Java SE 8 Programmer Certification Crash Course, May 1-3\nGetting Started with DevOps in 90 Minutes, May 2\nLearn the Basics of Scala in 3 hours, May 2\nIPv4 Subnetting, May 2-3\nSQL Fundamentals for Data, May 2-3\nSAFe 4.5 (Scaled Agile Framework) Foundations, May 3\nManaging Team Conflict, May 3\nHands-On Machine Learning with Python: Clustering, Dimension Reduction, and Time Series Analysis, May 3\nGoogle Cloud Platform Professional Cloud Architect Certification Crash Course, May 3-4\nCyber Security Fundamentals, May 3-4\nAdvanced Agile: Scaling in the Enterprise, May 4\nNetwork Troubleshooting Using the Half Split and OODA, May 4\nSoftware Architecture for Developers, May 4\nHands-On Machine Learning with Python: Classification and Regression, May 4\nBuilding and Managing Kubernetes Applications, May 7\nIntroducing Blockchain, May 7\nGet Started with NLP, May 7\nIntroduction to Digital Forensics and Incident Response (DFIR), May 7\nEssential Machine Learning and Exploratory Data Analysis with Python and Jupyter Notebooks, May 7-8\nBuilding Deployment Pipelines with Jenkins 2, May 7 and 9\nIntroduction to Apache Spark 2.x, May 7-9\nDeep Learning Fundamentals, May 8\nAcing the CCNA Exam, May 8\nEmotional Intelligence for Managers, May 8\nScala Core Programming: Methods, Classes, and Traits, May 8\nDesign Patterns Boot Camp, May 8-9\nIntroduction to Lean, May 9\nBeginner\u2019s Guide to Creating Prototypes in Sketch, May 9\nAWS Certified Solutions Architect Associate Crash Course, May 9-10\nCloud Native Architecture Patterns, May 9-10\nAmazon Web Services: Architect Associate Certification - AWS Core Architecture Concepts, May 9-11\nBlockchain Applications and Smart Contracts, May 10\nDeep Reinforcement Learning, May 10\nGetting Started with Machine Learning, May 10\nIntroduction to Ethical Hacking and Penetration Testing, May 10-11\nExplore, Visualize, and Predict using pandas and Jupyter, May 10-11\nScalable Web Development with Angular, May 10-11\nApache Hadoop, Spark, and Big Data Foundations, May 11\nVisualizing Software Architecture with the C4 Model, May 11\nWrite Your First Hadoop MapReduce Program, May 14\nWrite Your First Spark Program in Java, May 14\nInteractive Java with Java 9\u2019s JShell, May 14\nBash Shell Scripting in 3 Hours, May 14\nLearn Linux in 3 Hours, May 14\nCybersecurity Blue Teams vs. Red Teams, May 14\nNext-Generation Java testing with JUnit 5, May 14\nProduct Management in Practice, May 14-15\nIoT Fundamentals, May 14-15\nPorting from Python 2 to Python 3, May 15\nRed Hat Certified System Administrator (RHCSA) Crash Course, May 15-18\nIntroduction to Analytics for Product Managers, May 16\nArchitecture Without an End State, May 16-17\nDeploying Container-Based Microservices on AWS, May 16-17\nAgile for Everybody, May 17\nIntroduction to Google Cloud Platform, May 17\nPractical Data Cleaning with Python, May 17-18\nHands-on Introduction to Apache Hadoop and Spark Programming, May 17-18\nTroubleshooting Agile, May 18\nManaging your Manager, May 18\nBuilding Chatbots with AWS, May 18\nYour First 30 Days as a Manager, May 21\nIntroduction to Unreal Engine 4 with Blueprints, May 21\nIntroduction to Critical Thinking, May 21\nTesting and Validating Product Ideas with Lean, May 21\nFrom Developer to Software Architect, May 22-23\nCISSP Crash Course, May 22-23\nIntroduction to Kubernetes, May 22\nCCNP R/S ROUTE (300-101) Crash Course, May 22-24\nAdvanced SQL for Data Analysis (with Python, R, and Java), May 23\nDocker: Beyond the Basics (CI & CD), May 23-24\nIntroduction to TensorFlow, May 23-24\nLeadership Communication Skills for Managers, May 24\nCyber Security Defense, May 24\nEnd-to-End Data Science Workflows in Jupyter Notebooks, May 24\nThe DevOps Toolkit, May 24-25\nIntroduction to Cisco Next-Generation Firewalls, May 24-25\nAmazon Web Services: Architect Associate Certification - AWS Core Architecture Concepts, May 24-25\nKubernetes in 3 Hours, May 25\nAnsible in 3 Hours, May 25\nDesign Fundamentals for Non-Designers, May 25\nPython Data Handling - A Deeper Dive, May 29\nIntroduction to Modularity with the Java 9 Platform Module System (JPMS), May 29\nCCNA Security Crash Course, May 29-30\nScala: Beyond the Basics, May 29-30\nMicroservices Architecture and Design, May 29-30\nDocker: Up and Running, May 29-30\nHigh Performance TensorFlow in Production: Hands on with GPUs and Kubernetes, May 29-30\nRethinking REST: A Hands-On Guide to GraphQL and Queryable APIs, May 30\nPMP Crash Course, May 31-June 1\nTest Driven Development in Java, May 31-June 1\nArchitecture Without an End State, May 31-June 1\nBuilding Microservices with Spring Boot, Spring Cloud, and Cloud Foundry, July 2-3\nVisit our learning platform for more information on these and other live online trainings.\nContinue reading 100+ new live online trainings just launched on O'Reilly's learning platform.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/lOpaYkY_QT8/100-plus-new-live-online-trainings-just-launched-on-oreillys-learning-platform"
 },
 {
  "title": "It's time to rebuild the web",
  "content": "The web was never supposed to be a few walled gardens of concentrated content owned by a few major publishers; it was supposed to be a cacophony of different sites and voices.Anil Dash's \"The Missing Building Blocks of the Web\" is an excellent article about the web as it was supposed to be, using technologies that exist but have been neglected or abandoned. It's not his first take on the technologies the web has lost, or on the possibility of rebuilding the web, and I hope it's not his last. And we have to ask ourselves what would happen if we brought back those technologies: would we have a web that's more humane and better suited to the future we want to build?\nI've written several times (and will no doubt write more) about rebuilding the internet, but I've generally assumed the rebuild will need peer-to-peer technologies. Those technologies are inherently much more complex than anything Dash proposes. While many of the technologies I'd use already exist, rebuilding the web around blockchains and onion routing would require a revolution in user interface design to have a chance; otherwise it will be a playground for the technology elite. In contrast, Dash's \"missing building blocks\" are fundamentally simple. They can easily be used by people who don't have a unicorn's worth of experience as web developers and security administrators.\nDash writes about the demise of the View Source browser feature, which dispays the HTML from which the web page is built. View Source isn't dead, but it's sick. He's right that the web succeeded, in part, because people with little background could look at the source for the pages they liked, copy the code they wanted, and end up with something that looks pretty good. Today, you can no longer learn by copying; while View Source still exists on most browsers, the complexity of modern web pages have made it next to useless. The bits you want are wrapped in megabytes (literally) of JavaScript and CSS.\nBut that doesn't have to be the end of the story. HTML can be functional without being complex. Most of what I write (including this piece) goes into a first draft as very simple HTML, using only a half-dozen tags. Simple editors for basic web content still exist. Dash points out that Netscape Gold (the paid version of Netscape) had one, back in the day, and that there are many free editors for basic HTML. We'd have to talk ourselves out of the very complex formatting and layout that, after all, just gets in the way. Ask (almost) any designer: simplicity wins, not a drop-dead gorgeous page. We may have made View Source useless, but we haven't lost simplicity. And if we make enough simple sites, sites from which viewers can effectively copy useful code, View Source will become useful again, too. You can't become a web developer by viewing Facebook's source; but you might by looking at a new site that isn't weighed down by all that CSS and JavaScript.\nThe web was never supposed to be a few walled gardens of concentrated content owned by Facebook, YouTube, Twitter, and a few other major publishers. It was supposed to be a cacophony of different sites and voices. And it would be easy to rebuild this cacophony\u2014indeed, it never really died. There are plenty of individual sites out there still, and they provide some (should I say most?) of the really valuable content on the web. The problem with the megasites is that they select and present \"relevant\" content to us. Much as we may complain about Facebook, selecting relevant content from an ocean of random sites is an important service. It's easy for me to imagine relatives and friends building their own sites for baby pictures, announcements, and general talk. That's what we did in the 90s. But would we go to the trouble of reading those all those sites? Probably not. I didn't in the 90s, and neither did you.\nWe already have a tool for solving this problem. RSS lets websites provide \"feeds\" of news and new items. Applications like Feedly and Reeder let you build a collection of sites that interest you, and show you what's changed since the last time you visited. While I'd never check a dozen sites each day, I use Feedly to monitor hundreds of websites. I would never check those sites by hand, but I scan Feedly every morning. And, unlike Facebook, Feedly doesn't know anything about its users except for the sites they read.\nFeedly has a decent user interface, though it could be a improved; it would have to be better to become popular with people who aren't technically literate. (Sorry.) Still, though, the UI gap for RSS is much smaller than for technologies like TOR. And if we're going to rebuild the net, we'll probably be better off choosing simple rather than bright, shiny, and complex technologies. Could someone build an RSS reader that made the web of independent sites as approachable as Facebook? I don't see why not\u2014and users would have complete control over what they see. That's important; in a recent tweet, Dash says:\nGoogle\u2019s decision to kill Google Reader [their RSS client] was a turning point in enabling media to be manipulated by misinformation campaigns. The difference between individuals choosing the feeds they read and companies doing it for you affects all other forms of media.\nYes, there would still be plenty of sites for every conspiracy theory and propaganda project around; but in a world where you choose what you see rather than letting a third party decide for you, these sites would have trouble gaining momentum.\nI don't want to underestimate the difficulty of this project, or overestimate its chances of success. We'd certainly have to get used to sites that aren't as glossy or complex as the ones we have now. We might have to revisit some of the most hideous bits of the first-generation web, including those awful GeoCities pages. We would probably need to avoid fancy, dynamic websites; and, before you think this will be easy, remember that one of the first extensions to the static web was CGI Perl. We would be taking the risk that we'd re-invent the same mistakes that brought us to our current mess. Simplicity is a discipline, and not an easy one. However, by losing tons of bloat, we'd end up with a web that is much faster and more responsive than what we have now. And maybe we'd learn to prize that speed and that responsiveness.\nWe'd also need to avoid many of the privacy and security flaws that were rampant in the early internet, and for which we're still paying. That technical debt came due a long time ago. Paying off that debt may require some complex technology, and some significant UI engineering. All too often, solutions to security problems make things more difficult for both users and attackers. Crowdflare's new 1.1.1.1 service addresses some basic problems with our DNS infrastructure and privacy, and their CEO proposes some more basic changes, like DNS over HTTPS. But even simple changes like this require non-technical users to change configuration settings that they don't understand. This is where we really need the help of UX designers. We can't afford to make \"safe\" difficult.\nAnd we'd have to admit that our current web, with all its flaws, evolved from these simple building blocks. To some extent, then, it's what we wanted\u2014or, perhaps, what we deserved. It's certainly what we accepted, and begs the question: \"why wouldn't we accept the same thing again?\" Starting over means little if we're destined to repeat the mistakes we've already made. So, we would need to develop and incorporate technology for preventing abuse; we would need to build a public space that really is a public space, not someone else's private property; and above all, we would need to divest ourselves of the arrogance that assumes \"because we've built it, it is good.\" As Dash said six years ago, well before Facebook's Very Bad Month, we would need to \"take responsibility and accept blame.\"\nRegardless of how it happens, it's time to start thinking about rebuilding the web. That project is only likely to succeed if the rebuilt web is compatible with what we have today, including Facebook and YouTube. And it's only likely to succeed if it's simple enough for anyone to use. Anil Dash has outlined a way forward. It's not what I would have suggested, but it has a much higher chance of succeeding. Time to (re)build it.\nContinue reading It's time to rebuild the web.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/POr_sH3BkzI/its-time-to-rebuild-the-web"
 },
 {
  "title": "It\u2019s time for data ethics conversations at your dinner table",
  "content": "In an era where fake news travels faster than the truth, our communities are at a critical juncture.With 2.5 quintillion records of data created every day, people are being defined by how they travel, surf the internet, eat, and live their lives. We are in the midst of a \u201cdata revolution,\u201d where individuals and organizations can store and analyze massive amounts of information. Leveraging data can allow for surprising discoveries and innovations with the power to fundamentally alter society: from applying machine learning to cancer research to harnessing data to create \u201csmart\u201d cities, data science efforts are increasingly surfacing new insights\u2014and new questions.\nWorking with large databases, new analytical tools, and data-enabled methods promises to bring many benefits to society. However, \u201cdata-driven technologies also challenge the fundamental assumptions upon which our societies are built,\u201d says Margo Boenig-Liptsin, co-instructor of UC Berkeley\u2019s \u201cHuman Contexts and Ethics of Data\u201d course. Boenig-Liptsin notes, \u201cIn this time of rapid social and technological change, concepts like \u2018privacy,\u2019 \u2018fairness,\u2019 and \u2018representation\u2019 are reconstituted.\u201d Indeed, bias in algorithms may favor some groups over others, as evidenced by notorious cases such as the finding by MIT Researcher Joy Buolamwini that certain facial recognition software fails to work for those with dark skin tones. Moreover, lack of transparency and data misuse at ever-larger scales has prompted calls for greater scrutiny on behalf of more than 50 million Facebook users.\nIn an era where fake news travels faster than the truth, our communities are at a critical juncture, and we need to be having difficult conversations about our individual and collective responsibility to handle data ethically. These conversations, and the principles and outcomes that emerge as a result, will benefit from being intentionally inclusive.\nWhat does responsible data sharing and use look like\u2014for a data scientist, a parent, or a business? How are our socioeconomic structures and methods of interaction shaping behavior? How might we ensure that our technologies and practices are fair and unbiased?\nOne idea that has gained traction is the need for a \u2018Hippocratic Oath\u2019 for data scientists. Just as medical professionals pledge to \u201cdo no harm,\u201d individuals working with data should sign and abide by one or a set of pledges, manifestos, principles, or codes of conduct. At Bloomberg\u2019s Data for Good Exchange (D4GX) in New York City in September 2017, the company announced a partnership with Data for Democracy and BrightHiveto bring the data science community together to explore this very topic. More than 100 volunteers from universities, nonprofits, local and federal government agencies, and tech companies participated, drafting a set of guiding principles that could be adopted as a code of ethics. Notably, this is an ongoing and iterative process that must be community driven, respecting and recognizing the value of diverse thoughts and experiences.\nThe group re-convened on February 6, 2018, at the inaugural D4GX event in San Francisco, again open to the public. Notable attendees included DJ Patil, who served as the chief data scientist of the United States from 2015-2017, Doug Cutting, co-creator of Hadoop and advocate for open source, as well as representation from the National Science Foundation-funded Regional Big Data Innovation Hubs and Spokes program. At this event, participants reviewed more than 75 drafted ethics principles formulated by several working groups, with the goal of distilling a larger group of tenets into a streamlined set of principles for an ethics code.\nEfforts such as Bloomberg\u2019s D4GX can be situated in a growing movement, with increased interest in the ethical aspects of technology, particularly related to advances in data science and artificial intelligence (AI) systems. For example, AI Now 2017, IEEE, The Future of Life Institute, Metro Lab Network, the ACM, and the Oxford Internet Institute have all issued reports on these topics. Plus, Microsoft\u2019s Brad Smith and Harry Shum published a book entitled The Future Computed: Artificial intelligence and its role in society earlier this year.\nA recent National Science Foundation grant focusing on the responsible use of big data was awarded to a group of researchers led by Julia Stoyanovich, an assistant professor at Drexel University, who has participated regularly in D4GX events in New York and San Francisco. The goal of this research project is to understand how legal and ethical norms can be embedded into technology, and to create tools that enable responsible collection, sharing, and analysis of data. These issues have also been a topic of discussion at multiple recent workshops. Last week, a workshop at the National Academy of Sciences focused on ethics and data in the context of international research collaborations. Similarly, another recent workshop on fairness in machine learning aimed to identify key challenges and open questions that limit fairness, both in theory and in practice.\nAs noted in the AI Now 2017 report, there are powerful incentives for the commercial sector to disregard these initiatives in favor of business as usual. It is not clear how compliance and accountability could be incentivized, monitored, or enforced in both the public and private sectors, although new European Union regulations pertaining to data privacy will affect organizations globally beginning in May 2018. \u201cTop-down\u201d regulations as well as \u201cgrassroots\u201d efforts are increasingly raising questions about how we might define fairness, combat bias, and create ethics guidelines in data science and AI.\nYet, widespread adoption of ethical data collection and data analysis practices requires more than business penalties and awareness of these issues on the part of data science practitioners and the general public. Ultimately, data scientists and our broader community of data users must be equipped with the right tools and methodologies, and help each other leverage guidance effectively. Boenig-Liptsin notes, \u201cWe need to understand how our values shape our data tools and, reciprocally, how our data tools inform our values.\u201d Successful efforts will require thoughtful and sustainable collaboration to apply insights and refine solutions.\nWe are seeing an increasing number of data practitioners and leaders stand up and speak about the questionable and often outright illegal collection, sharing, and use of sensitive data. For their voices to drive change, and for our society to truly harness the positive impacts of data innovation, while mitigating unintended consequences, we will need a collective effort. This effort needs to reach beyond academia and policymakers to anyone who can contribute\u2014from both the public and private sectors.\nOur community needs to collectively voice expectations for responsible data use, bringing data practitioners together to examine existing research and evidence. By creating environments, curricula, and tools that support community dialogue around ethics challenges, we can hope to translate findings into actionable principles\u2014and to hold each other accountable. In addition to working with regulatory bodies, the shaping of social norms can transform these principles into enforceable standards for the responsible use of data. As Barbara C. Jordan, a former member of the U.S. House of Representatives from Texas, and professor of ethics at the University of Texas at Austin, eloquently stated in 1976:\n\nThere is no executive order; there is no law that can require the American people to form a national community. This we must do as individuals, and if we do it as individuals, there is no President of the United States who can veto that decision... We must define the 'common good' and begin again to shape a common future.\n\nFully harnessing the data revolution requires that we not only explore what can be done with data, but also that we understand the broader impacts of how any individual or organization\u2019s contribution affects others. We should be having these conversations early and often, bringing in a diverse range of perspectives. We should be having these conversations not just at academic conferences and in tech and ethics courses, but around dinner tables, everywhere.\nContinue reading It\u2019s time for data ethics conversations at your dinner table.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/jPVnvLAOl3Q/its-time-for-data-ethics-conversations-at-your-dinner-table"
 },
 {
  "title": "How companies around the world apply machine learning",
  "content": "Strata Data London will introduce technologies and techniques; showcase use cases; and highlight the importance of ethics, privacy, and security.The growing role of data and machine learning cuts across domains and industries. Companies continue to use data to improve decision-making (business intelligence and analytics) and for automation (machine learning and AI). At the Strata Data Conference in London, we\u2019ve assembled a program that introduces technologies and techniques, showcases use cases across many industries, and highlights the importance of ethics, privacy, and security.\n\n\nWe are bringing back the Strata Business Summit, and this year, we have two days of executive briefings.\n\n\nData Science and Machine Learning sessions will cover tools, techniques, and case studies. This year, we have many sessions on managing and deploying models to production, and applications of deep learning in enterprise applications.\n\n\nThis year\u2019s sessions on Data Engineering and Architecture showcases streaming and real-time applications, along with the data platforms used at several leading companies.\n\n\nPrivacy and security\nThe enforcement date for the General Data Protection Regulation (GDPR) is the day after the end of the conference (May 25, 2018) and for the past few months, companies have been scrambling to learn this new set of regulations. We have a tutorial and sessions to help companies learn how to comply with GDPR. Implementing data security and privacy remain foundational, but one of the key changes advanced by GDPR\u2014\u201cprivacy-by-design\u201d\u2014will require companies to reassess how they design and architect products.\n\n\nSecurity and Privacy sessions\n\n\nVisualization, Design, and UX sessions\n\n\nUnlocking popular data types: Text, temporal data, and graphs\nThe need for scaleout and streaming infrastructure can often be traced back to the importance of text, temporal data, and graphs. After one sets up infrastructure for collecting, storing, and querying these data types, the next step is to uncover interesting patterns or to use them to make predictions. Over the past year, companies have been turning to machine learning, in many cases to deep learning, when faced with large amounts of text, graphs, or temporal data. On the infrastructure side, we have sessions from members of some of the leading stream processing and storage communities.\n\n\nText and Natural Language sessions\n\n\nTime-series and Graphs sessions\n\n\nStream Processing and Real-time Applications sessions\n\n\nData platforms\nHow do some of the best companies architect and develop data platforms that help accelerate innovation and digital transformation? In a series of sessions, companies will share their internal platforms for business intelligence and machine learning. These are battle-tested platforms used in production, some at extremely large scale. \nMany of these data platforms encourage collaboration and sharing of data, features, and models. In addition, since we\u2019re very much in an empirical era for machine learning, tools for running and reproducing experiments, and for exploring the space of algorithms, are essential. Security and privacy become even more critical in light of the upcoming enforcement date for GDPR.\n\n\nData Platforms sessions\n\n\nMachine learning: From data preparation and integration, to model deployment and management\nMedia articles on machine learning over emphasize algorithms and models. The reality is that model building is just one aspect of building products that rely on machine learning. In a vast majority of cases, machine learning applications require training data (\u201clabeled data is the new, new oil\u201d). To that end, the first step is to bring together existing data sources and when appropriate, enrich them with other data sets. In most cases, data needs to be refined and prepared before it\u2019s ready for analytic applications.\nWhile prototypes are easy to cook up, building production-grade applications requires serious engineering. Companies have come to realize that deploying, monitoring, and managing models in production requires different skills and a different mindset. So much so that a new breed of workers, machine learning engineers, was recently forecasted to be the fastest growing, emerging job in 2018.\n\n\nManaging and Deploying Machine Learning sessions\n\n\nData Integration and Data Pipelines sessions\n\n\nIndustry- and domain-specific tools, methods, and use cases\nThe best way to understand the potential of data technologies and machine learning is to see how companies are using them in real-world applications. One of the great things about Strata Data London is that one gets to hear case studies from many different industries and countries. You will learn how a variety of companies from across the globe have designed their data infrastructures; how they are incorporating machine learning; and how they\u2019re approaching data privacy, security, and ethics. This year, we have keynotes and sessions on important topics in public policy, health care, manufacturing, and many other sectors of the economy. Here are some examples:\n\n\nData Case Studies (12 presentations)\n\n\nFindata Day and Financial Services sessions\n\n\nMedia and Advertising sessions\n\n\nE-commerce, and Transportation and Logistics sessions\n\n\nTelecom sessions\n\n\nThe Strata Data Conference is happening in London from May 21-24, 2018\u2014best price ends April 6.\nContinue reading How companies around the world apply machine learning.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/hbg9aPjilzI/how-companies-around-the-world-apply-machine-learning"
 },
 {
  "title": "Four short links: 3 April 2018",
  "content": "Internet of Battle Things, Program Fuzzing, Data Sheets for Data Sets, and Retro Port\n\nChallenges and Characteristics of Intelligent Autonomy for Internet of Battle Things in Highly Adversarial Environments -- Numerous artificially intelligent, networked things will populate the battlefield of the future, operating in close collaboration with human warfighters, and fighting as teams in highly adversarial environments. This paper explores the characteristics, capabilities, and intelligence required of such a network of intelligent things and humans\u2014Internet of Battle Things (IOBT). It will experience unique challenges that are not yet well addressed by the current generation of AI and machine learning. (via Slashdot)\n\nT-Fuzz: Fuzzing by Program Transformation -- clever! To improve coverage, existing approaches rely on imprecise heuristics or complex input mutation techniques (e.g., symbolic execution or taint analysis) to bypass sanity checks. Our novel method tackles coverage from a different angle: by removing sanity checks in the target program. T-Fuzz leverages a coverage-guided fuzzer to generate inputs. Whenever the fuzzer can no longer trigger new code paths, a lightweight, dynamic tracing-based technique detects the input checks that the fuzzer-generated inputs fail. These checks are then removed from the target program. Fuzzing then continues on the transformed program, allowing the code protected by the removed checks to be triggered and potential bugs discovered.\n\n\nData Sheets for Data Sets -- Currently there is no standard way to identify how a data set was created, and what characteristics, motivations, and potential skews it represents. To begin to address this issue, we propose the concept of a data sheet for data sets, a short document to accompany public data sets, commercial APIs, and pretrained models.\n\n\nPorting Prince of Persia to the BBC Master -- the author of the original 1980s game, Jordan Mechner, found and posted the source code to the Apple II version. These fine folks ported it to a different 1980s computer. I love the creativity of people who hack on small retro systems. I find big web stuff lacks that these days: it's all up-to-your-elbows in frameworks.\n\nContinue reading Four short links: 3 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/rtT2vajk28Y/four-short-links-3-april-2018"
 },
 {
  "title": "Four short links: 2 April 2018",
  "content": "Game Networking, Grep JSON, Voting Ideas, and UIs from Pictures\n\nValve's Networking Code -- a basic transport layer for games. The features are: connection-oriented protocol (like TCP)...but message-oriented instead of stream-oriented; mix of reliable and unreliable messages; messages can be larger than underlying MTU, the protocol performs fragmentation and reassembly, and retransmission for reliable; bandwidth estimation based on TCP-friendly rate control (RFC 5348); encryption; AES per packet, Ed25519 crypto for key exchange and cert signatures; the details for shared key derivation and per-packet IV are based on Google QUIC; tools for simulating loss and detailed stats measurement.\n\n\ngron -- grep JSON from the command line.\n\nThe Problem With Voting -- I don't agree with all of the analysis, but the proposed techniques are interesting. I did like the term \"lazy consensus\" where consensus is assumed to be the default state (i.e., \u201cdefault to yes\u201d). The underlying theory is that most proposals are not interesting enough to discuss. But if anyone does object, a consensus seeking process begins. (via Daniel Bachhuber)\n\npix2code -- open source code that generates Android, iOS, and web source code for a UI from just a photo. It's not coming for your job any time soon (over 77% of accuracy), but it's still a nifty idea. (via Two Minute Papers)\n\nContinue reading Four short links: 2 April 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/lGbSuXSAv4s/four-short-links-2-april-2018"
 },
 {
  "title": "6 creative ways to solve problems with Linux containers and Docker",
  "content": "An outside-the-box exploration of how containers can be used to provide novel solutions.Most people are introduced to Docker and Linux containers as a way to approach solving a very specific problem they are experiencing in their organization. The problem they want to solve often revolves around either making the dev/test cycle faster and more reliable while simultaneously shortening the related feedback loops, or improving the packaging and deploying of applications into production in a very similar fashion. Today, there are a lot of tools in the ecosystem that can significantly decrease the time it takes to accomplish these tasks while also vastly improving the ability of individuals, teams, and organizations to reliably perform repetitive tasks successfully.\nThat being said, tools have become such a big focus in the ecosystem that there are many people who haven\u2019t really spent much time thinking about all the ways containers alone can provide interesting solutions to problems that can occur in the course of any technical task.\nTo get the creative juices flowing and help folks start thinking outside the box, we\u2019ll examine a few scenarios and explore how containers can be used to provide possible solutions. You'll notice that many of these examples utilize file mounts to access data stored on local machines.\nNote that all of these were tested on Mac OS X running a current stable release of Docker: Community Edition. Also, most of the examples assume you have a unix-based operating system, but they can often be adjusted to work on Windows.\n\nPreparation\nIf you are planning on running these examples, go ahead and download the following images ahead of time so you can see how the commands run without the additional time required to pull down the images the first time:\n$ docker pull acleancoder/imagemagick-full:latest\n$ docker pull jasperla/docker-go-cross:latest\n$ docker pull spkane/dell-openmanage:latest\n$ docker pull debian:latest\n$ docker pull spkane/train-os:latest\n$ docker pull alpine:latest\n$ docker pull jess/firefox:latest\n\n\nScenario 1\n\nUsing containers for console commands\nThere are often applications that are very useful to have but don't run or are very difficult to compile on the platform we are using. Containers can provide a very easy way to run these applications, despite the apparent barriers (and even if we can run the application natively, containers can be a very compelling approach to packaging and distributing programs). In this example, we are using an ImageMagick container to resize an image. Although this particular example is easy to accomplish in other ways, it should give some insight into how a container can be used to take advantage of a wide variety of similar console-based tools.\n$ curl -o docker.png \\\n  https://www.docker.com/sites/default/files/vertical-whitespace.png\n$ ls\n$ docker run -ti -v $(pwd):/data acleancoder/imagemagick-full:latest \\\n  convert /data/docker.png -resize 50% /data/half_docker.png\n$ ls\n\n\n\n\nScenario 2\n\nUsing containers for development environments\n\n\nHave you ever needed to set up your development environment at a new job or on a new computer and struggled to get it right?\n\n\nHave you ever had problems because your development and Q/A environments used slightly different versions of the compiler?\n\n\nBy using containers, it is possible to ensure your builds are repeatable, even for complex development environments. In this example, we are using a Docker image that contains a robust Go development environment to compile a small console game for Linux, OS X, and Windows.\n$ git clone https://github.com/spkane/go-paranoia.git\n$ cd go-paranoia/paranoia\n\n\nMac OS X\n$ docker run -ti --rm -e APPNAME=paranoia \\\n  -e GOLANG_TARGET_PLATFORM=\"darwin/amd64\" -v \"$(pwd):/go/src/app\" \\\n  jasperla/docker-go-cross\n$ ./paranoia-darwin-amd64\n\n\n\nLinux\n$ docker run -ti --rm -e APPNAME=paranoia \\\n  -e GOLANG_TARGET_PLATFORM=\"linux/amd64\" -v \"$(pwd):/go/src/app\" \\\n  jasperla/docker-go-cross\n$ ./paranoia-linux-amd64\n\n\n\nWindows\n> docker run -ti --rm -e APPNAME=paranoia \\\n  -e GOLANG_TARGET_PLATFORM=\"windows/amd64\" -v \"$(pwd):/go/src/app\" \\\n  jasperla/docker-go-cross\n> .\\paranoia-windows-amd64\n\n\n\n\n\nScenario 3\n\nUsing containers to solve OS version incompatibilities\nThis example will only work on a Linux server running on Dell hardware, but it provides a good example of how containers can make it easier to run certain classes of software.\nDell's OpenManage Server Administrator (OMSA) is critical for monitoring and configuring Dell hardware, but Dell supports only a few Linux distributions and can be slow to provide updates for newer releases. By using containers, we can ensure that OMSA is packaged with the Linux platform (e.g., CentOS 7) and libraries that it requires, while still having the freedom to run it on the Linux platform (e.g., CoreOS) that we require.\nIn the example below, we launch a container that runs continuously in the background with a few processes that Dell uses to facilitate communication between the Dell tools and the underlying hardware. We then wait 40 seconds while the container finishes starting up all the background process that it launches.\n$ docker run --privileged -d -p 161:161/udp -p 1311:1311 \\\n  --restart=always --net=host --name=omsa \\\n  -v /lib/modules/`uname -r`:/lib/modules/`uname -r` \\\n  spkane/dell-openmanage:latest\n$ sleep 40s\n\nOnce the container is running, we can utilize docker exec to treat the running container like a simple command line tool and query the hardware, just as if the OMSA tools were installed and running in a more traditional manner. With this command, we retrieve the chassis info.\n$ docker exec omsa omreport chassis info\n\nChassis Information\n\nIndex                                    : 0\nChassis Name                             : Main System Chassis\nHost Name                                : dell-host.example.net\niDRAC8 Version                           : 2.30.30.30 (Build 50)\nLifecycle Controller Version             : 2.30.30.30\nChassis Model                            : PowerEdge R430\nChassis Lock                             : Present\nChassis Service Tag                      : 245XWE2\nExpress Service Code                     : 0000924034\nChassis Asset Tag                        : Unknown\nFlash chassis identify LED state         : Off\nFlash chassis identify LED timeout value : 300\n\nAnd then we can immediately run another command to clear the ESM log, or whatever else we might need.\n$ docker exec omsa omconfig system esmlog action=clear\n\nEmbedded System Management (ESM) log cleared successfully.\n\n\n\n\nScenario 4\n\nUsing containers to explore the underlying host\nDocker: Community Edition (CE) does a great job of making the Docker server feel like it runs natively on Mac OS X and Windows. Honestly, it does too good a job. When you are first trying to learn how Docker works, it can actually be very deceiving because Docker: CE launches a lightweight Linux virtual machine (VM) on both of these platforms, but it is not obvious to the end user that this is the case, and there is no way to log in to this VM and take a look around. So, given all this, how do you learn more about how the Docker VM works?\nIn this scenario, we can utilize a partially privileged container and Linux namespaces to launch a container that will allow us to see all the processes that are running on the underlying host and explore its filesystem.\n$ docker run --rm -it --cap-add SYS_ADMIN --cap-add SYS_PTRACE \\\n  --pid=host debian:latest nsenter -t 1 -m -u -n -i sh\n\n/ # cat /etc/os-release\nPRETTY_NAME=\"Docker for Mac\"\n\n/ # exit\n\nNote: This is an important example of why running privileged containers in production can be very dangerous. Although we have only shared the host's PID namespace with this container and given it two Linux capabilities, it can easily access the host's underlying filesystem.\n\n\n\nScenario 5\n\nUsing containers to sidestep a read-only filesystem\nAnother quirk of Docker: Community Edition is that the virtual machine's root filesystem has been made read-only in recent releases. This was done to help prevent people from breaking Docker by fooling around inside the VM, utilizing techniques like the one we just showed. This is understandable since they need to be able to support their product in such a wide range of environments, but it can also be problematic.\nWhile teaching classes about Docker and specifically trying to demonstrate how Linux Control Groups (cgroups) impact the resources that are available to a container, it is often desirable to run a simple tool on the Linux host that makes it easy to monitor the processes that are running and see how they are performing. \nIn class, we will often run a container that stresses the underlying VM by generating some load on the CPU and memory so that we can see what effect it has on the underlying VM.\n$ docker run -d spkane/train-os:latest stress -v --cpu 2 --io 1 --vm 2 --vm-bytes 128M --timeout 480s\n\nA simple and visually appealing tool, like htop is ideal for observing the impact on the VM, but since the root filesystem of the virtual machine is read-only, there is no way to install htop directly into the VM. \n$ docker run --rm -it --cap-add SYS_ADMIN --cap-add SYS_PTRACE \\\n  --pid=host debian:latest nsenter -t 1 -m -u -n -i sh\n\n/ # apk update\nERROR: Unable to lock database: Read-only file system\nERROR: Failed to open apk database: Read-only file system\n\n/ # exit\n\nSo, instead of using the VM directly, we can run a container that shares the host's PID (process) namespace so that htop can see all the processes running on the host and allow us to understand how our stress program is impacting the Docker server.\n$ docker run --rm -it --pid=host alpine:latest sh\n\n/ # apk update\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gz\n...\nOK: 8437 distinct packages available\n\n/ # apk add htop\n(1/4) Installing ncurses-terminfo-base (6.0_p20171125-r0)\n...\nOK: 11 MiB in 15 packages\n\n/ # htop -p $(pgrep stress | tr '\\n' ',')   # Press q to exit\n\n/ # exit\n\n\n\nScenario 6\n\nUsing containers to run X11 graphical applications\nThis specific example is designed for Mac OS X, but it can be easily modified for Linux and Windows. On Windows, you will also need to install a third-party X11 server, like Xming, Cygwin/X or MobaXterm.\nOn Mac OS X, if you do not already have the homebrew package manager installed, you can get it from Homebrew.\nTo make this X11 container work, we need to prepare our system the first time by installing socat and Xquartz, an X11 server, on the Mac. Once Xquartz is installed, we need to reboot the Mac so that the X11 server is set up properly for the current user.\n$ brew install socat\n$ brew cask install xquartz\n$ shutdown -r now\n\nAfter this one-time setup, we can now run a Linux X11 graphical application by running socat to facilitate communication between the container and the Mac's X11 server, and then launching the desired container.\n$ socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\\\"$DISPLAY\\\" &\n$ IP=$(ifconfig en0 | grep inet | awk '$1==\"inet\" {print $2}')\n$ docker run -it --rm -e DISPLAY=${IP}:0 jess/firefox\n\nAfter a few moments you should see a usable Firefox browser window open on your system.\nNote: On the Mac, it is actually possible to set the DISPLAY to docker.for.mac.host.internal:0 instead of using the primary IP address. Also, don't forget to kill the socat process when you are done playing around with this.\n\n\n\nConclusion\nHopefully this article has helped expose you to some of the less obvious ways that containers can be used. I can't recommend enough that you take the time to become familiar with the underlying technologies that enable containers and how things like namespaces, cgroups, Linux capabilities, and even hardware virtualization can be combined to solve problems in new and creative ways.\n\nSean Kane will be teaching an in-depth, hands-on, two-day Docker workshop at the O'Reilly Velocity Conference in San Jose, June 11-14, 2018. During the first day, students will be introduced to Linux containers and Docker, with deep dives later in the day that will help explain the functionality that makes all of the above techniques possible. During the second day of the workshop, students will build a functional DevOps CI/CD pipeline using Docker and get hands-on experience with how Docker and Linux containers can be used to streamline processes, and improve both reliability and repeatability on projects. Register now to participate in this hands-on training.\n\n\n\n\nContinue reading 6 creative ways to solve problems with Linux containers and Docker.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/uC88mH5OUwA/6-creative-ways-to-solve-problems-with-linux-containers-and-docker"
 },
 {
  "title": "Four short links: 30 March 2018",
  "content": "Data Literacy, Data Science Readings, Bloated Data Architectures, and AI Ruins Everything\n\nData Defenders -- game for grade 4-6 that teaches children and pre-teens the concept of personal information and its economic value, and introduces them to ways to manage and protect their personal information on the websites and apps they enjoy. (via BoingBoing)\n\nReadings in Applied Data Science -- pointers to interesting papers, via Hadley Wickham's Stanford class.\n\nCOST: Configuration that Outperforms a Single Thread -- The COST of a given platform for a given problem is the hardware configuration required before the platform outperforms a competent single-threaded implementation. [...] We survey measurements of data-parallel systems recently reported in SOSP and OSDI, and find that many systems have either a surprisingly large COST, often hundreds of cores, or simply underperform one thread for all their reported configurations.\n\n\nFinding Alternative Musical Scales -- is there nothing that AI cannot improve/ruin? We search for alternative musical scales that share the main advantages of classical scales: pitch frequencies that bear simple ratios to each other, and multiple keys based on an underlying chromatic scale with tempered tuning. We conduct the search by formulating a constraint satisfaction problem that is well suited for solution by constraint programming. We find that certain 11-note scales on a 19-note chromatic stand out as superior to all others. These scales enjoy harmonic and structural possibilities that go significantly beyond what is available in classical scales and therefore provide a possible medium for innovative musical composition. (via Mark J. Nelson)\n\nContinue reading Four short links: 30 March 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/cvoY43pM-y8/four-short-links-30-march-2018"
 },
 {
  "title": "What machine learning engineers need to know",
  "content": "The O\u2019Reilly Data Show Podcast: Jesse Anderson and Paco Nathan on organizing data teams and next-generation messaging with Apache Pulsar.In this episode of the Data Show, I spoke with\u00a0Jesse Anderson, managing director of the Big Data Institute, and my colleague Paco Nathan, who recently became co-chair of Jupytercon. This conversation grew out of a recent email thread the three of us had on machine learning engineers, a new job role that LinkedIn recently pegged as the fastest growing job in the U.S. In our email discussion, there was some disagreement on whether such a specialized job role/title was needed in the first place. As Eric Colson pointed out in his beautiful keynote at Strata Data San Jose, when done too soon, creating specialized roles can slow down your data team.Continue reading What machine learning engineers need to know.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/0T4QvUO0r6k/what-machine-learning-engineers-need-to-know"
 },
 {
  "title": "UX challenges in the Internet of Things",
  "content": "A look the various ways the IoT asks consumers to think like programmers, and the risks inherent in exponentially increasing educators.Continue reading UX challenges in the Internet of Things.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/3QEaQCyj4_E/ux-challenges-in-the-internet-of-things"
 },
 {
  "title": "Four short links: 29 March 2018",
  "content": "Facebook Container, Publishing Future, Social Media Ethics, and Online Virality\n\nFacebook Container -- Firefox add-on that isolates your Facebook identity from the rest of your web activity. When you install it, you will continue to be able to use Facebook normally. Facebook can continue to deliver their service to you and send you advertising. The difference is that it will be much harder for Facebook to use your activity collected off Facebook to send you ads and other targeted messages.\n\n\nWhat's Coming for Online Publishing (Doc Searls) -- What will happen when the Times, the New Yorker, and other pubs own up to the simple fact that they are just as guilty as Facebook of leaking its readers\u2019 data to other parties, for\u2014in many if not most cases\u2014God knows what purposes besides \u201cinterest-based\u201d advertising? (via Piers Harding)\n\nAffiliate Marketing Not Disclosed on Social Media (Freedom to Tinker) -- Of all the YouTube videos and Pinterest pins that contained affiliate links, only ~10% and ~7% respectively contained accompanying disclosures. (paper)\n\nThe Structural Virality of Online Diffusion --  Indeed, the very label \u201cviral hit\u201d implies precisely the exponential spreading of the sort observed in contagion models in their supercritical regime. It is therefore notable that essentially everything we observe, including the very largest and rarest events, can be accounted for by a simple model operating entirely in the low infectiousness parameter regime.\n\n\nContinue reading Four short links: 29 March 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/LC2N2TJ_CzA/four-short-links-29-march-2018"
 },
 {
  "title": "A graphical user interface to build apps on top of microservices",
  "content": "How to enable non-programmer business users to create their own data applications.Companies are increasingly asking their IT staffs for rapid turn-around on tasks that require programming. The most likely path to attaining quick turn-around would be to let non-programmers create their own applications\u2014an approach that can be achieved with a combination of microservices, APIs, and graphical user interfaces (GUIs).\nThe goal of letting non-programmers manipulate data is an old one. When IBM released early versions of the SQL programming language, they intended it for business users. They really expected a mid-level manager to sit down in the morning and type UPDATE PRODUCT.SPEC SET WIDTH = 19, HEIGHT = 12, DEPTH = 4 WHERE PRODUCT_NUM LIKE 'GK145%' onto a green screen. More realistically, though, SQL was hidden behind various forms that eventually moved to the web. But these forms do not offer the full power of the language.\nVisual programming, using some technique such as moving boxes around a screen to create control flows, has also been researched for decades. It is best known in children's educational tools such as Alice and MIT's Scratch. The problem with trying to create large-scale applications using visual programming\u2014and the reason I'm guessing that visual programming hasn't won a large user base\u2014is that programming's complexity lies more in the mind than in the syntax. Exposing the complexity of control flow and math through boxes and lines doesn't make it easier than using words and punctuation.\nIt may be quite a different matter, however, when powerful chunks of functionality, already hooked up to an organization's data sets and control structure, are offered in a visual interface, also known as a \u201clow-code development platform.\u201d For instance, an auto insurance assessor can do something really useful if she can automate part of her job by drawing a line between client information and a tool that calculates how much to pay for each part of a car.\nWhere do microservices enter the picture? They work at a higher level than function or library calls, offering precise access to specific data and services in the organization. I talked about microservices with Bruno Trimouille, a senior marketing executive at TIBCO Software. He spoke of an airline that has microservices for travel services, customer profile data, flight information, and other elements of their workflow. Visual programming exposes all these things to the average employee. If someone in the luggage department thinks up an application that can find a bag more quickly or send a voucher to a customer's mobile phone, he can hook up services to create the application.\nThe low-code application environment can tap microservices to digitize a process that previously was done manually, such as submitting expenses or getting travel approval. It can also extend an existing system, or add some logic that stitches two microservices together.\nAs another example, Trimouille points to the problem of repricing in insurance. When an auto body shop takes apart a car, it often discovers new damage that the insurance assessor did not originally cover. The insurance company can upgrade its assessment tool to do repricing quickly and save both time and money.\nThus, microservices, APIs, and low-code application development may lead to a new level of productivity. They could provide end users with the deep reach into their corporate data promised by the classic UPDATE statement\u2014but now backed up by full insight into the structure and value of the data.\nThis post is a collaboration between O'Reilly and TIBCO. See our statement of editorial independence.\nContinue reading A graphical user interface to build apps on top of microservices.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/01-SocPxRug/a-graphical-user-interface-to-build-apps-on-top-of-microservices"
 },
 {
  "title": "Four short links: 28 March 2018",
  "content": "Business Logic, Digital Forgery, Twitter Demetricator, and ML for Kids\n\nThe Business Logic of Silicon Valley (Cory Doctorow) -- Selling hardware does not have exponential growth potential, because people only need so many sex toys, and really successful models are likely to be cloned or imitated, driving down the price. For a \"smart\" sex toy startup to cash out its investors, it will need to have a second, much more profitable business, and that, inevitably, is private data about sex toy users.\n\n\nCommoditization of AI, Digital Forgery, and the End of Trust -- Once tools for fabrication become a commodity, the effects will be more dramatic than the current phenomenon of fake news. In the tech circles, the issue are discussed only at a philosophical level; no clear solution is known at present time. This post discusses pros and cons of two classes of potential solutions: digital signatures and learning-based detection systems.\n\n\nTwitter Demetricator -- a Chrome interface that hides all the gamification numbers in Twitter.\n\nMachine Learning for Kids -- Each project is a stand-alone activity, written to last for a single lesson, and will guide children to create a game or interactive project that demonstrates a real-world use of artificial intelligence and machine learning.\n\n\nContinue reading Four short links: 28 March 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/RUcYXYiIfRQ/four-short-links-28-march-2018"
 },
 {
  "title": "Four short links: 27 March 2018",
  "content": "Database Attack, Death of Android Predicted, Predicting Recidivism, and Cybersecurity Law and Policy\n\nDeep Dive: Database Attacks -- I enjoyed the description of how this attack worked: using Postgres to write and run executables, smuggling in an executable that sets up a cryptocurrency mining operation on the machine.\n\nYegge on Android (Steve Yegge) -- Remember that I said it could take 20 minutes to see a 1-line code change in the regular Android stack? That can happen in the biggest apps like Nest or Facebook, but even for medium-size apps it can be two or three minutes. Whereas with React Native, it\u2019s instantaneous. You make a change; you see the change. And that, folks, means you get to launch features 10x faster, which means faster time to market, which means first-mover advantage, which means you win, win, win. Abandoning native programming in favor of fast-cycle cross-platform frameworks like React Native is a winning strategy. Tim Bray disagrees with some of Yegge's points. (Also: Yegge's hiring, which is why he's blogging again)\n\nThe Accuracy, Fairness, and Limits of Predicting Recidivism -- We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. We further show that a simple linear predictor provided with only two features is nearly equivalent to COMPAS with its 137 features. (via Aravind Narayanan)\n\nTeaching Cybersecurity Law and Policy -- My syllabus is much more than a one- or two-pager just listing the topics and weekly readings. Though there are a lot of reading assignments, the syllabus itself functions a bit like a casebook in that there also is a ton of narrative text framing each week\u2019s topic, and also extensive questions for consideration matched to each reading. The full syllabus is 58 pages long. (via Bobby Chesney)\n\nContinue reading Four short links: 27 March 2018.",
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/i-PQWT-lu3U/four-short-links-27-march-2018"
 }
]