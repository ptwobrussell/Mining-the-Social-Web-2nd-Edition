<html>
    <head>
        <title>It’s time for data ethics conversations at your dinner table Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body>In an <strong>era</strong> where fake <strong>news</strong> <strong>travels</strong> faster than the <strong>truth</strong>, our <strong>communities</strong> are at a critical <strong>juncture.With</strong> 2.5 <strong>quintillion</strong> <strong>records</strong> of <strong>data</strong> cr<strong>eat</strong>ed every <strong>day</strong>, <strong>people</strong> are being defined by how they travel, surf the <strong>internet</strong>, <strong>eat</strong>, and live their lives. We are in the <strong>midst</strong> of a <strong>“</strong><strong>data revolution</strong>,<strong>”</strong> where <strong>individuals</strong> and <strong>organizations</strong> can store and analyze massive <strong>amounts</strong> of information. Leveraging <strong><strong><strong>data</strong></strong></strong> can allow for surprising <strong>discoveries</strong> and <strong>innovations</strong> with the <strong>power</strong> to fundamentally alter <strong>society</strong>: from applying <strong>machine learning</strong> to <strong>cancer research</strong> to harnessing <strong><strong><strong>data</strong></strong></strong> to create <strong>“</strong>smart<strong>”</strong> <strong>cities</strong>, <strong><strong><strong>data</strong></strong></strong> <strong>science</strong> <strong>efforts</strong> are increasingly surfacing new insights—and new questions. Working with large <strong>databases</strong>, new analytical <strong>tools</strong>, and data-enabled <strong>methods promises</strong> to bring many <strong>benefits</strong> to society. However, “data-driven <strong>technologies</strong> also challenge the fundamental <strong>assumptions</strong> upon which our <strong>societies</strong> are built,<strong>”</strong> says <strong>Margo Boenig-Liptsin</strong>, <strong>co-instructor</strong> of UC Berkeley’s “Human Contexts and <strong>Ethics</strong> of Data<strong>”</strong> course. <strong>Boenig-Liptsin</strong> <strong>notes</strong>, <strong>“</strong>In this <strong>time</strong> of rapid social and technological <strong>change</strong>, <strong>concepts</strong> like <strong><strong>‘</strong></strong><strong>privacy</strong>,<strong>’</strong> <strong><strong>‘</strong></strong><strong>fairness</strong>,<strong>’</strong> and <strong><strong>‘</strong></strong>representation<strong>’</strong> are reconstituted.<strong>”</strong> Indeed, <strong>bias</strong> in <strong>algorithms</strong> may favor some <strong>groups</strong> over <strong>others</strong>, as evidenced by notorious <strong>cases</strong> such as the <strong>finding</strong> by <strong>MIT Researcher Joy Buolamwini</strong> that certain facial <strong>recognition software</strong> fails to work for those with dark <strong>skin</strong> tones. Moreover, <strong>lack</strong> of <strong>transparency</strong> and <strong>data</strong> <strong>misuse</strong> at ever-larger <strong>scales</strong> has prompted <strong>calls</strong> for greater <strong>scrutiny</strong> on <strong>behalf</strong> of more than 50 million <strong>Facebook</strong> users. In an <strong>era</strong> where fake <strong>news</strong> <strong>travels</strong> faster than the <strong>truth</strong>, our <strong>communities</strong> are at a critical <strong>juncture</strong>, and we need to be having difficult <strong>conversations</strong> about our individual and collective <strong>responsibility</strong> to handle data ethically. These <strong>conversations</strong>, and the <strong>principles</strong> and <strong>outcomes</strong> that emerge as a result, will benefit from being intentionally inclusive. What does responsible <strong>data</strong> <strong>sharing</strong> and use <strong>look</strong> like—for a <strong>data</strong> scientist, a <strong>parent</strong>, or a business? How are our socioeconomic <strong>structures</strong> and <strong>methods</strong> of <strong>interaction</strong> shaping behavior? How might we ensure that our technologies and practices are fair and unbiased? One <strong>idea</strong> that has gained <strong>traction</strong> is the <strong>need</strong> for a ‘Hippocratic Oath’ for <strong>data</strong> scientists. Just as medical <strong>professionals</strong> pledge to “do no <strong>harm</strong>,” <strong>individuals</strong> working with <strong>data</strong> should sign and abide by one or a <strong>set</strong> of <strong>pledges</strong>, <strong>manifestos</strong>, <strong>principles</strong>, or <strong>codes</strong> of conduct. At Bloomberg’s <strong><strong>Data</strong></strong> for <strong>Good Exchange</strong> (<strong>D4GX</strong>) in <strong>New York City</strong> in <strong>September</strong> 2017, the <strong>company</strong> announced a <strong>partnership</strong> with <strong><strong>Data</strong></strong> for <strong>Democracy</strong> and <strong>BrightHiveto</strong> bring the <strong>data science community</strong> together to explore this very topic. More than 100 <strong>volunteers</strong> from <strong>universities</strong>, <strong>nonprofits</strong>, local and federal <strong>government</strong> <strong>agencies</strong>, and <strong>tech</strong> <strong>companies</strong> participated, drafting a <strong>set</strong> of guiding <strong>principles</strong> that could be adopted as a <strong>code</strong> of ethics. Notably, this is an ongoing and iterative <strong>process</strong> that must be <strong>community</strong> driven, respecting and recognizing the <strong>value</strong> of diverse <strong>thoughts</strong> and experiences. The <strong>group</strong> re-convened on <strong>February</strong> 6, 2018, at the inaugural <strong>D4GX</strong> <strong>event</strong> in <strong>San Francisco</strong>, again open to the public. Notable <strong>attendees</strong> included <strong>DJ Patil</strong>, who served as the <strong>chief</strong> <strong>data</strong> <strong>scientist</strong> of the <strong>United</strong> <strong>States</strong> from 2015-2017, <strong>Doug Cutting</strong>, <strong>co-creator</strong> of <strong>Hadoop</strong> and <strong>advocate</strong> for open <strong>source</strong>, as well as <strong>representation</strong> from the <strong>National Science Foundation-funded Regional Big Data Innovation Hubs</strong> and <strong>Spokes</strong> program. At this <strong>event</strong>, <strong>participants</strong> reviewed more than 75 drafted <strong>ethics <strong>principles</strong></strong> formulated by several working <strong><strong>group</strong>s</strong>, with the <strong>goal</strong> of distilling a larger <strong>group</strong> of <strong>tenets</strong> into a streamlined <strong>set</strong> of <strong>principles</strong> for an ethics code. <strong>Efforts</strong> such as Bloomberg’s <strong>D4GX</strong> can be situated in a growing <strong>movement</strong>, with increased <strong>interest</strong> in the ethical <strong>aspects</strong> of <strong>technology</strong>, particularly related to <strong>advances</strong> in <strong>data</strong> <strong>science</strong> and artificial <strong>intelligence</strong> (<strong>AI</strong>) systems. For <strong>example</strong>, <strong>AI</strong> Now 2017, <strong>IEEE</strong>, The <strong>Future</strong> of <strong>Life Institute</strong>, <strong>Metro Lab Network</strong>, the <strong>ACM</strong>, and the <strong>Oxford Internet Institute</strong> have all issued <strong>reports</strong> on these topics. Plus, Microsoft’s <strong>Brad Smith</strong> and <strong>Harry Shum</strong> published a <strong>book</strong> entitled The <strong>Future Computed</strong>: Artificial <strong>intelligence</strong> and its <strong>role</strong> in <strong>society</strong> earlier this year. A recent <strong>National Science Foundation</strong> <strong>grant</strong> focusing on the responsible <strong>use</strong> of big <strong>data</strong> was awarded to a <strong>group</strong> of <strong>researchers</strong> led by <strong>Julia Stoyanovich</strong>, an <strong>assistant professor</strong> at <strong>Drexel University</strong>, who has participated regularly in <strong>D4GX</strong> <strong>events</strong> in <strong>New York</strong> and San Francisco. The <strong>goal</strong> of this <strong>research project</strong> is to understand how legal and ethical <strong>norms</strong> can be embedded into <strong>technology</strong>, and to create <strong>tools</strong> that enable responsible <strong>collection</strong>, <strong>sharing</strong>, and <strong>analysis</strong> of data. These <strong>issues</strong> have also been a <strong>topic</strong> of <strong>discussion</strong> at multiple recent workshops. Last <strong>week</strong>, a <strong>workshop</strong> at the <strong>National Academy</strong> of <strong>Sciences</strong> focused on <strong>ethics</strong> and <strong>data</strong> in the <strong>context</strong> of international <strong>research</strong> collaborations. Similarly, another recent <strong>workshop</strong> on <strong><strong>fairness</strong></strong> in <strong>machine learning</strong> aimed to identify key <strong>challenges</strong> and open <strong>questions</strong> that limit <strong><strong>fairness</strong></strong>, both in <strong>theory</strong> and in practice. As noted in the <strong>AI</strong> Now 2017 <strong>report</strong>, there are powerful <strong>incentives</strong> for the commercial <strong>sector</strong> to disregard these <strong>initiatives</strong> in <strong>favor</strong> of business as usual. It is not clear how <strong>compliance</strong> and <strong>accountability</strong> could be incentivized, monitored, or enforced in both the <strong>public</strong> and private <strong>sectors</strong>, although new <strong>European Union</strong> <strong>regulations</strong> pertaining to data <strong>privacy</strong> will affect <strong>organizations</strong> globally beginning in May 2018. “Top-down” <strong>regulations</strong> as well as “<strong>grassroots</strong>” <strong>efforts</strong> are increasingly raising <strong>questions</strong> about how we might define <strong>fairness</strong>, <strong>combat bias</strong>, and create <strong>ethics guidelines</strong> in <strong>data</strong> <strong>science</strong> and AI. Yet, widespread <strong>adoption</strong> of ethical <strong><strong>data</strong></strong> <strong>collection</strong> and <strong><strong>data</strong></strong> analysis <strong>practices</strong> requires more than <strong>business</strong> <strong>penalties</strong> and <strong>awareness</strong> of these <strong>issues</strong> on the <strong>part</strong> of <strong><strong>data</strong></strong> <strong>science</strong> <strong>practitioners</strong> and the general public. Ultimately, <strong><strong>data</strong> scientists</strong> and our broader <strong>community</strong> of <strong>data</strong> <strong>users</strong> must be equipped with the <strong>right</strong> <strong>tools</strong> and <strong>methodologies</strong>, and help each other leverage guidance effectively. <strong>Boenig-Liptsin</strong> <strong>notes</strong>, “We need to understand how our <strong>values</strong> shape our <strong><strong>data</strong></strong> <strong><strong>tools</strong></strong> and, reciprocally, how our <strong><strong>data</strong></strong> <strong><strong>tools</strong></strong> inform our <strong>values</strong>.<strong>” Successful</strong> <strong>efforts</strong> will require thoughtful and sustainable <strong>collaboration</strong> to apply <strong>insights</strong> and refine solutions. We are seeing an increasing <strong>number</strong> of <strong>data practitioners</strong> and <strong>leaders</strong> stand up and speak about the questionable and often outright illegal <strong>collection</strong>, <strong>sharing</strong>, and <strong>use</strong> of sensitive data. For their <strong>voices</strong> to drive <strong>change</strong>, and for our <strong>society</strong> to truly harness the positive <strong>impacts</strong> of <strong>data</strong> <strong>innovation</strong>, while mitigating unintended <strong>consequences</strong>, we will need a collective effort. This <strong>effort</strong> needs to reach beyond <strong>academia</strong> and <strong>policymakers</strong> to <strong>anyone</strong> who can contribute—from both the <strong>public</strong> and private sectors. Our <strong>community</strong> needs to collectively <strong>voice</strong> <strong>expectations</strong> for responsible <strong>data</strong> <strong>use</strong>, bringing <strong>data</strong> practitioners together to examine existing <strong>research</strong> and evidence. By creating <strong>environments</strong>, <strong>curricula</strong>, and <strong>tools</strong> that support <strong>community dialogue</strong> around <strong>ethics challenges</strong>, we can hope to translate <strong>findings</strong> into actionable principles—and to hold each other accountable. In <strong>addition</strong> to working with regulatory <strong>bodies</strong>, the <strong>shaping</strong> of social <strong>norms</strong> can transform these <strong>principles</strong> into enforceable <strong>standards</strong> for the responsible <strong>use</strong> of data. As <strong>Barbara C. Jordan</strong>, a former <strong>member</strong> of the <strong>U.S. House</strong> of <strong>Representatives</strong> from <strong><strong>Texas</strong></strong>, and <strong>professor</strong> of <strong>ethics</strong> at the <strong>University</strong> of <strong><strong>Texas</strong></strong> at <strong>Austin</strong>, eloquently stated in 1976:

There is no executive <strong>order</strong>; there is no <strong>law</strong> that can require the American <strong>people</strong> to form a national community. This we must do as <strong><strong>individuals</strong></strong>, and if we do it as <strong><strong>individuals</strong></strong>, there is no <strong>President</strong> of the <strong>United</strong> <strong>States</strong> who can veto that <strong>decision</strong>... We must define the 'common good' and begin again to shape a common future. Fully harnessing the <strong><strong>data</strong> revolution</strong> requires that we not only explore what can be done with <strong>data</strong>, but also that we understand the broader <strong>impacts</strong> of how any individual or <strong>organization</strong><strong>’</strong>s <strong>contribution</strong> affects others. We should be having these <strong>conversations</strong> early and often, bringing in a diverse <strong>range</strong> of perspectives. We should be having these <strong>conversations</strong> not just at academic <strong>conferences</strong> and in <strong>tech</strong> and <strong>ethics courses</strong>, but around <strong>dinner</strong> tables, everywhere. <strong>Continue</strong> reading It’s <strong>time</strong> for <strong>data ethics conversations</strong> at your dinner table.</body>
</html>