<html>
    <head>
        <title>The importance of transparency and user control in machine learning Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body>The O’Reilly <strong>Data Show</strong> Podcast: <strong><strong>Guillaume Chaslot</strong></strong> on <strong>bias</strong> and <strong>extremism</strong> in content <strong>recommendations.In</strong> this <strong>episode</strong> of the <strong>Data Show</strong>, I spoke with <strong><strong>Guillaume Chaslot</strong></strong>, an ex-YouTube <strong>engineer</strong> and <strong>founder</strong> of <strong>AlgoTransparency</strong>, an <strong>organization</strong> dedicated to helping the public understand the <strong>profound impact</strong> <strong>algorithms</strong> have on our lives. We live in an <strong>age</strong> when many of our <strong>interactions</strong> with <strong>companies</strong> and <strong>services</strong> are governed by algorithms. At a <strong>time</strong> when their <strong>impact</strong> continues to grow, there are many <strong>settings</strong> where these <strong>algorithms</strong> are far from transparent. There is growing awareness about the vast <strong>amounts</strong> of <strong>data</strong> <strong>companies</strong> are collecting on their <strong>users</strong> and <strong>customers</strong>, and <strong>people</strong> are starting to demand <strong>control</strong> over their <strong>data</strong>. A similar <strong>conversation</strong> is starting to happen about <strong>algorithms—users</strong> are wanting more <strong>control</strong> over what these <strong>models</strong> optimize for and an understanding of how they work. I first came across <strong>Chaslot</strong> through a <strong>series</strong> of <strong>articles</strong> about the <strong>power</strong> and <strong>impact</strong> of <strong>YouTube</strong> on <strong>politics</strong> and society. Many of the <strong>articles</strong> I read relied on <strong>data</strong> and <strong>analysis</strong> supplied by Chaslot. We talked about his <strong>work</strong> trying to decipher how YouTube’s <strong>recommendation system</strong> <strong>work</strong>s, <strong>filter</strong> <strong>bubbles</strong>, <strong><strong>transparency</strong></strong> in <strong>machine learning</strong>, and <strong>data</strong> <strong>privacy.Continue</strong> reading The <strong>importance</strong> of <strong><strong>transparency</strong></strong> and <strong>user control</strong> in <strong>machine learning</strong>.</body>
</html>