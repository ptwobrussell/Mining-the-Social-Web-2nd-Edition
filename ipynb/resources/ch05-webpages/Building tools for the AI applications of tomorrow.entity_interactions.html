<html>
    <head>
        <title>Building tools for the AI applications of tomorrow Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body>We’re curren<strong>t</strong>ly laying <strong>t</strong>he <s<strong>t</strong>rong>founda<strong>t</strong>ion</s<strong>t</strong>rong> for fu<strong>t</strong>ure <s<strong>t</strong>rong>genera<strong>t</strong>ions</s<strong>t</strong>rong> of <s<strong>t</strong>rong><strong>AI</strong></s<strong>t</strong>rong> <s<strong>t</strong>rong>applica<strong>t</strong>ions</s<strong>t</strong>rong>, bu<strong>t</strong> we aren’<strong>t</strong> <strong>t</strong>here ye<strong>t</strong>.For <strong>t</strong>he las<strong>t</strong> few <strong>years</strong>, <s<strong>t</strong>rong><strong>AI</strong></s<strong>t</strong>rong> has been almos<strong>t</strong> synonymous wi<strong>t</strong>h deep <strong>learning</strong> (DL). We’ve seen <strong>AlphaGo</strong> touted as an <strong>example</strong> of deep learning. We’ve seen deep <strong>learning</strong> used for naming <strong>paint</strong> <strong>colors</strong> (not very successfully), imitating <strong>Rembrandt</strong> and other great <strong>paint</strong>ers, and many other applications. <strong>Deep</strong> <strong><strong>learning</strong></strong> has been successful in <strong>part</strong> because, as <strong>François Chollet</strong> tweeted, “you can achieve a surprising <strong>amount</strong> using only a small <strong>set</strong> of very basic techniques.” In other <strong>words</strong>, you can accomplish <strong>things</strong> with deep <strong><strong>learning</strong></strong> that don’<strong>t require</strong> you to become an <strong>AI</strong> expert. <<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong>Deep</<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong> <<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong>learning</<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong><<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong>’</<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong><s<strong>t</strong>rong>s</s<strong>t</strong>rong> apparen<strong>t</strong> <s<strong>t</strong>rong>s</s<strong>t</strong>rong>implici<strong>t</strong>y--<strong>t</strong>he <s<strong>t</strong>rong>s</s<strong>t</strong>rong>mall <s<strong>t</strong>rong>number</s<strong>t</strong>rong> of ba<s<strong>t</strong>rong>s</s<strong>t</strong>rong>ic <strong>t</strong>echnique<s<strong>t</strong>rong>s</s<strong>t</strong>rong> you need <strong>t</strong>o know--make<s<strong>t</strong>rong>s</s<strong>t</strong>rong> i<strong>t</strong> much ea<s<strong>t</strong>rong>s</s<strong>t</strong>rong>ier <strong>t</strong>o “democra<strong>t</strong>ize<s<strong>t</strong>rong>” <s<strong>t</strong>rong>AI</s<strong>t</strong>rong></s<strong>t</strong>rong>, <strong>t</strong>o build a <s<strong>t</strong>rong>core</s<strong>t</strong>rong> of <s<strong>t</strong>rong>AI</s<strong>t</strong>rong> developer<s<strong>t</strong>rong>s</s<strong>t</strong>rong> <strong>t</strong>ha<strong>t</strong> don<<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong>’</<s<strong>t</strong>rong>s</s<strong>t</strong>rong><strong>t</strong>rong><strong>t</strong> have Ph.D.<s<strong>t</strong>rong>s</s<strong>t</strong>rong> in applied ma<strong>t</strong>h or compu<strong>t</strong>er <s<strong>t</strong>rong>s</s<strong>t</strong>rong>cience. But having said that, there’s a deep problem with deep learning. As <s<strong>t</strong>rong>Ali Rahimi</s<strong>t</strong>rong> has argued, we can of<strong>t</strong>en ge<strong>t</strong> deep <s<strong>t</strong>rong>learning</s<strong>t</strong>rong> <strong>t</strong>o work, bu<strong>t</strong> we aren’<strong>t</strong> close <strong>t</strong>o unders<strong>t</strong>anding how, when, or why i<strong>t</strong> works: <strong>“</strong>we’re equipping [new <strong>AI</strong> <strong>developers</strong>] wi<strong>t</strong>h li<strong>t</strong><strong>t</strong>le more <strong>t</strong>han folklore and pre-<strong>t</strong>rained deep ne<strong>t</strong>s, <strong>t</strong>hen asking <strong>t</strong>hem <strong>t</strong>o innova<strong>t</strong>e. We can barely agree on the <<strong>s</strong>trong>phenomena</<strong>s</strong>trong> that we <strong>s</strong>hould be explaining away.” <<strong>s</strong>trong>Deep</<strong>s</strong>trong> <<strong>s</strong>trong>learning</<strong>s</strong>trong><<strong>s</strong>trong>’</<strong>s</strong>trong><strong>s</strong> <strong>s</strong>ucce<strong>s</strong><strong>s</strong>e<strong>s</strong> are <strong>s</strong>ugge<strong>s</strong>tive, but if we can<<strong>s</strong>trong>’</<strong>s</strong>trong>t <strong>figure</strong> out why it work<strong>s</strong>, it<strong>s</strong> <strong>value</strong> a<strong>s</strong> a tool i<strong>s</strong> limited. We can build an <strong>army</strong> of deep <strong>learning</strong> <strong>developers</strong>, but that won<strong>’</strong>t <strong>help</strong> much if all we can tell them is, “Here are some tools. Try random stuff. Good <strong>luck.</strong><strong>”</strong>
However, nothing is as simple as it seems. The best <strong>applications</strong> we’ve seen to <strong>date</strong> have been hybrid systems. <strong>AlphaGo</strong> <strong>wasn</strong><strong>’</strong>t a pure deep <strong>learning engine</strong>; it incorporated <strong>Monte Carlo Tree Search</strong>, and at least two deep neural networks. At O’Reilly’s <strong>New York AI Conference</strong> in 2017, <strong>Josh Tenenbaum</strong> and <strong>David Ferrucci</strong> sketched out <strong><strong>systems</strong></strong> they are working on, <strong><strong>systems</strong></strong> that combine deep <strong>learning</strong> with other <strong>ideas</strong> and methods. <strong>Tenenbaum</strong> is working with one-shot <strong>learning</strong>, imitating the human <strong>ability</strong> to learn based on a single <strong>experience</strong>, and <strong>Ferrucci</strong> is working on building cognitive <strong>models</strong> that enable <strong>machines</strong> to understand human <strong>language</strong> in a meaningful way, not just pattern matching. DeepStack’<strong>s poker</strong> playing <strong>system</strong> <strong>combines</strong> neural <strong>networks</strong> with counterfactual <strong>regret minimization</strong> and heuristic search. Adding <strong>structure</strong> to improve <strong>models</strong>
The fundamental <strong>idea</strong> behind deep <strong><strong>learning</strong></strong> is very simple: deep <strong><strong>learning</strong></strong> <strong>systems</strong> are neural <strong>networks</strong> with several hidden layers. Each <<strong>s</strong>trong>neuron</<strong>s</strong>trong> i<strong>s</strong> very <strong>s</strong>imple: it take<strong>s</strong> a <<strong>s</strong>trong>number</<strong>s</strong>trong> of <<strong>s</strong>trong>input<strong>s</strong></<strong>s</strong>trong> from previou<strong>s</strong> <<strong>s</strong>trong>layer<strong>s</strong></<strong>s</strong>trong>, <<strong>s</strong>trong>combine<strong>s</strong></<strong>s</strong>trong> them according to a <<strong>s</strong>trong><strong>s</strong>et</<strong>s</strong>trong> of <<strong>s</strong>trong>weight<strong>s</strong></<strong>s</strong>trong>, and produce<strong>s</strong> an <<strong>s</strong>trong>output</<strong>s</strong>trong> that’<strong>s</strong> pa<strong>s</strong><strong>s</strong>ed to the next layer. The <s<strong>t</strong>rong>ne<strong>t</strong>work doesn</s<strong>t</strong>rong><s<strong>t</strong>rong><strong>’</strong></s<strong>t</strong>rong><strong>t</strong> really care whe<strong>t</strong>her i<strong>t</strong><s<strong>t</strong>rong><strong>’</strong></s<strong>t</strong>rong>s <strong>processing</strong> <strong>images</strong>, <strong>t</strong>ex<strong>t</strong>, or <strong>t</strong>eleme<strong>t</strong>ry. That <strong>simplicity</strong>, though, is a <strong>hint</strong> that we’re missing out on a <strong>lot</strong> of <strong>structure</strong> that’s inherent in data. Images and texts aren’t the same; they’re structured differently. <strong>Languages</strong> have a <strong>lot</strong> of internal structure. As the computational <strong>linguist</strong> <strong>Chris Manning</strong> says:
I think the current <strong>era</strong> where <strong>everyone</strong> touts this <strong>mantra</strong> of fast <strong>GPUs</strong>, massive <strong>data</strong>, and these great deep <strong>learning algorithms</strong> has ... sent computational <strong>linguist</strong>ics off-track. Because it is the <strong>case</strong> that if you have huge <strong>computation</strong> and massive <strong>amounts</strong> of <strong>data</strong>, you can do a <strong>lot</strong> ... with a simple learning device. But those learners are extremely bad learners. Human beings are extremely good learners. What we want to do is build <strong>AI</strong> <strong>devices</strong> that are also extremely good learners. ... The <strong>way</strong> to achieve those <strong>learners</strong> is to put much more innate structures. If we’re going to make <strong>AI</strong> <strong>applications</strong> that understand <strong>language</strong> as well as <strong>humans</strong> do, we will have to take <strong>advantage</strong> of the <strong>structures</strong> that are in <strong>language</strong>. From that <strong>standpoint</strong>, deep <strong>learning</strong> has been a fruitful dead <strong>end</strong>: it’s a <strong>shortcut</strong> that has prevented us from asking the really important <strong>questions</strong> about how knowledge is structured. <strong>Gary Marcus</strong> makes an <strong>argument</strong> that’s even more radical:
There is a whole <strong>world</strong> of possible <strong>innate</strong> <strong>mechanisms</strong> that <strong>AI</strong> <strong>researchers</strong> might profitably consider; simply presuming by <strong>default</strong> it is desirable to include little or no <strong>innate</strong> machinery seems, at best, close-minded. And, at worst, an unthinking <strong>commitment</strong> to relearning <strong>everything</strong> from <strong>scratch</strong> may be downright foolish, effectively putting each <strong>individual</strong> <strong>AI</strong> <strong>system</strong> in the <strong>position</strong> of having to recapitulate a large <strong>portion</strong> of a billion <strong>years</strong> of evolution. <strong>Deep</strong> <strong>learning</strong> began with a <strong>model</strong> that was, at least in <strong>principle</strong>, based on the human <strong>brain</strong>: the <strong>interconnection</strong> of <strong>neurons</strong>, and the ancient <strong>notion</strong> that human <strong>brain</strong>s start out as a blank slate. <strong>Marcus</strong> is arguing that <strong>humans</strong> are born with <strong>innate</strong> <strong>abilities</strong> which are still very poorly <strong>understood</strong>--for <strong>example</strong>, the <strong><strong>ability</strong></strong> to learn <strong>language</strong>, or the <strong><strong>ability</strong></strong> to form abstractions. For <strong>AI</strong> to progress beyond deep <strong>learning</strong>, he suggests that <strong>researchers</strong> must learn how to model these innate abilities. There are other paths forward. <strong>Ben Recht</strong> has written a <strong>series</strong> of <strong>posts</strong> sketching out how <strong>one</strong> might approach <strong>problems</strong> that fall under reinforcement learning. He is also concerned with the <strong>possibility</strong> that deep <strong>learning</strong>, as practiced <strong>today</strong>, promises more than it can deliver:
If you read <strong>Hacker News</strong>, you’d think that deep reinforcement <strong>learning</strong> can be used to solve any problem. ... I personally get suspicious when audacious <strong>claims</strong> like this are thrown about in <strong>press</strong> <strong>releases</strong>, and I get even more suspicious when other <strong>researchers</strong> call into <strong>question</strong> their reproducibility. <strong>Recht</strong> argues for taking a comprehensive <strong>view</strong>, and re<strong>view</strong>s the <strong>possibility</strong> for augmenting <strong>reinforcement</strong> learning with <strong>techniques</strong> from optimal <strong>control</strong> and dynamical systems. This allows <strong>RL</strong> <strong>models</strong> to benefit from <strong>research</strong> <strong>results</strong> and <strong>techniques</strong> used in many real-world applications. He notes:
By throwing away <strong>models</strong> and <strong>knowledge</strong>, it is never clear if we can learn enough from a few <strong>instances</strong> and <strong>random</strong> seeds to generalize. <strong><strong>AI</strong></strong> is more than <strong><strong>machine learning</strong></strong>
As <strong>Michael Jordan</strong> pointed out in a recent <strong>post</strong>, what is called <strong><strong>AI</strong></strong> is often <strong><strong>machine learning</strong></strong> (ML). As <strong>someone</strong> who organizes <strong>AI</strong> <strong>conferences</strong>, I can attest to this: many of the <strong>proposals</strong> we receive are for standard <strong>machine learning</strong> applications. The <strong>confusion</strong> was inevitable: when calling a <strong>research project</strong> <strong><strong>“</strong></strong>artificial intelligence” was hardly respectable, we used the <strong>term</strong> <strong><strong>“</strong></strong><strong>machine <strong>learning</strong>.</strong><strong>” ML</strong> became a <strong>shorthand</strong> for <strong><strong>“</strong></strong>the <strong><strong>parts</strong></strong> of <strong>AI</strong> that work.” These <strong><strong>parts</strong></strong>, up to and including deep <strong>learning</strong>, were basically large-scale <strong>data</strong> analysis. Now that the <strong>tides</strong> of <strong>buzz</strong> have shifted, and <strong>everyone</strong> wants <strong>AI</strong>, <strong>machine learning</strong> <strong>applications</strong> are <strong>AI</strong> again. But a full-fledged <strong>AI</strong> <strong>application</strong>, such as an autonomous <strong>vehicle</strong>, requires much more than <strong>data</strong> analysis. It will require <strong>progress</strong> in many <strong>areas</strong> that go well beyond pattern recognition. To build an autonomous <strong>vehicle</strong> and other true <strong>AI</strong> <strong>applications</strong>, we will need significant <strong>advances</strong> in <strong>sensors</strong> and other <strong>hardware</strong>; we will need to learn how to build <strong>software</strong> for <strong>“</strong><strong><strong>edge</strong></strong> <strong><strong>devices</strong></strong>,<strong>”</strong> which includes understanding how to partition <strong>problems</strong> between the <strong><strong>edge</strong></strong> <strong><strong>devices</strong></strong> and some <strong>kind</strong> of <strong>“</strong>cloud<strong>”</strong>; we will need to develop <strong>infrastructure</strong> for <strong>simulation</strong> and distributed <strong>computation</strong>; and we will need to understand how to craft the <strong>user experience</strong> for truly intelligent <strong><strong>devices</strong></strong>. <strong>Jordan</strong> highlights the <strong>need</strong> for further <strong>research</strong> in two important <strong>areas</strong>:
<strong>Intelligence augmentation</strong> (<strong>IA</strong>): <strong>Tools</strong> that are designed to augment human <strong>intelligence</strong> and capabilities. These include <s<strong>t</strong>rong>search</s<strong>t</strong>rong> <s<strong>t</strong>rong>engines</s<strong>t</strong>rong> (which remember <s<strong>t</strong>rong><strong>t</strong>hings</s<strong>t</strong>rong> we can’<strong>t</strong>), au<strong>t</strong>oma<strong>t</strong>ed <strong>t</strong>ransla<strong>t</strong>ion, and even <strong>aids</strong> for ar<strong>t</strong>is<strong>t</strong>s and musicians. These <strong>tools</strong> might involve high-level <strong>reasoning</strong> and <strong>thought</strong>, though current <strong>implementations</strong> don’t. Intelligent <strong>infrastructure</strong> (<strong><strong>II</strong></strong>): <strong>Jordan</strong> defines <strong><strong>II</strong></strong> as <strong>“</strong>a <strong>web</strong> of <strong>computation</strong>, <strong><strong>data</strong></strong>, and physical <strong>entities</strong> exist that make human <strong>environments</strong> more supportive, interesting and safe.<strong>”</strong> This would include <strong>networks</strong> to <strong>share</strong> medical <strong><strong>data</strong></strong> safely, <strong>systems</strong> to make <strong>transportation safer</strong> (including smart <strong>cars</strong> and smart <strong>roads</strong>), and many other applications. Intelligent <strong>infrastructure</strong> is about managing <strong>flows</strong> of <strong>data</strong> in <strong>ways</strong> that support human life. What<strong>’</strong>s most important about Jordan<strong>’</strong><strong>s argument</strong>, though, is that we won<strong>’</strong><strong>t get</strong> either <strong>IA</strong> or <strong>II</strong> if we focus solely on deep learning. They are inherently multidisciplinary. <s<strong>t</strong>rong>Deep</s<strong>t</strong>rong> <s<strong>t</strong>rong>learning</s<strong>t</strong>rong> will inevi<strong>t</strong>ably be <s<strong>t</strong>rong>par<strong>t</strong></s<strong>t</strong>rong> of <strong>t</strong>he <s<strong>t</strong>rong>solu<strong>t</strong>ion</s<strong>t</strong>rong>, bu<strong>t</strong> jus<strong>t</strong> as inevi<strong>t</strong>ably, i<strong>t</strong> won<s<strong>t</strong>rong>’</s<strong>t</strong>rong><strong>t</strong> be <strong>t</strong>he whole <s<strong>t</strong>rong>solu<strong>t</strong>ion</s<strong>t</strong>rong>. It may even be a very small part. Closing <strong>thoughts</strong>
<strong>Researchers</strong> from many <strong>institutions</strong> are building <strong>tools</strong> for creating the <strong>AI</strong> <strong>applications</strong> of the future. While there is still a <strong>lot</strong> of <strong>work</strong> to be done on deep <strong>learning</strong>, <strong>researchers</strong> are looking well beyond <strong>DL</strong> to build the next <strong>generation</strong> of <strong>AI</strong> systems. <strong>UC Berkeley</strong>'s <strong>RISE Lab</strong> has sketched out a <strong>research agenda</strong> that involves <strong>systems</strong>, <strong>architectures</strong>, and security. Ameet Talwalkar’s recent <strong>post</strong> lists a <strong>number</strong> of <strong>research</strong> <strong>directions</strong> that should benefit industrial <strong>machine learning</strong> platforms. <strong>Industrial</strong> <strong>machine learning</strong> will have to meet <strong>system</strong> <strong>requirements</strong>, such as <strong>memory</strong> <strong>limitations</strong>, <strong>power</strong> <strong>budgets</strong>, and hard real <strong>time</strong>; they must be easy to deploy and to update, particularly since <strong>data models</strong> tend to grow <strong>stale</strong> over <strong>time</strong>; and they must be safe. <strong>Humans</strong> must understand how <strong>applications</strong> make <strong>decisions</strong>, along with the likely <strong>consequences</strong> of those <strong>decisions</strong>. These <strong>applications</strong> must take <strong>ethics</strong> into account. These are all <strong>requirements</strong> for Jordan’s intelligent infrastructure. Over the past few <strong>years</strong>, we’ve seen many <strong>examples</strong> of <strong>machine</strong> learning put to questionable <strong>purposes</strong>, ranging from <strong>set</strong>ting <strong>bail</strong> and determining <strong>prison</strong> <strong>sentences</strong> to targeted <strong>advertising</strong>, emotional <strong>manipulation</strong>, and the <strong>spreading</strong> of <strong>misinformation</strong>, that point us to a different <strong>set</strong> of needs. The <strong>research agenda</strong> for <strong>AI</strong> needs to take into <strong>account fairness</strong> and <strong>bias</strong>, <strong>transparency</strong>, <strong>privacy</strong> and <strong>user control</strong> over <strong>data</strong>, and the <strong>models</strong> built from that <strong>data</strong>. These <strong>issues</strong> encompass <strong>everything</strong> from <strong>ethics</strong> to design: getting informed <strong><strong>consent</strong></strong>, and explaining what that <strong><strong>consent</strong></strong> <strong>means</strong>, is not a trivial design problem. We’re only starting to understand how these <strong>disciplines</strong> connect to <strong>research</strong> in artificial intelligence. Fortunately, we’re seeing increasing <strong>interest</strong> within the <strong>data</strong> <strong>community</strong> in connecting <strong>ethics</strong> to practice. <strong>Events</strong> like the <strong>Data</strong> For <strong>Good Exchange</strong> (<strong>D4GX</strong>), the <strong>Conference</strong> on <strong>Fairness</strong>, <strong>Accountability</strong>, and <strong>Transparency</strong> (<strong>FAT*</strong>), and <strong>others</strong> are devoted to data ethics. <strong>Talwalkar</strong> <strong>notes</strong> that <strong>air</strong> travel didn’t become <strong>commonplace</strong> until nearly 50 <strong>years</strong> after the <strong>Wright</strong> Brothers. While they were the first to achieve <strong>flight</strong>, many more <strong>developments</strong> were needed to make flying safe, inexpensive, and convenient. We’<strong>re</strong> at a similar <strong>stage</strong> in the <strong>history</strong> of AI. We’<strong>ve</strong> made <strong>progress</strong> in a few basic <strong>areas</strong>, and what we ultimately build will no doubt be amazing. We’re currently laying the <strong>foundation</strong> for future <strong>generations</strong> of <strong>AI</strong> <strong>applications</strong>, but we aren’t there yet. Related <strong>content</strong>:

<strong><strong>“</strong></strong>Toward the <strong>Jet Age</strong> of <strong><strong><strong><strong>machine</strong></strong></strong></strong> learning<strong>”</strong>
<strong><strong>“</strong></strong><strong>Open-endedness</strong>: The last grand <strong>challenge</strong> you’ve never <strong>heard</strong> of<strong>”</strong>

"<strong>Language</strong> <strong>understanding</strong> remains one of <strong>AI</strong>’s grand <strong>challenge</strong>s": <strong>David Ferrucci</strong> on the <strong>evolution</strong> of <strong>AI</strong> <strong>systems</strong> for <strong>language</strong> <strong>understanding</strong>
<strong><strong>“</strong></strong>The <strong><strong><strong><strong>machine</strong></strong></strong></strong> learning paradox<strong>”</strong>
<strong><strong>“</strong></strong>We need to build <strong><strong><strong><strong>machine</strong></strong></strong></strong> learning <strong><strong>tools</strong></strong> to augment <strong><strong><strong><strong>machine</strong></strong></strong></strong> learning <strong>engineers</strong><strong>”</strong>

"<strong>Building</strong> and deploying large-scale <strong><strong><strong><strong>machine</strong></strong></strong></strong> learning <strong>pipelines</strong>": <strong>Ben Recht</strong> on why we need <strong>primitives</strong>, <strong>pipeline synthesis</strong> <strong><strong>tools</strong></strong>, and most importantly, <strong>error analysis</strong> and verification. "How to train and deploy deep <strong>learning</strong> at <strong>scale</strong>": <strong>Ameet Talwalkar</strong> on large-<strong>scale</strong> machine <strong>learning</strong>

<strong>Continue</strong> reading <strong>Building</strong> <strong>tools</strong> for the <strong>AI</strong> <strong>applications</strong> of tomorrow.</body>
</html>