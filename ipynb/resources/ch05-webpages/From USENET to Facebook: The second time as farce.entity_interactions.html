<html>
    <head>
        <title>From USENET to Facebook: The second time as farce Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body>Demanding and building a social <strong>network</strong> that serves us and <strong>enables</strong> free <strong>speech</strong>, rather than serving a <strong>business</strong> metric that <strong>amplifies</strong> noise, is the <strong>way</strong> to end the farce.Re-interpreting <strong>Hegel</strong>, <strong>Marx</strong> said that <strong>everything</strong> in <strong>history</strong> <strong>happens</strong> twice, the first <strong>time</strong> as <strong>tragedy</strong>, the second as farce. That’s a fitting <strong>summary</strong> of Facebook’s Very Bad Month. There<strong>’</strong><s<strong>t</strong>rong>s no<strong>t</strong>hing</s<strong>t</strong>rong> here we haven<strong>’</strong><strong>t</strong> seen before, no<strong>t</strong>hing abou<strong>t</strong> <strong>abuse</strong>, <strong>t</strong>rolling, <strong>racism</strong>, <strong>spam</strong>, <strong>porn</strong>, and even bo<strong>t</strong>s <strong>t</strong>ha<strong>t</strong> <strong>hasn</strong><strong>’</strong><strong>t</strong> already happened. This time as farce? Certainly Zuckerberg’s 14-year <strong>Apology Tour</strong>, as <strong>Zeynep Tufecki</strong> calls it, has the <strong>look</strong> and <strong>feel</strong> of a farce. He ju<strong>s</strong>t can’t <<strong>s</strong>trong><strong>s</strong>top apologizing</<strong>s</strong>trong> for Facebook’<strong>s</strong> me<strong>s</strong><strong>s</strong>e<strong>s</strong>. Except that the <strong>farce isn</strong><strong>’</strong>t over yet. We’re in the middle of it. As <strong>Tufekci</strong> points out, 2018 <strong>isn</strong><strong>’</strong>t the first <strong>time</strong> <strong>Zuckerberg</strong> has said “we blew it, we<strong>’</strong>ll do better.<strong>” Apology</strong> has been a roughly biennial <strong>occurrence</strong> since Facebook<strong>’</strong>s earliest days. So, the <strong>question</strong> we face is simple: how do we bring this sad <strong>history</strong> to an <strong>endpoint</strong> that isn<strong>’</strong>t farce? The third time around, should there be one, it isn’t even farce; it’s just stupidity. We don’<strong>t</strong> have <strong>t</strong>o accep<strong>t</strong> fu<strong>t</strong>ure <strong>apologies</strong>, whe<strong>t</strong>her <strong>t</strong>hey come from <strong>Zuck</strong> or some o<strong>t</strong>her ne<strong>t</strong>work magna<strong>t</strong>e, as inevi<strong>t</strong>able. I want to think about what we can learn from the <strong>forerunners</strong> of modern social networks—specifically about <strong>USENET</strong>, the proto-internet of the 1980s and 90s. (The same observations probably apply to BBSs, though I’m less familiar with them.) <strong>USENET</strong> was a decentralized and unmanaged <strong>system</strong> that allowed <strong>Unix</strong> <strong>users</strong> to exchange “<strong>posts</strong>” by sending them to <strong>hundreds</strong> of newsgroups. It started in the early 80s, peaked sometime around 1995, and arguably ended as <strong>tragedy</strong> (though it went out with a <strong>whimper</strong>, not a bang). As a no-holds-barred <strong>Wild West</strong> <strong>sort</strong> of social <strong>network</strong>, <strong>USENET</strong> was filled with <strong>everything</strong> we rightly complain about today. It was easy to troll and be abusive; all too many participants did it for fun. Most <strong>groups</strong> were eventually flooded by <strong>spam</strong>, long before <strong>spam</strong> became a <strong>problem</strong> for email. Much of that <strong>spam</strong> distributed <strong>pornography</strong> or pirated <strong>software</strong> (“warez”). You could certainly find newsgroups in which to express your inner neo-Nazi or white supremacist self. Fake news? We had that; we had malicious <strong>answers</strong> to technical <strong>questions</strong> that would get new <strong>users</strong> to trash their systems. And yes, <strong>t</strong>here were <s<strong>t</strong>rong>bo<strong>t</strong>s</s<strong>t</strong>rong>; <strong>t</strong>ha<strong>t</strong> <s<strong>t</strong>rong><strong>t</strong>echnology isn</s<strong>t</strong>rong><s<strong>t</strong>rong>’</s<strong>t</strong>rong><strong>t</strong> as new as we<s<strong>t</strong>rong>’</s<strong>t</strong>rong>d like <strong>t</strong>o <strong>t</strong>hink. But there was a big <strong>divide</strong> on <strong>USENET</strong> between moderated and unmoderated newsgroups. <strong>Posts</strong> to moderated <strong>newsgroups</strong> had to be approved by a human <strong>moderator</strong> before they were pushed to the <strong>rest</strong> of the network. Moderated <strong>groups</strong> were much less <strong>prone</strong> to abuse. They weren’<strong>t immune</strong>, certainly, but moderated <strong>groups</strong> remained virtual <strong>places</strong> where <strong>discussion</strong> was mostly civilized, and where you could get questions answered. Unmoderated newsgroups were always spam-filled and frequently abusive, and the alt. <strong>*</strong> <strong>newsgroups</strong>, which could be created by <strong>anyone</strong>, for any <strong>reason</strong>, matched <strong>anything</strong> we have now for bad behavior. So, the first <strong>thing</strong> we should learn from <strong>USENET</strong> is the <strong>importance</strong> of moderation. Fully human <strong>moderation</strong> at <strong>Facebook</strong> scale is impossible. With seven billion <strong>pieces</strong> of <strong>content</strong> shared per <strong>day</strong>, even a million <strong>moderators</strong> would have to scan seven thousand <strong>posts</strong> each: roughly 4 <strong>seconds</strong> per post. But we don’t need to rely on human moderation. After USENET’s <strong>decline</strong>, <strong>research</strong> showed that it was possible to classify <strong>users</strong> as <strong>newbies</strong>, <strong><strong>help</strong>ers</strong>, <strong>leaders</strong>, <strong>trolls</strong>, or <strong>flamers</strong>, purely by their <strong>communications</strong> patterns—with only minimal <strong>help</strong> from the content. This could be the <strong>basis</strong> for automated <strong>moderation</strong> <strong>assistants</strong> that kick suspicious <strong>posts</strong> over to human <strong>moderators</strong>, who would then have the final word. <strong>Whether</strong> automated or human, <strong>moderators</strong> prevent many of the bad <strong>posts</strong> from being made in the first place. It’s no <strong>fun</strong> being a <strong>troll</strong> if you can’t get through to your victims. Automated moderation can also do fact checking. The <strong>technology</strong> that won <strong>Jeopardy</strong> a <strong>decade</strong> ago is more than capable of checking basic facts. It might not be capable of checking complex <strong>logic</strong>, but most “fake news” <strong>centers</strong> around facts that can easily be evaluated. And automated <<strong>s</strong>trong><strong>s</strong>y<strong>s</strong>tem<strong>s</strong></<strong>s</strong>trong> are very capable of detecting <<strong>s</strong>trong>bot<strong>s</strong></<strong>s</strong>trong>: Google’<strong>s</strong> <strong>Gmail</strong> ha<strong>s</strong> <strong>s</strong>ucce<strong>s</strong><strong>s</strong>fully throttled <strong>s</strong>pam. What else can we learn from USENET? Trolls were everywhere, but the really obnoxious stuff stayed where it was supposed to be. I’m not naive enough to think that neo-Nazis and white supremacists will dry up and go away, on Facebook or elsewhere. And I’m even content to allow them to have their own <strong><strong>Facebook</strong></strong> <strong>pages</strong>: <strong><strong>Facebook</strong></strong> can let these <strong>people</strong> talk to each other all they want, because they’re going to do that anyway, whatever tools you put in place. The <strong>problem</strong> we have now is that Facebook’s engagement metric paves the <strong>road</strong> to their door. Once you give <strong>someone</strong> a <strong>hit</strong> of something titillating, they’ll come back for more. And the next hit has to be stronger. That<<strong>s</strong>trong>’</<strong>s</strong>trong><strong>s</strong> how you keep <<strong>s</strong>trong>people</<strong>s</strong>trong> engaged, and that<<strong>s</strong>trong>’</<strong>s</strong>trong><strong>s</strong> (a<strong>s</strong> <strong>Tufekci</strong> ha<strong>s</strong> argued about YouTube) how you radicalize them. <strong>USENET</strong> had no engagement <strong>metrics</strong>, no <strong>means</strong> of linking <strong>users</strong> to stronger content. Islands of hatred certainly existed. But in a <strong>network</strong> that didn<strong>’</strong><strong>t optimize</strong> for <strong>engagement</strong>, <strong>hate</strong> <strong>groups</strong> didn<strong>’</strong>t spread. <strong>Neo-Nazis</strong> and their <strong>like</strong> were certainly there, but you had to search them out, you weren’t pushed to them. The <strong>platform didn</strong><strong><strong>’</strong></strong>t <strong>lead</strong> you there, trying to maximize your “engagement.<strong>”</strong> I can<strong><strong>’</strong></strong>t <strong>claim</strong> that was some <strong>sort</strong> of brilliant <strong>design</strong> on USENET<strong><strong>’</strong></strong>s <strong>part</strong>; it just wasn<strong><strong>’</strong></strong>t <strong>something anyone</strong> thought about at the time. And as a free <strong>service</strong>, there was a <strong>need</strong> to maximize profit. Facebook’s <strong>obsession</strong> with <strong>engagement</strong> is ultimately more dangerous than their sloppy <strong>handling</strong> of personal data. “Engagement” <strong>allows—indeed</strong>, <strong>encourages—hate</strong> groups to metastasize. Engagement <strong>metrics</strong> harm free <strong>speech</strong>, another <strong>ideal</strong> carried to the modern <strong>internet</strong> from the <strong>USENET</strong> world. But in an “<strong><strong>attention</strong> economy</strong>,” where the <strong>limiting factor</strong> is <strong>attention</strong>, not speech, we have to rethink what those values mean. I’<strong>ve</strong> said that <strong>USENET</strong> ended in a “whimper”—but what drained the energy away? The <strong>participants</strong> who contributed real <strong>value</strong> just got tired of wading through the <strong>spam</strong> and fighting off the trolls. They went elsewhere. USENET’s <strong>history</strong> gives us a <strong>warning</strong>: good <strong>speech</strong> was crowded off the <strong>stage</strong> by bad <strong>speech</strong>. <strong>Speech</strong> that exists to crowd out other <strong>speech isn</strong><strong>’</strong>t the unfettered <strong>interchange</strong> of ideas. Free <s<strong>t</strong>rong>speech doesn</s<strong>t</strong>rong><s<strong>t</strong>rong>’</s<strong>t</strong>rong><strong>t</strong> mean <strong>t</strong>he righ<strong>t</strong> <strong>t</strong>o a pla<strong>t</strong>form. Indeed, the <strong>U.S. Constitution</strong> already makes that <strong>distinction</strong>: “freedom of the <strong>press</strong>” is about <strong>platforms</strong>, and you don’<strong>t get freedom</strong> of the <strong>press</strong> unless you have a <strong>press</strong>. Again, <s<strong>t</strong>rong>Zeynep Tufekci</s<strong>t</strong>rong> has i<strong>t</strong>: in <s<strong>t</strong>rong>“</s<strong>t</strong>rong>I<strong>t</strong><s<strong>t</strong>rong>’</s<strong>t</strong>rong>s <strong>t</strong>he (<s<strong>t</strong>rong>Democracy-Poisoning</s<strong>t</strong>rong>) <s<strong>t</strong>rong>Golden Age</s<strong>t</strong>rong> of <s<strong>t</strong>rong>Free Speech</s<strong>t</strong>rong>,<s<strong>t</strong>rong>”</s<strong>t</strong>rong> she wri<strong>t</strong>es <s<strong>t</strong>rong>“</s<strong>t</strong>rong>The mos<strong>t</strong> effec<strong>t</strong>ive <s<strong>t</strong>rong>forms</s<strong>t</strong>rong> of <s<strong>t</strong>rong>censorship <strong>t</strong>oday</s<strong>t</strong>rong> involve meddling wi<strong>t</strong>h <s<strong>t</strong>rong><strong>t</strong>rus<strong>t</strong></s<strong>t</strong>rong> and <s<strong>t</strong>rong>a<strong>t</strong><strong>t</strong>en<strong>t</strong>ion</s<strong>t</strong>rong>, no<strong>t</strong> muzzling <s<strong>t</strong>rong>speech i<strong>t</strong>self.</s<strong>t</strong>rong><s<strong>t</strong>rong>”</s<strong>t</strong>rong> Censorship isn<s<strong>t</strong>rong>’</s<strong>t</strong>rong><strong>t</strong> abou<strong>t</strong> arres<strong>t</strong>ing dissiden<strong>t</strong>s; i<strong>t</strong><s<strong>t</strong>rong>’</s<strong>t</strong>rong>s abou<strong>t</strong> genera<strong>t</strong>ing so much <strong>noise</strong> <strong>t</strong>ha<strong>t</strong> voices you don<s<strong>t</strong>rong>’</s<strong>t</strong>rong><strong>t</strong> like can<s<strong>t</strong>rong>’</s<strong>t</strong>rong><strong>t</strong> be heard. If we’re to put an <strong>end</strong> to the <strong>farce</strong>, we need to understand what it means to enable speech, rather than to drown it out. Abandoning “engagement” is <strong>part</strong> of the solution. We will be better served by a <strong>network</strong> that, like <strong>USENET</strong>, <strong>doesn</strong><strong>’</strong><strong>t care</strong> how <strong>people</strong> engage, and that allows them to make their own connections. Automated <strong>moderation</strong> can be a <strong>tool</strong> that makes <strong>room</strong> for <strong>speech</strong>, particularly if we can take <strong>advantage</strong> of <strong>communication</strong> <strong>patterns</strong> to moderate those whose primary <strong>goal</strong> is to be the loudest voice. <strong>Marx</strong> certainly would have laid <strong>blame</strong> at the <strong>feet</strong> of <strong>Zuckerberg</strong>, for naively and profitably commoditizing the social <strong>identities</strong> of his users. But blame is not a solution. A<strong>s</strong> <<strong>s</strong>trong>convenient</<strong>s</strong>trong> a <<strong>s</strong>trong>punching bag</<strong>s</strong>trong> a<strong>s</strong> <<strong>s</strong>trong>Zuckerberg</<strong>s</strong>trong> i<strong>s</strong>, we have to recognize that Facebook’<strong>s</strong> problem<strong>s</strong> extend to the entire <strong>s</strong>ocial world. That includes <strong>Twitter</strong> and <strong>YouTube</strong>, many other social <strong>networks</strong> past and present, and many <strong>networks</strong> that are neither online nor social. Expecting <strong>Zuck</strong> to “fix <strong>Facebook</strong><strong>”</strong> may be the best <strong>way</strong> to guarantee that the farce plays on. <s<strong>t</strong>rong>His<strong>t</strong>ory</s<strong>t</strong>rong> is only de<strong>t</strong>erminis<strong>t</strong>ic in <s<strong>t</strong>rong>hindsigh<strong>t</strong></s<strong>t</strong>rong>, and i<strong>t</strong> doesn’<strong>t</strong> have <strong>t</strong>o end in farce (or worse). We all build our social <strong>networks</strong>, and <strong>Mark Zuckerberg</strong> <strong>isn</strong><strong><strong>’</strong></strong>t the only <strong>player</strong> on <strong>history</strong><strong><strong>’</strong></strong>s stage. We need to revisit, reassess, and learn from all of our past social networks. Demanding and building a social <strong>network</strong> that serves us and <strong>enables</strong> free <strong>speech</strong>, rather than serving a <strong>business</strong> metric that <strong>amplifies</strong> noise, is the <strong>way</strong> to end the farce. Is that a revolution? We have nothing to lose but our chains. <strong>Continue</strong> reading <strong>From USENET</strong> to Facebook: The second <strong>time</strong> as farce.</body>
</html>